{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "beVDRE2IOscX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdk2V9p9OevX"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import tarfile\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import QuadMesh\n",
        "import seaborn as sn\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import BertModel, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_dir = '/content/drive/MyDrive/msc_project/model/contrastive/lcl'\n",
        "dataset_path = \"/content/drive/MyDrive/msc_project/datasets\"\n",
        "# dataset_file_name = {\n",
        "#     \"imdb62\": 'full_imdb62.csv',\n",
        "#     \"blog\": 'full_blog.csv',\n",
        "#     \"turing\": \"turing_ori_0208.csv\"\n",
        "# }\n",
        "datasets = {\n",
        "    'contrax_datasets.tar': 'https://drive.google.com/uc?id=1T3VgMe-dCy5QVI7b1K2KdfL-2e2gq2Rn'\n",
        "}\n",
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "c_TFVhCROrkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "beVDRE2IOscX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_new_fig(fn, figsize=[9, 9]):\n",
        "    \"\"\" Init graphics \"\"\"\n",
        "    fig1 = plt.figure(fn, figsize)\n",
        "    ax1 = fig1.gca()  # Get Current Axis\n",
        "    ax1.cla()  # clear existing plot\n",
        "    return fig1, ax1\n",
        "\n",
        "\n",
        "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
        "    \"\"\"\n",
        "      config cell text and colors\n",
        "      and return text elements to add and to dell\n",
        "      @TODO: use fmt\n",
        "    \"\"\"\n",
        "    text_add = [];\n",
        "    text_del = [];\n",
        "    cell_val = array_df[lin][col]\n",
        "    tot_all = array_df[-1][-1]\n",
        "    per = (float(cell_val) / tot_all) * 100\n",
        "    curr_column = array_df[:, col]\n",
        "    ccl = len(curr_column)\n",
        "\n",
        "    # last line  and/or last column\n",
        "    if (col == (ccl - 1)) or (lin == (ccl - 1)):\n",
        "        # tots and percents\n",
        "        if (cell_val != 0):\n",
        "            if (col == ccl - 1) and (lin == ccl - 1):\n",
        "                tot_rig = 0\n",
        "                for i in range(array_df.shape[0] - 1):\n",
        "                    tot_rig += array_df[i][i]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif (col == ccl - 1):\n",
        "                tot_rig = array_df[lin][lin]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif (lin == ccl - 1):\n",
        "                tot_rig = array_df[col][col]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            per_err = 100 - per_ok\n",
        "        else:\n",
        "            per_ok = per_err = 0\n",
        "\n",
        "        per_ok_s = ['%.2f%%' % (per_ok), '100%'][per_ok == 100]\n",
        "\n",
        "        # text to DEL\n",
        "        text_del.append(oText)\n",
        "\n",
        "        # text to ADD\n",
        "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
        "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
        "        lis_txt = ['%d' % (cell_val), per_ok_s, '%.2f%%' % (per_err)]\n",
        "        lis_kwa = [text_kwargs]\n",
        "        dic = text_kwargs.copy();\n",
        "        dic['color'] = 'g';\n",
        "        lis_kwa.append(dic);\n",
        "        dic = text_kwargs.copy();\n",
        "        dic['color'] = 'r';\n",
        "        lis_kwa.append(dic);\n",
        "        lis_pos = [(oText._x, oText._y - 0.3), (oText._x, oText._y), (oText._x, oText._y + 0.3)]\n",
        "        for i in range(len(lis_txt)):\n",
        "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
        "            # print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
        "            text_add.append(newText)\n",
        "        # print '\\n'\n",
        "\n",
        "        # set background color for sum cells (last line and last column)\n",
        "        carr = [0.27, 0.30, 0.27, 1.0]\n",
        "        if (col == ccl - 1) and (lin == ccl - 1):\n",
        "            carr = [0.17, 0.20, 0.17, 1.0]\n",
        "        facecolors[posi] = carr\n",
        "\n",
        "    else:\n",
        "        if (per > 0):\n",
        "            txt = '%s\\n%.2f%%' % (cell_val, per)\n",
        "        else:\n",
        "            if (show_null_values == 0):\n",
        "                txt = ''\n",
        "            elif (show_null_values == 1):\n",
        "                txt = '0'\n",
        "            else:\n",
        "                txt = '0\\n0.0%'\n",
        "        oText.set_text(txt)\n",
        "\n",
        "        # main diagonal\n",
        "        if (col == lin):\n",
        "            # set color of the textin the diagonal to white\n",
        "            oText.set_color('w')\n",
        "            # set background color in the diagonal to blue\n",
        "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
        "        else:\n",
        "            oText.set_color('r')\n",
        "\n",
        "    return text_add, text_del\n",
        "\n",
        "\n",
        "def insert_totals(df_cm):\n",
        "    \"\"\" insert total column and line (the last ones) \"\"\"\n",
        "    sum_col = []\n",
        "    for c in df_cm.columns:\n",
        "        sum_col.append(df_cm[c].sum())\n",
        "    sum_lin = []\n",
        "    for item_line in df_cm.iterrows():\n",
        "        sum_lin.append(item_line[1].sum())\n",
        "    df_cm['sum_lin'] = sum_lin\n",
        "    sum_col.append(np.sum(sum_lin))\n",
        "    df_cm.loc['sum_col'] = sum_col\n",
        "\n",
        "\n",
        "def pretty_plot_confusion_matrix(df_cm, annot=True, cmap=\"Oranges\", fmt='.2f', fz=11,\n",
        "                                 lw=0.5, cbar=False, figsize=[8, 8], show_null_values=0, pred_val_axis='y'):\n",
        "    \"\"\"\n",
        "      print conf matrix with default layout (like matlab)\n",
        "      params:\n",
        "        df_cm          dataframe (pandas) without totals\n",
        "        annot          print text in each cell\n",
        "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
        "        fz             fontsize\n",
        "        lw             linewidth\n",
        "        pred_val_axis  where to show the prediction values (x or y axis)\n",
        "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
        "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
        "    \"\"\"\n",
        "    if (pred_val_axis in ('col', 'x')):\n",
        "        xlbl = 'Predicted'\n",
        "        ylbl = 'Actual'\n",
        "    else:\n",
        "        xlbl = 'Actual'\n",
        "        ylbl = 'Predicted'\n",
        "        df_cm = df_cm.T\n",
        "\n",
        "    # create \"Total\" column\n",
        "    insert_totals(df_cm)\n",
        "\n",
        "    # this is for print allways in the same window\n",
        "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
        "\n",
        "    # thanks for seaborn\n",
        "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
        "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
        "\n",
        "    # set ticklabels rotation\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation=25, fontsize=10)\n",
        "\n",
        "    # Turn off all the ticks\n",
        "    for t in ax.xaxis.get_major_ticks():\n",
        "        t.tick1On = False\n",
        "        t.tick2On = False\n",
        "    for t in ax.yaxis.get_major_ticks():\n",
        "        t.tick1On = False\n",
        "        t.tick2On = False\n",
        "\n",
        "    # face colors list\n",
        "    quadmesh = ax.findobj(QuadMesh)[0]\n",
        "    facecolors = quadmesh.get_facecolors()\n",
        "\n",
        "    # iter in text elements\n",
        "    array_df = np.array(df_cm.to_records(index=False).tolist())\n",
        "    text_add = [];\n",
        "    text_del = [];\n",
        "    posi = -1  # from left to right, bottom to top.\n",
        "    for t in ax.collections[0].axes.texts:  # ax.texts:\n",
        "        pos = np.array(t.get_position()) - [0.5, 0.5]\n",
        "        lin = int(pos[1]);\n",
        "        col = int(pos[0]);\n",
        "        posi += 1\n",
        "        # print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
        "\n",
        "        # set text\n",
        "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
        "\n",
        "        text_add.extend(txt_res[0])\n",
        "        text_del.extend(txt_res[1])\n",
        "\n",
        "    # remove the old ones\n",
        "    for item in text_del:\n",
        "        item.remove()\n",
        "    # append the new ones\n",
        "    for item in text_add:\n",
        "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
        "\n",
        "    # titles and legends\n",
        "    ax.set_title('Confusion matrix')\n",
        "    ax.set_xlabel(xlbl)\n",
        "    ax.set_ylabel(ylbl)\n",
        "    plt.tight_layout()  # set layout slim\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_from_data(y_test, predictions, columns=None, annot=True, cmap=\"Oranges\",\n",
        "                                    fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[8, 8], show_null_values=0,\n",
        "                                    pred_val_axis='lin'):\n",
        "    \"\"\"\n",
        "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
        "        whitout a confusion matrix yet\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from pandas import DataFrame\n",
        "\n",
        "    # data\n",
        "    if (not columns):\n",
        "        from string import ascii_uppercase\n",
        "        columns = ['class %s' % (i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
        "\n",
        "    confm = confusion_matrix(y_test, predictions)\n",
        "    cmap = 'Oranges';\n",
        "    fz = 11;\n",
        "    figsize = [9, 9];\n",
        "    show_null_values = 2\n",
        "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
        "    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values,\n",
        "                                 pred_val_axis=pred_val_axis)\n",
        "\n",
        "\n",
        "def fil_sent(sent):\n",
        "    \"\"\"\n",
        "    Filter stopwords\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_sentence = ' '.join([w for w in sent.split() if not w in stop_words])\n",
        "    return filtered_sentence\n",
        "\n",
        "\n",
        "def process(sent):\n",
        "    \"\"\"\n",
        "    Apply stemming\n",
        "    \"\"\"\n",
        "    sent = str(sent)\n",
        "    ps = PorterStemmer()\n",
        "    return fil_sent(' '.join([ps.stem(str(x).lower()) for x in word_tokenize(sent)]))\n",
        "\n",
        "\n",
        "def extract_style(text):\n",
        "    \"\"\"\n",
        "    Extracting stylometric features of a text\n",
        "    \"\"\"\n",
        "\n",
        "    text = str(text)\n",
        "    len_text = len(text)\n",
        "    len_words = len(text.split())\n",
        "    avg_len = np.mean([len(t) for t in text.split()])\n",
        "    num_short_w = len([t for t in text.split() if len(t) < 3])\n",
        "    per_digit = sum(t.isdigit() for t in text) / len(text)\n",
        "    per_cap = sum(1 for t in text if t.isupper()) / len(text)\n",
        "    f_a = sum(1 for t in text if t.lower() == \"a\") / len(text)\n",
        "    f_b = sum(1 for t in text if t.lower() == \"b\") / len(text)\n",
        "    f_c = sum(1 for t in text if t.lower() == \"c\") / len(text)\n",
        "    f_d = sum(1 for t in text if t.lower() == \"d\") / len(text)\n",
        "    f_e = sum(1 for t in text if t.lower() == \"e\") / len(text)\n",
        "    f_f = sum(1 for t in text if t.lower() == \"f\") / len(text)\n",
        "    f_g = sum(1 for t in text if t.lower() == \"g\") / len(text)\n",
        "    f_h = sum(1 for t in text if t.lower() == \"h\") / len(text)\n",
        "    f_i = sum(1 for t in text if t.lower() == \"i\") / len(text)\n",
        "    f_j = sum(1 for t in text if t.lower() == \"j\") / len(text)\n",
        "    f_k = sum(1 for t in text if t.lower() == \"k\") / len(text)\n",
        "    f_l = sum(1 for t in text if t.lower() == \"l\") / len(text)\n",
        "    f_m = sum(1 for t in text if t.lower() == \"m\") / len(text)\n",
        "    f_n = sum(1 for t in text if t.lower() == \"n\") / len(text)\n",
        "    f_o = sum(1 for t in text if t.lower() == \"o\") / len(text)\n",
        "    f_p = sum(1 for t in text if t.lower() == \"p\") / len(text)\n",
        "    f_q = sum(1 for t in text if t.lower() == \"q\") / len(text)\n",
        "    f_r = sum(1 for t in text if t.lower() == \"r\") / len(text)\n",
        "    f_s = sum(1 for t in text if t.lower() == \"s\") / len(text)\n",
        "    f_t = sum(1 for t in text if t.lower() == \"t\") / len(text)\n",
        "    f_u = sum(1 for t in text if t.lower() == \"u\") / len(text)\n",
        "    f_v = sum(1 for t in text if t.lower() == \"v\") / len(text)\n",
        "    f_w = sum(1 for t in text if t.lower() == \"w\") / len(text)\n",
        "    f_x = sum(1 for t in text if t.lower() == \"x\") / len(text)\n",
        "    f_y = sum(1 for t in text if t.lower() == \"y\") / len(text)\n",
        "    f_z = sum(1 for t in text if t.lower() == \"z\") / len(text)\n",
        "    f_1 = sum(1 for t in text if t.lower() == \"1\") / len(text)\n",
        "    f_2 = sum(1 for t in text if t.lower() == \"2\") / len(text)\n",
        "    f_3 = sum(1 for t in text if t.lower() == \"3\") / len(text)\n",
        "    f_4 = sum(1 for t in text if t.lower() == \"4\") / len(text)\n",
        "    f_5 = sum(1 for t in text if t.lower() == \"5\") / len(text)\n",
        "    f_6 = sum(1 for t in text if t.lower() == \"6\") / len(text)\n",
        "    f_7 = sum(1 for t in text if t.lower() == \"7\") / len(text)\n",
        "    f_8 = sum(1 for t in text if t.lower() == \"8\") / len(text)\n",
        "    f_9 = sum(1 for t in text if t.lower() == \"9\") / len(text)\n",
        "    f_0 = sum(1 for t in text if t.lower() == \"0\") / len(text)\n",
        "    f_e_0 = sum(1 for t in text if t.lower() == \"!\") / len(text)\n",
        "    f_e_1 = sum(1 for t in text if t.lower() == \"-\") / len(text)\n",
        "    f_e_2 = sum(1 for t in text if t.lower() == \":\") / len(text)\n",
        "    f_e_3 = sum(1 for t in text if t.lower() == \"?\") / len(text)\n",
        "    f_e_4 = sum(1 for t in text if t.lower() == \".\") / len(text)\n",
        "    f_e_5 = sum(1 for t in text if t.lower() == \",\") / len(text)\n",
        "    f_e_6 = sum(1 for t in text if t.lower() == \";\") / len(text)\n",
        "    f_e_7 = sum(1 for t in text if t.lower() == \"'\") / len(text)\n",
        "    f_e_8 = sum(1 for t in text if t.lower() == \"/\") / len(text)\n",
        "    f_e_9 = sum(1 for t in text if t.lower() == \"(\") / len(text)\n",
        "    f_e_10 = sum(1 for t in text if t.lower() == \")\") / len(text)\n",
        "    f_e_11 = sum(1 for t in text if t.lower() == \"&\") / len(text)\n",
        "    richness = len(list(set(text.split()))) / len(text.split())\n",
        "\n",
        "    return pd.Series(\n",
        "        [avg_len, len_text, len_words, num_short_w, per_digit, per_cap, f_a, f_b, f_c, f_d, f_e, f_f, f_g, f_h, f_i,\n",
        "         f_j, f_k, f_l, f_m, f_n, f_o, f_p, f_q, f_r, f_s, f_t, f_u, f_v, f_w, f_x, f_y, f_z, f_0, f_1, f_2, f_3,\n",
        "         f_4, f_5, f_6, f_7, f_8, f_9, f_e_0, f_e_1, f_e_2, f_e_3, f_e_4, f_e_5, f_e_6, f_e_7, f_e_8, f_e_9, f_e_10,\n",
        "         f_e_11, richness])\n",
        "\n",
        "\n",
        "def build_train_test(df, source, limit, per_author=None, seed=None):\n",
        "    # Select top N senders and build Train and Test\n",
        "    # list_spk = list(pd.DataFrame(df['From'].value_counts().iloc[:limit]).reset_index()['index'])\n",
        "    list_spk = list(pd.DataFrame(df['From'].value_counts().iloc[:limit]).reset_index().iloc[:, 0])\n",
        "    sub_df = df[df['From'].isin(list_spk)]\n",
        "\n",
        "    if per_author is not None:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    if source == 'turing':\n",
        "        sub_df = sub_df[\n",
        "            [\n",
        "                'From', 'content', 'content_tfidf', \"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\",\n",
        "                \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\",\n",
        "                \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\",\n",
        "                \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\",\n",
        "                \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\", \"train\"\n",
        "            ]\n",
        "        ]\n",
        "    else:\n",
        "        sub_df = sub_df[\n",
        "            [\n",
        "                'From', 'content', 'content_tfidf', \"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\",\n",
        "                \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\",\n",
        "                \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\",\n",
        "                \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\",\n",
        "                \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"\n",
        "            ]\n",
        "        ]\n",
        "    sub_df = sub_df.dropna()\n",
        "\n",
        "    print(\"Number of texts : \", len(sub_df))\n",
        "\n",
        "    dict_nlp_enron = {}\n",
        "    k = 0\n",
        "\n",
        "    for val in np.unique(sub_df.From):\n",
        "        dict_nlp_enron[val] = k\n",
        "        k += 1\n",
        "\n",
        "    sub_df['Target'] = sub_df['From'].apply(lambda x: dict_nlp_enron[x])\n",
        "\n",
        "    if source == 'turing':\n",
        "        perc = 0.5\n",
        "        print(\"Percentage: \" + str(perc))\n",
        "        full_train = sub_df[sub_df[\"train\"] == 1]\n",
        "        nlp_train = full_train[['content', 'Target']]\n",
        "\n",
        "        full_test = sub_df[sub_df[\"train\"] == 0]\n",
        "        test_dict = full_test[['content', 'Target']]\n",
        "\n",
        "        full_valid = sub_df[sub_df[\"train\"] == 2]\n",
        "        val_dict = full_valid[['content', 'Target']]\n",
        "\n",
        "        shrinked_train = nlp_train\n",
        "        shrinked_test = test_dict\n",
        "        shrinked_val = val_dict\n",
        "        for l in range(20):\n",
        "            part_train = nlp_train[nlp_train[\"Target\"] == l]\n",
        "            part_train = part_train[:int(len(part_train) * perc)]\n",
        "            part_test = test_dict[test_dict[\"Target\"] == l]\n",
        "            part_test = part_test[:int(len(part_test) * perc)]\n",
        "            part_val = val_dict[val_dict[\"Target\"] == l]\n",
        "            part_val = part_val[:int(len(part_val) * perc)]\n",
        "            if l == 0:\n",
        "                shrinked_train = part_train\n",
        "                shrinked_test = part_test\n",
        "                shrinked_val = part_val\n",
        "            else:\n",
        "                shrinked_train = pd.concat([shrinked_train, part_train], axis=0)\n",
        "                shrinked_test = pd.concat([shrinked_test, part_test], axis=0)\n",
        "                shrinked_val = pd.concat([shrinked_val, part_val], axis=0)\n",
        "\n",
        "        return shrinked_train, shrinked_test, shrinked_val\n",
        "\n",
        "    if 'blog' in source or 'imdb62' in source:\n",
        "        perc = 0.75\n",
        "        print(\"seed: \" + str(seed))\n",
        "\n",
        "        if seed is None:\n",
        "            seed = 0\n",
        "\n",
        "        ind = train_test_split(sub_df[['content', 'Target']], test_size=0.2, stratify=sub_df['Target'],\n",
        "                               random_state=seed)\n",
        "        ind_train = list(ind[0].index)\n",
        "        nlp_train = sub_df.loc[ind_train]\n",
        "\n",
        "        val_test_sub_df = ind[1]\n",
        "        ind2 = train_test_split(val_test_sub_df[['content', 'Target']], test_size=0.5,\n",
        "                                stratify=val_test_sub_df['Target'], random_state=seed)\n",
        "        ind_val = list(ind2[0].index)\n",
        "        ind_test = list(ind2[1].index)\n",
        "        val_dict = val_test_sub_df.loc[ind_val]\n",
        "        test_dict = val_test_sub_df.loc[ind_test]\n",
        "\n",
        "        if 'blog' in source:\n",
        "            shrinked_train = nlp_train\n",
        "            shrinked_test = test_dict\n",
        "            shrinked_val = val_dict\n",
        "            for l in range(50):\n",
        "                part_train = nlp_train[nlp_train[\"Target\"] == l]\n",
        "                part_train = part_train[:int(len(part_train) * perc)]\n",
        "                part_test = test_dict[test_dict[\"Target\"] == l]\n",
        "                part_test = part_test[:int(len(part_test) * perc)]\n",
        "                part_val = val_dict[val_dict[\"Target\"] == l]\n",
        "                part_val = part_val[:int(len(part_val) * perc)]\n",
        "                if l == 0:\n",
        "                    shrinked_train = part_train\n",
        "                    shrinked_test = part_test\n",
        "                    shrinked_val = part_val\n",
        "                else:\n",
        "                    shrinked_train = pd.concat([shrinked_train, part_train], axis=0)\n",
        "                    shrinked_test = pd.concat([shrinked_test, part_test], axis=0)\n",
        "                    shrinked_val = pd.concat([shrinked_val, part_val], axis=0)\n",
        "\n",
        "            return shrinked_train, shrinked_test, shrinked_val\n",
        "\n",
        "        return nlp_train, val_dict, test_dict\n",
        "\n",
        "    ind = train_test_split(sub_df[['content', 'Target']], test_size=0.2, stratify=sub_df['Target'], random_state=seed)\n",
        "    ind_train = list(ind[0].index)\n",
        "    ind_test = list(ind[1].index)\n",
        "    nlp_train = sub_df.loc[ind_train]\n",
        "    test_dict = sub_df.loc[ind_test]\n",
        "\n",
        "    return nlp_train, test_dict\n",
        "\n",
        "\n",
        "def is_name_in_email(name, email):\n",
        "    \"\"\"\n",
        "    Removing emails from Enron where name is in email\n",
        "    \"\"\"\n",
        "\n",
        "    if str(name).lower() in str(email).lower():\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def load_dataset_dataframe(source):\n",
        "    print(\"Loading and processing dataframe\")\n",
        "\n",
        "    # dataset_path = \"datasets\"\n",
        "    # dataset_file_name = {\n",
        "    #     \"imdb62\": 'full_imdb62.csv',\n",
        "    #     \"blog\": 'full_blog.csv',\n",
        "    #     \"turing\": \"turing_ori_0208.csv\"\n",
        "    # }\n",
        "\n",
        "    df = None\n",
        "    if source == \"imdb62\":\n",
        "        df = pd.read_csv(os.path.join(dataset_path, dataset_file_name[source]), index_col=0)\n",
        "    elif source == \"blog\":\n",
        "        df = pd.read_csv(os.path.join(dataset_path, dataset_file_name[source]))\n",
        "    elif source == 'diffusiondb':\n",
        "        df = pd.read_csv(os.path.join(dataset_path, dataset_file_name[source]))\n",
        "        df = df[['prompt', 'user_name']]\n",
        "        df.columns = ['content', 'Target']\n",
        "    else:\n",
        "        df = pd.read_csv(os.path.join(dataset_path, dataset_file_name[source]))\n",
        "        df.sort_values(by=['train', 'From'], inplace=True, ascending=[False, True])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def save_model(ckpt_dir, cp_name, model):\n",
        "    \"\"\"\n",
        "    Create directory /Checkpoint under exp_data_path and save encoder as cp_name\n",
        "    \"\"\"\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    saving_model_path = os.path.join(ckpt_dir, cp_name)\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        model = model.module  # convert to non-parallel form\n",
        "    torch.save(model.state_dict(), saving_model_path)\n",
        "    print(f'Model saved: {saving_model_path}')\n",
        "\n",
        "\n",
        "def load_model_dic(model, ckpt_path, verbose=True, strict=True):\n",
        "    \"\"\"\n",
        "    Load weights to model and take care of weight parallelism\n",
        "    \"\"\"\n",
        "    assert os.path.exists(ckpt_path), f\"trained model {ckpt_path} does not exist\"\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(ckpt_path), strict=strict)\n",
        "    except:\n",
        "        state_dict = torch.load(ckpt_path)\n",
        "        state_dict = {k.partition('module.')[2]: state_dict[k] for k in state_dict.keys()}\n",
        "        model.load_state_dict(state_dict, strict=strict)\n",
        "    if verbose:\n",
        "        print(f'Model loaded: {ckpt_path}')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "t0k0jD_jOtGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset"
      ],
      "metadata": {
        "id": "j8LWMiCdOuUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertDataset(Dataset):\n",
        "    def __init__(self, x, y, tokenizer, length=128, return_idx=False):\n",
        "        super(BertDataset, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.length = length\n",
        "        self.x = x\n",
        "        self.return_idx = return_idx\n",
        "        self.y = torch.tensor(y)\n",
        "        self.tokens_cache = {}\n",
        "\n",
        "    def tokenize(self, x):\n",
        "        dic = self.tokenizer.batch_encode_plus(\n",
        "            [x],  # input must be a list\n",
        "            max_length=self.length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return [x[0] for x in dic.values()]  # get rid of the first dim\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        int_idx = int(idx)\n",
        "        assert idx == int_idx\n",
        "        idx = int_idx\n",
        "        if idx not in self.tokens_cache:\n",
        "            self.tokens_cache[idx] = self.tokenize(self.x[idx])\n",
        "        input_ids, token_type_ids, attention_mask = self.tokens_cache[idx]\n",
        "        if self.return_idx:\n",
        "            return input_ids, token_type_ids, attention_mask, self.y[idx], idx, self.x[idx]\n",
        "        return input_ids, token_type_ids, attention_mask, self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "\n",
        "class TrainSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size, sim_ratio=0.5):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.sim_ratio = sim_ratio\n",
        "        self.num_pos_samples = int(batch_size * sim_ratio)\n",
        "        print(f'train sampler with batch size = {batch_size} and postive sample ratio = {sim_ratio}')\n",
        "\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "\n",
        "        assert len(label_cluster[0]) > self.num_pos_samples, \\\n",
        "            f\"only {len(label_cluster[0])} samples in each class, but {self.num_pos_samples} pos samples needed\"\n",
        "\n",
        "        # too time-consuming, i.e., O(|D||C|/|B|)s\n",
        "        batch_indices = []\n",
        "        flag = True\n",
        "        while flag:\n",
        "            # find a valid positive sample class\n",
        "            available_classes = list(filter(lambda x: len(label_cluster[x]) >= self.num_pos_samples,\n",
        "                                            list(range(max(self.y) + 1))))\n",
        "            if len(available_classes) == 0:\n",
        "                break\n",
        "            class_count = random.choice(available_classes)\n",
        "\n",
        "            # fill in positive samples\n",
        "            batch_indices.append(label_cluster[class_count][-self.num_pos_samples:])\n",
        "            del label_cluster[class_count][-self.num_pos_samples:]\n",
        "\n",
        "            # fill in negative samples\n",
        "            for i in range(self.batch_size - self.num_pos_samples):\n",
        "                available_classes = list(filter(lambda x: len(label_cluster[x]) > 0, list(range(max(self.y) + 1))))\n",
        "                if class_count in available_classes:\n",
        "                    available_classes.remove(class_count)\n",
        "                if len(available_classes) == 0:\n",
        "                    flag = False\n",
        "                    break\n",
        "                rand_class = random.choice(available_classes)\n",
        "                batch_indices[-1].append(label_cluster[rand_class].pop())\n",
        "\n",
        "            random.shuffle(batch_indices[-1])\n",
        "\n",
        "        random.shuffle(batch_indices)\n",
        "        all = sum(batch_indices, [])\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class TrainSamplerMultiClass(Sampler):\n",
        "    def __init__(self, dataset, batch_size, num_classes, samples_per_author):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.num_classes = num_classes\n",
        "        self.samples_per_author = samples_per_author\n",
        "        assert batch_size // num_classes * num_classes == batch_size, \\\n",
        "            f'batch size {batch_size} is not a multiple of num of classes {num_classes}'\n",
        "        print(f'train sampler with batch size = {batch_size} and {num_classes} classes in a batch')\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "\n",
        "        assert len(label_cluster) > self.num_classes, \\\n",
        "            f'number of available classes {label_cluster} < required classes {self.num_classes}'\n",
        "\n",
        "        num_samples_per_class_batch = self.batch_size // self.num_classes\n",
        "        min_class_samples = min([len(x) for x in label_cluster.values()])\n",
        "        assert min_class_samples > self.samples_per_author, \\\n",
        "            f\"expected {self.samples_per_author} per author, but got {min_class_samples} in the dataset\"\n",
        "        class_samples_needed = self.samples_per_author // num_samples_per_class_batch * num_samples_per_class_batch\n",
        "\n",
        "        dataset_matrix = []\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "            # value = [key] * len(value)    # debugging use\n",
        "            dataset_matrix.append(torch.tensor(value[:class_samples_needed]).view(num_samples_per_class_batch, -1))\n",
        "\n",
        "        tuples = torch.cat(dataset_matrix, dim=1).transpose(1, 0).split(1, dim=0)\n",
        "        tuples = [x.flatten().tolist() for x in tuples]\n",
        "        random.shuffle(tuples)\n",
        "        all = sum(tuples, [])\n",
        "\n",
        "        print(f'from dataset sampler: batch size {self.batch_size}, num of classes in a batch {self.num_classes}, '\n",
        "              f'num of samples per author in total {self.samples_per_author} (specified) / {class_samples_needed} (true).'\n",
        "              f'dataset size {len(all)}')\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class TrainSamplerMultiClassUnit(Sampler):\n",
        "    def __init__(self, dataset, sample_unit_size):\n",
        "        super().__init__(None)\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.sample_unit_size = sample_unit_size\n",
        "        print(f'train sampler with sample unit size {sample_unit_size}')\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "\n",
        "        dataset_matrix = []\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "            num_valid_samples = len(value) // self.sample_unit_size * self.sample_unit_size\n",
        "            dataset_matrix.append(torch.tensor(value[:num_valid_samples]).view(self.sample_unit_size, -1))\n",
        "\n",
        "        tuples = torch.cat(dataset_matrix, dim=1).transpose(1, 0).split(1, dim=0)\n",
        "        tuples = [x.flatten().tolist() for x in tuples]\n",
        "        random.shuffle(tuples)\n",
        "        all = sum(tuples, [])\n",
        "\n",
        "        print(f'from dataset sampler: original dataset size {len(self.y)}, resampled dataset size {len(all)}. '\n",
        "              f'sample unit size {self.sample_unit_size}')\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n"
      ],
      "metadata": {
        "id": "Xbvz1mreOvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loss"
      ],
      "metadata": {
        "id": "PIvPwwTXOw6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "\n",
        "class lcl_contrastiveAA(nn.Module):\n",
        "    def __init__(self, temperature=0.1, margin=0.2):\n",
        "        \"\"\"\n",
        "        Implementation of the loss described in the paper Supervised Contrastive Learning :\n",
        "        https://arxiv.org/abs/2004.11362\n",
        "        :param temperature: int\n",
        "        \"\"\"\n",
        "        super(lcl_contrastiveAA, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, projections, targets, W):\n",
        "        \"\"\"\n",
        "        :param projections: torch.Tensor, shape [batch_size, projection_dim]\n",
        "        :param targets: torch.Tensor, shape [batch_size]\n",
        "        :return: torch.Tensor, scalar\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\") if projections.is_cuda else torch.device(\"cpu\")\n",
        "\n",
        "        W = F.softmax(W,dim=1)\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        # dot_product_tempered = torch.mm(projections, projections.T) / self.temperature\n",
        "        # The cosine similarity between all pairs of projection vectors is computed\n",
        "        dot_product_tempered = self.cos(projections.unsqueeze(1), projections.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        # Compute softmax probabilities over all pairs (positive and negative)\n",
        "        # Minus max for numerical stability with exponential. Same done in cross entropy. Epsilon added to avoid log(0)\n",
        "        exp_dot_tempered = (\n",
        "            torch.exp(dot_product_tempered - torch.max(dot_product_tempered, dim=1, keepdim=True)[0]) + 1e-5\n",
        "        )\n",
        "\n",
        "        index = targets.view(1, -1).repeat(projections.size(0), 1)\n",
        "        # Gather the weights w_{i,y_k} where y_k is the class of sample x_k\n",
        "        weights_i_yk = W.gather(1, index)\n",
        "        # Compute the weighted exponential of tempered dot products\n",
        "        exp_dot_tempered = weights_i_yk * torch.exp(dot_product_tempered)\n",
        "\n",
        "        # Identify positive pairs for each anchor sample\n",
        "        # This mask identifies pairs of samples that belong to the same class\n",
        "        mask_similar_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) == targets).to(device)\n",
        "        # This mask removes the self-similarity (diagonal elements)\n",
        "        mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0])).to(device)\n",
        "        # This is the combined mask that identifies positive pairs (i.e., samples that belong to the same class but are not the same sample)\n",
        "        mask_combined_pos = mask_similar_class * mask_anchor_out\n",
        "\n",
        "        mask_diff_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) != targets).to(device)\n",
        "        mask_combined_neg = mask_diff_class * mask_anchor_out\n",
        "\n",
        "        # exp_sum = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
        "        # probabilities = exp_dot_tempered / (exp_sum + 1e-5)\n",
        "\n",
        "        # Compute number of relevant positive samples for each anchor sample\n",
        "        cardinality_pos = torch.sum(mask_combined_pos, dim=1)\n",
        "\n",
        "        # to avoid nan value of the loss if there is only one sample of a category  on the batch\n",
        "        # Ensures that if there's only one sample of a class (i.e., no positive pairs), the division by zero is avoided by setting the count to 1\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        # # Compute log probability of positive pairs\n",
        "        # log_prob = -torch.log(exp_dot_tempered / (torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)))\n",
        "        # supervised_contrastive_loss_per_sample = torch.sum(log_prob * mask_combined_pos, dim=1) / cardinality_pos\n",
        "        # supervised_contrastive_loss = torch.mean(supervised_contrastive_loss_per_sample)\n",
        "\n",
        "        # Sum of the exponentiated similarities for the negative pairs\n",
        "        exp_sum_neg = torch.sum(exp_dot_tempered * mask_combined_neg, dim=1)\n",
        "        # print(exp_sum_neg.shape)\n",
        "        # prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg + 1e-5)\n",
        "        prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg.view(-1, 1) + 1e-5)\n",
        "\n",
        "        log_prob = -torch.log(prob) * mask_combined_pos\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        total_loss = torch.mean(torch.sum(log_prob, dim=1) / cardinality_pos)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class LCL(nn.Module):\n",
        "\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super(LCL, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "\n",
        "    def forward(self, features, labels=None, weights=None,mask=None):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            A loss scalar.\n",
        "        \"\"\"\n",
        "        device = (torch.device('cuda')\n",
        "                  if features.is_cuda\n",
        "                  else torch.device('cpu'))\n",
        "\n",
        "        batch_size = features.shape[0]\n",
        "        weights = F.softmax(weights,dim=1)\n",
        "        # print(weights)\n",
        "\n",
        "        if labels is not None and mask is not None:\n",
        "            raise ValueError('Cannot define both `labels` and `mask`')\n",
        "        elif labels is None and mask is None:\n",
        "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
        "        elif labels is not None:\n",
        "            labels = labels.contiguous().view(-1, 1)\n",
        "            if labels.shape[0] != batch_size:\n",
        "                raise ValueError('Num of labels does not match num of features')\n",
        "            mask = torch.eq(labels, labels.T).float().to(device)\n",
        "        else:\n",
        "            mask = mask.float().to(device)\n",
        "\n",
        "        contrast_feature = features\n",
        "        anchor_feature = contrast_feature\n",
        "        anchor_count = 2\n",
        "\n",
        "        # compute logits\n",
        "        # anchor_dot_contrast = torch.div(\n",
        "        #     torch.matmul(anchor_feature, contrast_feature.T),\n",
        "        #     self.temperature)\n",
        "        anchor_dot_contrast = self.cos(features.unsqueeze(1), features.unsqueeze(0)) / self.temperature\n",
        "        # print('anchor_do_contrast', anchor_dot_contrast)\n",
        "        logits_mask = torch.scatter(\n",
        "            torch.ones_like(mask),\n",
        "            1,\n",
        "            torch.arange(batch_size).view(-1, 1).to(device),\n",
        "            0\n",
        "        )\n",
        "\n",
        "        ## it produces 0 for the non-matching places and 1 for matching places and neg mask does the opposite\n",
        "        mask = mask * logits_mask\n",
        "        # print('mask', mask)\n",
        "        # print('logits_mask', logits_mask)\n",
        "\n",
        "        weighted_mask = torch.zeros_like(logits_mask).float().to(device)\n",
        "\n",
        "\n",
        "        for i,val in enumerate(labels):\n",
        "            for j,jval in enumerate(labels):\n",
        "                weighted_mask[i,j] = weights[i,jval]\n",
        "\n",
        "        weighted_mask = weighted_mask * logits_mask\n",
        "        pos_weighted_mask = weighted_mask * mask\n",
        "        # print(weighted_mask)\n",
        "\n",
        "        # compute log_prob with logsumexp\n",
        "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
        "\n",
        "        logits = anchor_dot_contrast - logits_max.detach()\n",
        "        # print('logits', logits)\n",
        "\n",
        "        exp_logits = torch.exp(logits) * weighted_mask\n",
        "        # print('exp_logits', exp_logits)\n",
        "        ## log_prob = x - max(x1,..,xn) - logsumexp(x1,..,xn) the equation\n",
        "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "        # print('log_prob', log_prob)\n",
        "        # compute mean of log-likelihood over positive\n",
        "        mean_log_prob_pos = (pos_weighted_mask * log_prob).sum(1) / mask.sum(1)\n",
        "        # print('mean_log_prob_pos', mean_log_prob_pos)\n",
        "        # loss\n",
        "        loss = -1 * mean_log_prob_pos\n",
        "        # loss = loss.view(anchor_count, batch_size).mean()\n",
        "        loss = loss.mean()\n",
        "        # print(loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class SupConLoss_contrastiveAA(nn.Module):\n",
        "    def __init__(self, temperature=0.1, margin=0.2):\n",
        "        \"\"\"\n",
        "        Implementation of the loss described in the paper Supervised Contrastive Learning :\n",
        "        https://arxiv.org/abs/2004.11362\n",
        "        :param temperature: int\n",
        "        \"\"\"\n",
        "        super(SupConLoss_contrastiveAA, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, projections, targets):\n",
        "        \"\"\"\n",
        "        :param projections: torch.Tensor, shape [batch_size, projection_dim]\n",
        "        :param targets: torch.Tensor, shape [batch_size]\n",
        "        :return: torch.Tensor, scalar\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\") if projections.is_cuda else torch.device(\"cpu\")\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        # dot_product_tempered = torch.mm(projections, projections.T) / self.temperature\n",
        "        # The cosine similarity between all pairs of projection vectors is computed\n",
        "        dot_product_tempered = self.cos(projections.unsqueeze(1), projections.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        # Compute softmax probabilities over all pairs (positive and negative)\n",
        "        # Minus max for numerical stability with exponential. Same done in cross entropy. Epsilon added to avoid log(0)\n",
        "        exp_dot_tempered = (\n",
        "            torch.exp(dot_product_tempered - torch.max(dot_product_tempered, dim=1, keepdim=True)[0]) + 1e-5\n",
        "        )\n",
        "        # Identify positive pairs for each anchor sample\n",
        "        # This mask identifies pairs of samples that belong to the same class\n",
        "        mask_similar_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) == targets).to(device)\n",
        "        # This mask removes the self-similarity (diagonal elements)\n",
        "        mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0])).to(device)\n",
        "        # This is the combined mask that identifies positive pairs (i.e., samples that belong to the same class but are not the same sample)\n",
        "        mask_combined_pos = mask_similar_class * mask_anchor_out\n",
        "\n",
        "        mask_diff_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) != targets).to(device)\n",
        "        mask_combined_neg = mask_diff_class * mask_anchor_out\n",
        "\n",
        "        # exp_sum = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
        "        # probabilities = exp_dot_tempered / (exp_sum + 1e-5)\n",
        "\n",
        "        # Compute number of relevant positive samples for each anchor sample\n",
        "        cardinality_pos = torch.sum(mask_combined_pos, dim=1)\n",
        "\n",
        "        # to avoid nan value of the loss if there is only one sample of a category  on the batch\n",
        "        # Ensures that if there's only one sample of a class (i.e., no positive pairs), the division by zero is avoided by setting the count to 1\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        # # Compute log probability of positive pairs\n",
        "        # log_prob = -torch.log(exp_dot_tempered / (torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)))\n",
        "        # supervised_contrastive_loss_per_sample = torch.sum(log_prob * mask_combined_pos, dim=1) / cardinality_pos\n",
        "        # supervised_contrastive_loss = torch.mean(supervised_contrastive_loss_per_sample)\n",
        "\n",
        "        # Sum of the exponentiated similarities for the negative pairs\n",
        "        exp_sum_neg = torch.sum(exp_dot_tempered * mask_combined_neg, dim=1)\n",
        "        # print(exp_sum_neg.shape)\n",
        "        # prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg + 1e-5)\n",
        "        prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg.view(-1, 1) + 1e-5)\n",
        "        # prob = exp_dot_tempered / (exp_sum_neg.view(-1, 1) + 1e-5)\n",
        "\n",
        "        log_prob = -torch.log(prob) * mask_combined_pos\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        total_loss = torch.mean(torch.sum(log_prob, dim=1) / cardinality_pos)\n",
        "\n",
        "        return total_loss"
      ],
      "metadata": {
        "id": "7oMjO3Z5Ox0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "aUfxSUb0O4UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0):\n",
        "        super().__init__()\n",
        "        print(f'Logistic Regression classifier of dim ({in_dim} {hid_dim} {out_dim})')\n",
        "\n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(in_dim, hid_dim, bias=True),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hid_dim, out_dim, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        out = self.nn(x)\n",
        "        if return_feat:\n",
        "            return out, x\n",
        "        return out\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    FEAT_LEN = 768\n",
        "\n",
        "    def __init__(self, raw_bert, classifier):\n",
        "        super().__init__()\n",
        "        self.bert = raw_bert\n",
        "        self.fc = classifier\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        # x is a tokenized input\n",
        "        # feature = self.bert(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
        "        feature = self.bert(input_ids=x[0], attention_mask=x[2])\n",
        "        # out = self.fc(feature.pooler_output.flatten(1))       # not good for our task     # (BS, E)\n",
        "        out = self.fc(feature.last_hidden_state.flatten(1))  # (BS, T, E)\n",
        "        if return_feat:\n",
        "            return out, feature.last_hidden_state.flatten(1)\n",
        "        return out\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BertClassiferHyperparams:\n",
        "    mlp_size: int\n",
        "    token_len: int\n",
        "    embed_len: int\n",
        "\n",
        "\n",
        "class weighting_network(nn.Module):\n",
        "\n",
        "    def __init__(self,batch_size,hidden_size,emotion_size,encoder_type=\"electra\"):\n",
        "        super(weighting_network, self).__init__()\n",
        "\n",
        "        if encoder_type == \"electra\":\n",
        "            options_name = \"google/electra-base-discriminator\"\n",
        "            self.encoder_supcon_2 = ElectraForSequenceClassification.from_pretrained(options_name,num_labels=emotion_size)\n",
        "\n",
        "            ## to make it faster\n",
        "            self.encoder_supcon_2.electra.encoder.config.gradient_checkpointing=True\n",
        "        elif 'bert' in encoder_type:\n",
        "            options_name = encoder_type\n",
        "            self.encoder_supcon_2 = BertForSequenceClassification.from_pretrained(options_name,num_labels=emotion_size)\n",
        "\n",
        "            ## to make it faster\n",
        "            self.encoder_supcon_2.bert.encoder.config.gradient_checkpointing=True\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        supcon_fea_2 = self.encoder_supcon_2(x[0], x[2], output_hidden_states=True,return_dict=True)\n",
        "\n",
        "        return supcon_fea_2.logits\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5bQ_M9MjO3ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "I4TH8wMgPNAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert(train_dict, test_dic, tqdm_on, model_name, embed_len, id, num_epochs, base_bs, base_lr,\n",
        "               mask_classes, coefficient, coefficient1, num_authors, val_dic=None):\n",
        "    print(f'mask classes = {mask_classes}')\n",
        "\n",
        "    # tokenizer and pretrained model\n",
        "    tokenizer, extractor = None, None\n",
        "    if 'albert' in model_name:\n",
        "        from transformers import AlbertTokenizer, AlbertModel\n",
        "        tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "        extractor = AlbertModel.from_pretrained(model_name)\n",
        "    elif 'bert-base' in model_name:\n",
        "        from transformers import BertTokenizer, BertModel\n",
        "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        extractor = BertModel.from_pretrained(model_name)\n",
        "    elif 'deberta' in model_name:\n",
        "        from transformers import DebertaTokenizer, DebertaModel\n",
        "        tokenizer = DebertaTokenizer.from_pretrained(model_name)\n",
        "        extractor = DebertaModel.from_pretrained(model_name)\n",
        "    elif 'roberta' in model_name:\n",
        "        from transformers import RobertaTokenizer, RobertaModel\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "        extractor = RobertaModel.from_pretrained(model_name)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(f\"model {model_name} not implemented\")\n",
        "\n",
        "    # update extractor\n",
        "    for param in extractor.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # get dataset\n",
        "    train_x, train_y = train_dict['content'].tolist(), train_dict['Target'].tolist()\n",
        "    test_x, test_y = test_dic['content'].tolist(), test_dic['Target'].tolist()\n",
        "\n",
        "    if val_dic is not None:\n",
        "        val_x, val_y = val_dic['content'].tolist(), val_dic['Target'].tolist()\n",
        "\n",
        "    # training config\n",
        "    ngpus, dropout = torch.cuda.device_count(), 0.35\n",
        "    num_tokens, hidden_dim, out_dim = 256, 512, num_authors\n",
        "    model = BertClassifier(extractor, LogisticRegression(embed_len * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "\n",
        "    # model_helper = weighting_network(base_bs, hidden_dim, num_authors, model_name)\n",
        "    model_helper = BertClassifier(extractor, LogisticRegression(embed_len * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "    model_helper = nn.DataParallel(model_helper).cuda()\n",
        "\n",
        "    total_params = list(model.named_parameters()) + list(model_helper.named_parameters())\n",
        "    # no_decay = ['bias', 'LayerNorm.weight']\n",
        "    no_decay = []\n",
        "    optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in total_params if not any(nd in n for nd in no_decay)], 'weight_decay': 3e-4},\n",
        "    {'params': [p for n, p in total_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "    num_training_steps = int(len(train_x) * num_epochs)\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=base_lr * ngpus)\n",
        "\n",
        "    # optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=base_lr * ngpus)\n",
        "\n",
        "\n",
        "    # optimizer = torch.optim.AdamW(params=model.parameters(), lr=base_lr * ngpus, weight_decay=3e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    # scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "\n",
        "    train_set = BertDataset(train_x, train_y, tokenizer, num_tokens)\n",
        "    test_set = BertDataset(test_x, test_y, tokenizer, num_tokens)\n",
        "\n",
        "    if val_dic is not None:\n",
        "        val_set = BertDataset(val_x, val_y, tokenizer, num_tokens)\n",
        "\n",
        "    temperature, sample_unit_size = 0.1, 2\n",
        "    print(f'coefficient, temperature, sample_unit_size = {coefficient, temperature, sample_unit_size}')\n",
        "\n",
        "    # logger\n",
        "    exp_dir = os.path.join(ckpt_dir,\n",
        "                           f'{id}_{model_name.split(\"/\")[-1]}_coe{coefficient}_temp{temperature}_unit{sample_unit_size}_epoch{num_epochs}')\n",
        "    writer = SummaryWriter(os.path.join(exp_dir, 'board'))\n",
        "\n",
        "    # load data\n",
        "    train_sampler = TrainSamplerMultiClassUnit(train_set, sample_unit_size=sample_unit_size)\n",
        "    train_loader = DataLoader(train_set, batch_size=base_bs * ngpus, sampler=train_sampler, shuffle=False,\n",
        "                              num_workers=4 * ngpus, pin_memory=True, drop_last=False)\n",
        "    # train_loader = DataLoader(train_set, batch_size=base_bs * ngpus, shuffle=True,\n",
        "    #                           num_workers=4 * ngpus, pin_memory=True, drop_last=False)\n",
        "    test_loader = DataLoader(test_set, batch_size=base_bs * ngpus, shuffle=False, num_workers=4 * ngpus,\n",
        "                             pin_memory=True, drop_last=False)\n",
        "\n",
        "    if val_dic is not None:\n",
        "        val_loader = DataLoader(val_set, batch_size=base_bs * ngpus, shuffle=False, num_workers=4 * ngpus,\n",
        "                                pin_memory=True, drop_last=False)\n",
        "\n",
        "    final_test_acc = None\n",
        "    final_train_preds, final_test_preds = [], []\n",
        "    best_acc = -1\n",
        "    best_tv_acc = -1\n",
        "    # lcl = lcl_contrastiveAA()\n",
        "    supcon = SupConLoss_contrastiveAA()\n",
        "    lcl = LCL()\n",
        "    # supcon = losses.SupConLoss()\n",
        "    # miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
        "\n",
        "    # training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_acc = AverageMeter()\n",
        "        train_loss = AverageMeter()\n",
        "        train_loss_1 = AverageMeter()\n",
        "        train_loss_2 = AverageMeter()\n",
        "        train_loss_3 = AverageMeter()\n",
        "        train_loss_4 = AverageMeter()\n",
        "        train_acc_helper = AverageMeter()\n",
        "\n",
        "        # decay coefficient\n",
        "        # coefficient = coefficient - 1 / num_epochs\n",
        "\n",
        "        # training\n",
        "        model.train()\n",
        "        model_helper.train()\n",
        "\n",
        "        pg = tqdm(train_loader, leave=False, total=len(train_loader), disable=not tqdm_on)\n",
        "        for i, (x1, x2, x3, y) in enumerate(pg):  # for x1, x2, x3, y in train_set:\n",
        "            y1 = torch.tensor(list(set(y.tolist()))).cuda()\n",
        "            x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "            pred, feats = model(x, return_feat=True)\n",
        "            pred1 = model_helper(x)\n",
        "            # print(pred.shape) # batch_size * num_author\n",
        "            # print(feats.shape) # batch_size * (max_length * hidden_dim)\n",
        "            # print(y1)\n",
        "            # print(pred)\n",
        "            # print(feats)\n",
        "            # print(pred1)\n",
        "            # print(y)\n",
        "            # print()\n",
        "\n",
        "            # classification loss\n",
        "            loss_1 = criterion(pred, y.long())\n",
        "\n",
        "            # generate the mask\n",
        "            mask = y.clone().cpu().apply_(lambda x: x not in mask_classes).type(torch.bool).cuda()\n",
        "            feats, pred, y = feats[mask], pred[mask], y[mask]\n",
        "            if len(y) == 0:\n",
        "                continue\n",
        "\n",
        "            # contrastive learning\n",
        "\n",
        "            loss_2 = lcl(feats, y.long(), pred1)\n",
        "            loss_3 = supcon(feats, y.long())\n",
        "            loss_4 = criterion(pred1, y.long())\n",
        "\n",
        "            # total loss\n",
        "            loss = loss_1 + coefficient * loss_2 + coefficient1 * loss_3 + loss_4\n",
        "            # loss = loss_1 + coefficient1 * loss_3\n",
        "            # loss = loss_2\n",
        "            # loss = loss_1\n",
        "\n",
        "            acc = (pred.argmax(1) == y).sum().item() / len(y)\n",
        "            train_acc.update(acc)\n",
        "            train_loss.update(loss.item())\n",
        "            train_loss_1.update(loss_1.item())\n",
        "            train_loss_2.update(loss_2.item())\n",
        "\n",
        "            acc_helper = (pred1.argmax(1) == y).sum().item() / len(y)\n",
        "            train_acc_helper.update(acc_helper)\n",
        "            train_loss_3.update(loss_3.item())\n",
        "            train_loss_4.update(loss_4.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            model.zero_grad()\n",
        "            model_helper.zero_grad()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pg.set_postfix({\n",
        "                'train acc': '{:.6f}'.format(train_acc.avg),\n",
        "                'train acc helper': '{:.6f}'.format(train_acc_helper.avg),\n",
        "                'train L1': '{:.6f}'.format(train_loss_1.avg),\n",
        "                'train L2': '{:.6f}'.format(train_loss_2.avg),\n",
        "                'train L3': '{:.6f}'.format(train_loss_3.avg),\n",
        "                'train L4': '{:.6f}'.format(train_loss_4.avg),\n",
        "                'train L': '{:.6f}'.format(train_loss.avg),\n",
        "                'epoch': '{:03d}'.format(epoch)\n",
        "            })\n",
        "\n",
        "            # iteration logger\n",
        "            step = i + epoch * len(pg)\n",
        "            writer.add_scalar(\"train-iteration/L1\", loss_1.item(), step)\n",
        "            writer.add_scalar(\"train-iteration/L2\", loss_2.item(), step)\n",
        "            writer.add_scalar(\"train-iteration/L3\", loss_3.item(), step)\n",
        "            writer.add_scalar(\"train-iteration/L4\", loss_4.item(), step)\n",
        "            writer.add_scalar(\"train-iteration/L\", loss.item(), step)\n",
        "            writer.add_scalar(\"train-iteration/acc\", acc, step)\n",
        "            writer.add_scalar(\"train-iteration/acc_helper\", acc_helper, step)\n",
        "\n",
        "        print('train acc: {:.6f}'.format(train_acc.avg), 'train acc helper: {:.6f}'.format(train_acc_helper.avg),\n",
        "              'train L1 {:.6f}'.format(train_loss_1.avg), 'train L2 {:.6f}'.format(train_loss_2.avg),\n",
        "              'train L3 {:.6f}'.format(train_loss_3.avg), 'train L4 {:.6f}'.format(train_loss_3.avg),\n",
        "              'train L {:.6f}'.format(train_loss.avg), f'epoch {epoch}')\n",
        "\n",
        "        # epoch logger\n",
        "        writer.add_scalar(\"train/L1\", train_loss_1.avg, epoch)\n",
        "        writer.add_scalar(\"train/L2\", train_loss_2.avg, epoch)\n",
        "        writer.add_scalar(\"train/L3\", train_loss_3.avg, epoch)\n",
        "        writer.add_scalar(\"train/L4\", train_loss_4.avg, epoch)\n",
        "        writer.add_scalar(\"train/L\", train_loss.avg, epoch)\n",
        "        writer.add_scalar(\"train/acc\", train_acc.avg, epoch)\n",
        "        writer.add_scalar(\"train/acc_helper\", train_acc_helper.avg, epoch)\n",
        "\n",
        "        # validation\n",
        "        if val_dic is not None:\n",
        "            model.eval()\n",
        "            model_helper.eval()\n",
        "            pg = tqdm(val_loader, leave=False, total=len(val_loader), disable=not tqdm_on)\n",
        "            with torch.no_grad():\n",
        "                tv_acc = AverageMeter()  # tv stands for train_val\n",
        "                tv_acc_helper = AverageMeter()\n",
        "                tv_loss_1 = AverageMeter()\n",
        "                tv_loss_2 = AverageMeter()\n",
        "                tv_loss_3 = AverageMeter()\n",
        "                tv_loss = AverageMeter()\n",
        "                for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "                    x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "                    pred, feats = model(x, return_feat=True)\n",
        "                    pred1 = model_helper(x)\n",
        "\n",
        "                    # classification\n",
        "                    loss_1 = criterion(pred, y.long())\n",
        "\n",
        "                    loss_2 = lcl(feats, y.long(), pred1)\n",
        "                    loss_3 = supcon(feats, y.long())\n",
        "                    loss_4 = criterion(pred1, y.long())\n",
        "\n",
        "                    # total loss\n",
        "                    loss = loss_1 + coefficient * loss_2 + coefficient1 * loss_3 + loss_4\n",
        "                    # loss = loss_1 + coefficient1 * loss_3\n",
        "\n",
        "                    # # total loss\n",
        "                    # loss = loss_1 + coefficient * loss_2 + coefficient1 * loss_3\n",
        "                    # loss = loss_1\n",
        "\n",
        "                    # logger\n",
        "                    tv_acc.update((pred.argmax(1) == y).sum().item() / len(y))\n",
        "                    tv_acc_helper.update((pred1.argmax(1) == y).sum().item() / len(y))\n",
        "                    # test_acc.update(\n",
        "                    #     f1_score(y.cpu().detach().numpy(), pred.argmax(1).cpu().detach().numpy(), average='macro'))\n",
        "                    tv_loss.update(loss.item())\n",
        "                    tv_loss_1.update(loss_1.item())\n",
        "                    tv_loss_2.update(loss_2.item())\n",
        "                    tv_loss_3.update(loss_3.item())\n",
        "\n",
        "                    pg.set_postfix({\n",
        "                        'train_val acc': '{:.6f}'.format(tv_acc.avg),\n",
        "                        'train_val acc helper': '{:.6f}'.format(tv_acc_helper.avg),\n",
        "                        'epoch': '{:03d}'.format(epoch)\n",
        "                    })\n",
        "\n",
        "        # testing\n",
        "        model.eval()\n",
        "        model_helper.eval()\n",
        "        pg = tqdm(test_loader, leave=False, total=len(test_loader), disable=not tqdm_on)\n",
        "        with torch.no_grad():\n",
        "            test_acc = AverageMeter()\n",
        "            test_acc_helper = AverageMeter()\n",
        "            test_loss_1 = AverageMeter()\n",
        "            test_loss_2 = AverageMeter()\n",
        "            test_loss_3 = AverageMeter()\n",
        "            test_loss = AverageMeter()\n",
        "            for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "                x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "                pred, feats = model(x, return_feat=True)\n",
        "                pred1 = model_helper(x)\n",
        "\n",
        "                # classification\n",
        "                loss_1 = criterion(pred, y.long())\n",
        "\n",
        "                loss_2 = lcl(feats, y.long(), pred1)\n",
        "                loss_3 = supcon(feats, y.long())\n",
        "                loss_4 = criterion(pred1, y.long())\n",
        "\n",
        "                # total loss\n",
        "                loss = loss_1 + coefficient * loss_2 + coefficient1 * loss_3 + loss_4\n",
        "                # loss = loss_1 + coefficient1 * loss_3\n",
        "                # loss = loss_2\n",
        "                # loss = loss_1\n",
        "\n",
        "                # logger\n",
        "                test_acc.update((pred.argmax(1) == y).sum().item() / len(y))\n",
        "                test_acc_helper.update((pred1.argmax(1) == y).sum().item() / len(y))\n",
        "                # test_acc.update(\n",
        "                #     f1_score(y.cpu().detach().numpy(), pred.argmax(1).cpu().detach().numpy(), average='macro'))\n",
        "                test_loss.update(loss.item())\n",
        "                test_loss_1.update(loss_1.item())\n",
        "                test_loss_2.update(loss_2.item())\n",
        "                test_loss_3.update(loss_3.item())\n",
        "\n",
        "                pg.set_postfix({\n",
        "                    'test acc': '{:.6f}'.format(test_acc.avg),\n",
        "                    'test acc helper': '{:.6f}'.format(test_acc_helper.avg),\n",
        "                    'epoch': '{:03d}'.format(epoch)\n",
        "                })\n",
        "\n",
        "        # logging\n",
        "        if val_dic is not None:\n",
        "            writer.add_scalar(\"tv/L1\", tv_loss_1.avg, epoch)\n",
        "            writer.add_scalar(\"tv/L2\", tv_loss_2.avg, epoch)\n",
        "            writer.add_scalar(\"tv/L3\", tv_loss_3.avg, epoch)\n",
        "            writer.add_scalar(\"tv/L\", tv_loss.avg, epoch)\n",
        "            writer.add_scalar(\"tv/acc\", tv_acc.avg, epoch)\n",
        "            writer.add_scalar(\"tv/acc_helper\", tv_acc_helper.avg, epoch)\n",
        "\n",
        "        writer.add_scalar(\"test/L1\", test_loss_1.avg, epoch)\n",
        "        writer.add_scalar(\"test/L2\", test_loss_2.avg, epoch)\n",
        "        writer.add_scalar(\"test/L3\", test_loss_3.avg, epoch)\n",
        "        writer.add_scalar(\"test/L\", test_loss.avg, epoch)\n",
        "        writer.add_scalar(\"test/acc\", test_acc.avg, epoch)\n",
        "        writer.add_scalar(\"test/acc_helper\", test_acc_helper.avg, epoch)\n",
        "\n",
        "        # scheduler.step(test_loss.avg)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'epoch {epoch}, train acc {train_acc.avg}, test acc {test_acc.avg}')\n",
        "\n",
        "        final_test_acc = test_acc.avg\n",
        "\n",
        "        # save model\n",
        "        if tv_acc.avg:\n",
        "            if tv_acc.avg >= best_acc:\n",
        "                cur_models = os.listdir(exp_dir)\n",
        "                for cur_model in cur_models:\n",
        "                    if cur_model.endswith(\".pt\"):\n",
        "                        os.remove(os.path.join(exp_dir, cur_model))\n",
        "                save_model(exp_dir, f'{id}_val{final_test_acc:.5f}_e{epoch}.pt', model)\n",
        "        best_acc = max(best_acc, tv_acc.avg)\n",
        "\n",
        "        if val_dic is not None:\n",
        "            print(f'epoch {epoch}, train val acc {tv_acc.avg}')\n",
        "            final_tv_acc = tv_acc.avg\n",
        "            best_tv_acc = max(best_tv_acc, tv_acc.avg)\n",
        "\n",
        "    # save checkpoint\n",
        "    save_model(exp_dir, f'{id}_val{final_test_acc:.5f}_finale{epoch}.pt', model)\n",
        "\n",
        "    print(\n",
        "        f'Training complete after {num_epochs} epochs. Final val acc = {final_tv_acc}, '\n",
        "        f'best val acc = {best_tv_acc}, best test acc = {best_acc}.'\n",
        "        f'Final test acc {final_test_acc}')\n",
        "\n",
        "    return final_test_acc, final_train_preds, final_test_preds"
      ],
      "metadata": {
        "id": "u4kCxvVlPOPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main"
      ],
      "metadata": {
        "id": "orqycYwBPQdf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EVoYLxaPcWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_para_40',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    df = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    def split_author_data(author_data):\n",
        "        # Split into two parts\n",
        "        df_20 = author_data.iloc[:40]\n",
        "        return df_20\n",
        "\n",
        "    grouped = df_shuffled.groupby('user_name')\n",
        "\n",
        "    # Create two new DataFrames by concatenating the splits\n",
        "    nlp_train = pd.concat([split_author_data(group) for name, group in grouped])\n",
        "\n",
        "    nlp_train.to_csv('/content/drive/MyDrive/msc_project/data/twitter_micro/processed/train_random40_label_1.csv', index=False)\n",
        "\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "OH3iLdW85hSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_para_20',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    df = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    def split_author_data(author_data):\n",
        "        # Split into two parts\n",
        "        df_20 = author_data.iloc[:20]\n",
        "        return df_20\n",
        "\n",
        "    grouped = df_shuffled.groupby('user_name')\n",
        "\n",
        "    # Create two new DataFrames by concatenating the splits\n",
        "    nlp_train = pd.concat([split_author_data(group) for name, group in grouped])\n",
        "\n",
        "    nlp_train.to_csv('/content/drive/MyDrive/msc_project/data/twitter_micro/processed/train_random20_label_1.csv', index=False)\n",
        "\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "MZ-dF24duh0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_cls_para',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'albert-base-v2',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "CemiygcZdbD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_cls_para',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'roberta-base',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "EQHkozVQLj4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb', 'blogs50']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "        'blogs50': 50\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'imdb62',\n",
        "      '--id', 'imdb62_cls',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '62',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "        'blogs50': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/imdb62/processed/imdb62_train.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/imdb62/processed/imdb62_AA_val.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/imdb62/processed/imdb62_AA_test.csv')\n",
        "    print(nlp_train.columns)\n",
        "    nlp_train = nlp_train[['text', 'author_id']]\n",
        "    # nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['text', 'author_id']]\n",
        "    # nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['text', 'author_id']]\n",
        "    # nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "    # print(nlp_train['Target'])\n",
        "\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "yvBlgvuOO2eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb', 'blogs50']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "        'blogs50': 50\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'blogs50',\n",
        "      '--id', 'blogs50_cls',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '50',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "        'blogs50': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_train.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_val.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_test.csv')\n",
        "    nlp_train = nlp_train[['text', 'author_id']]\n",
        "    # nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['text', 'author_id']]\n",
        "    # nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['text', 'author_id']]\n",
        "    # nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "    # print(nlp_train['Target'])\n",
        "    # print(nlp_train.columns)\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "4WFmiAM54w1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_supcon_coe1_para_topic',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_topicseparate100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_topicseparate100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_topicseparate100_label_1.csv')\n",
        "    # nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    # nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    # nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "    # print(nlp_train['Target'])\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "MGAxcdEa1xFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_coe1_para_topic',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_topicseparate100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_topicseparate100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_topicseparate100_label_1.csv')\n",
        "    # nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    # nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    # nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "    # print(nlp_train['Target'])\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "w0dtlWxHegm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_coe1_para',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "AaV28IzkVKEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_para',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '1',\n",
        "      '--coe1', '0.5'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "yk8NWcY-PQ8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change coefficients\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    datasets = ['imdb62', 'blog', 'turing', 'diffusiondb']\n",
        "    parser = argparse.ArgumentParser(description=f'Training models for datasets {datasets}')\n",
        "    parser.add_argument('--dataset', type=str, help='dataset used for training', choices=datasets)\n",
        "    parser.add_argument('--id', type=str, default='0', help='experiment id')\n",
        "    parser.add_argument('--gpu', type=str, help='the cuda devices used for training', default=\"0,1,2,3\")\n",
        "    parser.add_argument('--tqdm', type=bool, help='whether tqdm is on', default=False)\n",
        "    parser.add_argument('--authors', type=int, help='number of authors', default=None)\n",
        "    parser.add_argument('--samples-per-auth', type=int, help='number of samples per author', default=None)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--model', type=str, default='microsoft/deberta-base')\n",
        "    parser.add_argument('--coe', type=float, default=1)\n",
        "    parser.add_argument('--coe1', type=float, default=1)\n",
        "\n",
        "    # dataset - num of authors mapping\n",
        "    default_num_authors = {\n",
        "        'imdb62': 62,\n",
        "        'blog': 50,\n",
        "        'turing': 20,\n",
        "        'diffusiondb': 100,\n",
        "    }\n",
        "\n",
        "    training_args = [\n",
        "      '--dataset', 'diffusiondb',\n",
        "      '--id', 'diffusiondb100_lcl_coe2_para',\n",
        "      '--gpu', '0',\n",
        "      '--tqdm', 'True',\n",
        "      '--authors', '100',\n",
        "      '--epochs', '30',\n",
        "      '--model', 'bert-base-cased',\n",
        "      '--coe', '2',\n",
        "      '--coe1', '1'\n",
        "    ]\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args(training_args)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    source = args.dataset\n",
        "    num_authors = args.authors if args.authors is not None else default_num_authors[args.dataset]\n",
        "    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))  # print all args\n",
        "\n",
        "    # masked classes\n",
        "    mask_classes = {\n",
        "        'blog': [],\n",
        "        'imdb62': [],\n",
        "        'turing': [],\n",
        "        'diffusiondb': [],\n",
        "    }\n",
        "\n",
        "    # load data and remove emails containing the sender's name\n",
        "    # df = load_dataset_dataframe(source)\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    if args.authors is not default_num_authors[args.dataset]:\n",
        "        warnings.warn(f\"Number of authors for dataset {args.dataset} is {default_num_authors[args.dataset]}, \"\n",
        "                      f\"but got {args.authors} instead. \")\n",
        "\n",
        "    if args.samples_per_auth is not None:\n",
        "        warnings.warn(f\"Number of samples per author specified as {args.samples_per_auth}, which is a \"\n",
        "                      f\"dangerous argument. \")\n",
        "\n",
        "    limit = num_authors\n",
        "    print(\"Number of authors: \", limit)\n",
        "\n",
        "    # select top N senders and build train and test\n",
        "    # nlp_train, nlp_val, nlp_test = build_train_test(df, source, limit, per_author=args.samples_per_auth, seed=0)\n",
        "\n",
        "    # train\n",
        "    if 'enron' in source or 'imdb62' in source or 'blog' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=8, base_lr=1e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    elif 'turing' in source:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=7, base_lr=5e-6,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)\n",
        "    else:\n",
        "        train_bert(nlp_train, nlp_test, args.tqdm, args.model, 768, args.id, args.epochs, base_bs=24, base_lr=2e-5,\n",
        "                   mask_classes=mask_classes[args.dataset], coefficient=args.coe, coefficient1=args.coe1, num_authors=num_authors,\n",
        "                   val_dic=nlp_val)"
      ],
      "metadata": {
        "id": "-p8l3ADR2G9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPogNfVtd1yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# crucial analysis"
      ],
      "metadata": {
        "id": "IJWUk1v6SCI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lda"
      ],
      "metadata": {
        "id": "5qkKPt6WTTox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_str(string):\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\d+\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip()\n",
        "\n",
        "def load_diffusiondb(data):\n",
        "    # load data (can be used if data already split into train and test set)\n",
        "    x = data['prompt'].tolist()\n",
        "    X = []\n",
        "    for i in range(len(x)):\n",
        "        X.append(clean_str(x[i]))\n",
        "    return X\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lda\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/final_llama3.csv')\n",
        "print(df.columns)\n",
        "\n",
        "X = []\n",
        "X = load_diffusiondb(df)\n",
        "tf_vectorizer = CountVectorizer(max_df=0.99, min_df=1, stop_words='english')\n",
        "X_tf = tf_vectorizer.fit_transform(X)\n",
        "print(f'vocabulary', len(tf_vectorizer.vocabulary_))\n",
        "\n",
        "lda_model = lda.LDA(n_topics=50, n_iter=1000, random_state=1000)\n",
        "lda_model.fit(X_tf)\n",
        "doc_topic = lda_model.doc_topic_\n",
        "\n",
        "df['topic'] = np.argmax(doc_topic, axis=1)\n",
        "\n",
        "topic_word = lda_model.topic_word_\n",
        "vocab = tf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the top words for each topic\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(10+1):-1]\n",
        "    print(f\"Topic {i}: {' '.join(topic_words)}\")\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume df is your DataFrame with columns 'user_name', 'prompt', and 'topic'\n",
        "\n",
        "# Step 1: Create a pivot table\n",
        "pivot_table = df.pivot_table(index='topic', columns='user_name', aggfunc='size', fill_value=0)\n",
        "\n",
        "# Step 2: Plot the heatmap\n",
        "plt.figure(figsize=(20, 10))  # Adjust the size as necessary\n",
        "sns.heatmap(pivot_table, cmap=\"YlGnBu\", annot=True, fmt=\"d\", linewidths=.5)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Number of Prompts per Author for Each Topic')\n",
        "plt.xlabel('Authors')\n",
        "plt.ylabel('Topics')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RReMuZxpSDsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Assume df is your DataFrame with columns 'user_name', 'prompt', and 'topic'\n",
        "\n",
        "# Step 1: Initialize lists for train, validation, and test sets\n",
        "train_data = []\n",
        "val_data = []\n",
        "test_data = []\n",
        "\n",
        "# Step 2: Process each author\n",
        "for user_name, group in df.groupby('user_name'):\n",
        "    # Group the user's prompts by topic\n",
        "    topics = defaultdict(list)\n",
        "    for _, row in group.iterrows():\n",
        "        topics[row['topic']].append(row)\n",
        "\n",
        "    # Convert the grouped topics to a list of (topic, prompts) tuples\n",
        "    topics_list = list(topics.items())\n",
        "    random.shuffle(topics_list)  # Shuffle to introduce randomness\n",
        "\n",
        "    # Determine the number of prompts required for each split\n",
        "    num_train = int(0.6 * 100)\n",
        "    num_val = int(0.2 * 100)\n",
        "    num_test = int(0.2 * 100)  # This is 20\n",
        "\n",
        "    train_prompts = []\n",
        "    test_prompts = []\n",
        "    val_prompts = []\n",
        "\n",
        "    # Allocate prompts while enforcing the correct split sizes\n",
        "    for topic, prompts in topics_list:\n",
        "        if len(train_prompts) < num_train:\n",
        "            train_prompts.extend(prompts)\n",
        "            if len(train_prompts) > num_train:\n",
        "                excess = len(train_prompts) - num_train\n",
        "                val_prompts.extend(train_prompts[-excess:])\n",
        "                train_prompts = train_prompts[:-excess]\n",
        "            continue\n",
        "\n",
        "        if len(test_prompts) < num_test:\n",
        "            test_prompts.extend(prompts)\n",
        "            if len(test_prompts) > num_test:\n",
        "                excess = len(test_prompts) - num_test\n",
        "                val_prompts.extend(test_prompts[-excess:])\n",
        "                test_prompts = test_prompts[:-excess]\n",
        "            continue\n",
        "\n",
        "        val_prompts.extend(prompts)\n",
        "\n",
        "    # If test prompts are less than 20, move from validation set ensuring no topic overlap with train set\n",
        "    if len(test_prompts) < num_test:\n",
        "        required = num_test - len(test_prompts)\n",
        "        additional_test_prompts = [p for p in val_prompts if p['topic'] not in set([tp['topic'] for tp in train_prompts])]\n",
        "\n",
        "        if len(additional_test_prompts) >= required:\n",
        "            test_prompts.extend(additional_test_prompts[:required])\n",
        "            val_prompts = [p for p in val_prompts if p not in additional_test_prompts[:required]]\n",
        "        else:\n",
        "            # If there are not enough prompts with different topics, move what we can and log the issue\n",
        "            test_prompts.extend(additional_test_prompts)\n",
        "            val_prompts = [p for p in val_prompts if p not in additional_test_prompts]\n",
        "\n",
        "    # If still underfilled, move prompts from val to test without checking topic overlap\n",
        "    if len(test_prompts) < num_test:\n",
        "        required = num_test - len(test_prompts)\n",
        "        test_prompts.extend(val_prompts[:required])\n",
        "        val_prompts = val_prompts[required:]\n",
        "\n",
        "    # Step 3: Add the prompts to the respective datasets\n",
        "    train_data.extend(train_prompts)\n",
        "    val_data.extend(val_prompts)\n",
        "    test_data.extend(test_prompts)\n",
        "\n",
        "# Step 4: Convert lists back to DataFrames\n",
        "train_df = pd.DataFrame(train_data, columns=df.columns)\n",
        "val_df = pd.DataFrame(val_data, columns=df.columns)\n",
        "test_df = pd.DataFrame(test_data, columns=df.columns)\n",
        "\n",
        "# Verify the sizes\n",
        "print(f\"Train set: {len(train_df)} prompts\")\n",
        "print(f\"Validation set: {len(val_df)} prompts\")\n",
        "print(f\"Test set: {len(test_df)} prompts\")\n",
        "\n",
        "# Now, train_df, val_df, and test_df contain the split data with the desired properties, including the 'user_name' column\n"
      ],
      "metadata": {
        "id": "ipCJspCxTGzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_topicseparate100_1.csv', index=False)\n",
        "val_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_topicseparate100_1.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_topicseparate100_1.csv', index=False)"
      ],
      "metadata": {
        "id": "fswGXyGeWFiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Fit the LabelEncoder on the entire dataset\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply the encoder to each DataFrame\n",
        "train_df['user_label'] = label_encoder.fit_transform(train_df['user_name'])\n",
        "val_df['user_label'] = label_encoder.transform(val_df['user_name'])\n",
        "test_df['user_label'] = label_encoder.transform(test_df['user_name'])\n",
        "joblib.dump(label_encoder, '/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/label_encoder_topicseparate100_1.pkl')\n",
        "train_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_topicseparate100_label_1.csv', index=False)\n",
        "val_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_topicseparate100_label_1.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_topicseparate100_label_1.csv', index=False)"
      ],
      "metadata": {
        "id": "Bpqu0q-PeBxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df"
      ],
      "metadata": {
        "id": "mpB83aSeXktf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "BJN8Wwz5Xpgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OjT2cqdGXqrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4r8pAnIZXtMG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}