{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80IVcS8sid8x"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z3Oq20G8kxl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFQy2y0of5TW"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric, DatasetDict\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.cuda\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.parallel import DataParallel\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    EncoderDecoderModel,\n",
        "    BertGenerationDecoder,\n",
        "    BertGenerationEncoder,\n",
        "    BertTokenizer,\n",
        "    BertModel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDo3Yzv0fjRD"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl1a-WMMfktW"
      },
      "outputs": [],
      "source": [
        "def get_dataset(data_files):\n",
        "    loaded_dataset = load_dataset(\"json\", data_files=data_files)\n",
        "\n",
        "    train_dataset = loaded_dataset['train']\n",
        "    test_dataset = loaded_dataset['test']\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def get_samples(data_files, len_train_sample=100, len_test_sample=100):\n",
        "    train_dataset, test_dataset = get_dataset(data_files)\n",
        "\n",
        "    train_dataset_sample = train_dataset.shuffle().select(range(len_train_sample))\n",
        "    test_dataset_sample = test_dataset.shuffle().select(range(len_test_sample))\n",
        "\n",
        "    return train_dataset_sample, test_dataset_sample\n",
        "\n",
        "def get_csv_dataset(data_file):\n",
        "    dataset = load_dataset(\"csv\", data_files=data_file)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_random(dataset):\n",
        "    sampled_sentences = {}\n",
        "\n",
        "    for data in dataset:\n",
        "        label = data['label']\n",
        "        sentence = data['sentence1']\n",
        "\n",
        "        if label in sampled_sentences:\n",
        "            sampled_sentences[label].append(sentence)\n",
        "        else:\n",
        "            sampled_sentences[label] = [sentence]\n",
        "\n",
        "    final_sampled_sentences = {}\n",
        "    for label, sentences in sampled_sentences.items():\n",
        "        # Randomly sample 200 sentences for each label\n",
        "        sampled = random.sample(sentences, k=min(200, len(sentences)))\n",
        "        final_sampled_sentences[label] = sampled\n",
        "    return final_sampled_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2_1RL7Il6Ld"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBKXRp4Yl7cI"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class BertDataset(Dataset):\n",
        "    def __init__(self, x, y, tokenizer, length=128, return_idx=False):\n",
        "        super(BertDataset, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.length = length\n",
        "        self.x = x\n",
        "        self.return_idx = return_idx\n",
        "        self.y = torch.tensor(y)\n",
        "        self.tokens_cache = {}\n",
        "\n",
        "    def mask_nouns(self, text):\n",
        "        doc = nlp(text)\n",
        "\n",
        "        masked_text = ' '.join(['[MASK]' if token.pos_ in ['NOUN'] else token.text for token in doc])\n",
        "        return masked_text\n",
        "\n",
        "    def tokenize(self, x):\n",
        "        # x = self.mask_nouns(x)\n",
        "        # print(x)\n",
        "        dic = self.tokenizer.batch_encode_plus(\n",
        "            [x],  # input must be a list\n",
        "            max_length=self.length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        # print([x[0] for x in dic.values()])\n",
        "        return [x[0] for x in dic.values()]  # get rid of the first dim\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        int_idx = int(idx)\n",
        "        assert idx == int_idx\n",
        "        idx = int_idx\n",
        "        if idx not in self.tokens_cache:\n",
        "            self.tokens_cache[idx] = self.tokenize(self.x[idx])\n",
        "        input_ids, token_type_ids, attention_mask = self.tokens_cache[idx]\n",
        "        if self.return_idx:\n",
        "            return input_ids, token_type_ids, attention_mask, self.y[idx], idx, self.x[idx]\n",
        "        return input_ids, token_type_ids, attention_mask, self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "class TrainSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size, sim_ratio=0.5):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.sim_ratio = sim_ratio\n",
        "        self.num_pos_samples = int(batch_size * sim_ratio)\n",
        "        print(f'train sampler with batch size = {batch_size} and postive sample ratio = {sim_ratio}')\n",
        "\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "\n",
        "        assert len(label_cluster[0]) > self.num_pos_samples, \\\n",
        "            f\"only {len(label_cluster[0])} samples in each class, but {self.num_pos_samples} pos samples needed\"\n",
        "\n",
        "        # too time-consuming, i.e., O(|D||C|/|B|)s\n",
        "        batch_indices = []\n",
        "        flag = True\n",
        "        while flag:\n",
        "            # find a valid positive sample class\n",
        "            available_classes = list(filter(lambda x: len(label_cluster[x]) >= self.num_pos_samples,\n",
        "                                            list(range(max(self.y) + 1))))\n",
        "            if len(available_classes) == 0:\n",
        "                break\n",
        "            class_count = random.choice(available_classes)\n",
        "\n",
        "            # fill in positive samples\n",
        "            batch_indices.append(label_cluster[class_count][-self.num_pos_samples:])\n",
        "            del label_cluster[class_count][-self.num_pos_samples:]\n",
        "\n",
        "            # fill in negative samples\n",
        "            for i in range(self.batch_size - self.num_pos_samples):\n",
        "                available_classes = list(filter(lambda x: len(label_cluster[x]) > 0, list(range(max(self.y) + 1))))\n",
        "                if class_count in available_classes:\n",
        "                    available_classes.remove(class_count)\n",
        "                if len(available_classes) == 0:\n",
        "                    flag = False\n",
        "                    break\n",
        "                rand_class = random.choice(available_classes)\n",
        "                batch_indices[-1].append(label_cluster[rand_class].pop())\n",
        "\n",
        "            random.shuffle(batch_indices[-1])\n",
        "\n",
        "        random.shuffle(batch_indices)\n",
        "        all = sum(batch_indices, [])\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class TrainSamplerMultiClass(Sampler):\n",
        "    def __init__(self, dataset, batch_size, num_classes, samples_per_author):\n",
        "        super().__init__(None)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.num_classes = num_classes\n",
        "        self.samples_per_author = samples_per_author\n",
        "        assert batch_size // num_classes * num_classes == batch_size, \\\n",
        "            f'batch size {batch_size} is not a multiple of num of classes {num_classes}'\n",
        "        print(f'train sampler with batch size = {batch_size} and {num_classes} classes in a batch')\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "\n",
        "        assert len(label_cluster) > self.num_classes, \\\n",
        "            f'number of available classes {label_cluster} < required classes {self.num_classes}'\n",
        "\n",
        "        num_samples_per_class_batch = self.batch_size // self.num_classes\n",
        "        min_class_samples = min([len(x) for x in label_cluster.values()])\n",
        "        assert min_class_samples > self.samples_per_author, \\\n",
        "            f\"expected {self.samples_per_author} per author, but got {min_class_samples} in the dataset\"\n",
        "        class_samples_needed = self.samples_per_author // num_samples_per_class_batch * num_samples_per_class_batch\n",
        "\n",
        "        dataset_matrix = []\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "            # value = [key] * len(value)    # debugging use\n",
        "            dataset_matrix.append(torch.tensor(value[:class_samples_needed]).view(num_samples_per_class_batch, -1))\n",
        "\n",
        "        tuples = torch.cat(dataset_matrix, dim=1).transpose(1, 0).split(1, dim=0)\n",
        "        tuples = [x.flatten().tolist() for x in tuples]\n",
        "        random.shuffle(tuples)\n",
        "        all = sum(tuples, [])\n",
        "\n",
        "        print(f'from dataset sampler: batch size {self.batch_size}, num of classes in a batch {self.num_classes}, '\n",
        "              f'num of samples per author in total {self.samples_per_author} (specified) / {class_samples_needed} (true).'\n",
        "              f'dataset size {len(all)}')\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class TrainSamplerMultiClassUnit(Sampler):\n",
        "    def __init__(self, dataset, sample_unit_size):\n",
        "        super().__init__(None)\n",
        "        self.x = dataset.x\n",
        "        self.y = dataset.y\n",
        "        self.sample_unit_size = sample_unit_size\n",
        "        print(f'train sampler with sample unit size {sample_unit_size}')\n",
        "        self.length = len(list(self.__iter__()))\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(range(len(self.y)))\n",
        "        label_cluster = {}\n",
        "        for i in indices:\n",
        "            label = self.y[i].item()\n",
        "            if label not in label_cluster:\n",
        "                label_cluster[label] = []\n",
        "            label_cluster[label].append(i)\n",
        "\n",
        "        dataset_matrix = []\n",
        "        for key, value in label_cluster.items():\n",
        "            random.shuffle(value)\n",
        "            num_valid_samples = len(value) // self.sample_unit_size * self.sample_unit_size\n",
        "            dataset_matrix.append(torch.tensor(value[:num_valid_samples]).view(self.sample_unit_size, -1))\n",
        "\n",
        "        tuples = torch.cat(dataset_matrix, dim=1).transpose(1, 0).split(1, dim=0)\n",
        "        tuples = [x.flatten().tolist() for x in tuples]\n",
        "        random.shuffle(tuples)\n",
        "        all = sum(tuples, [])\n",
        "\n",
        "        print(f'from dataset sampler: original dataset size {len(self.y)}, resampled dataset size {len(all)}. '\n",
        "              f'sample unit size {self.sample_unit_size}')\n",
        "\n",
        "        return iter(all)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ffl9OqrzdBg"
      },
      "source": [
        "# util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-laORBNzexV"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rzqadQ4fmoS"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyZuh7IjkSd0"
      },
      "outputs": [],
      "source": [
        "# def train_step(self, train_data):\n",
        "#         results = {}\n",
        "\n",
        "#         self.content_encoder.encoder.to(self.device)\n",
        "#         self.style_encoder.model.to(self.device)\n",
        "\n",
        "#         tokenized_content_data = self.content_encoder.prepare_data(train_data)\n",
        "#         tokenized_style_data = self.style_encoder.prepare_data(train_data)\n",
        "\n",
        "#         content_trainloader = DataLoader(tokenized_content_data, batch_size=self.batch_size, shuffle=True)\n",
        "#         style_trainloader = DataLoader(tokenized_style_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "#         # Training Loop\n",
        "#         for epoch in range(self.num_epochs):\n",
        "#             self.content_encoder.encoder.train()\n",
        "#             self.style_encoder.model.train()\n",
        "#             total_loss = 0\n",
        "\n",
        "#             for i in range(self.num_iters):\n",
        "#                 for batch1, batch2 in zip(content_trainloader, style_trainloader):\n",
        "#                     content_embedding = self.content_encoder.get_content_embeddings(batch1).to(self.device)\n",
        "#                     style_embedding = self.style_encoder.get_style(batch2).to(self.device)\n",
        "\n",
        "#                     mi_estimator = CLUB(content_embedding, style_embedding, hidden_size=self.hidden_size).to(self.device)\n",
        "#                     mi_estimator.eval()\n",
        "#                     sampler_loss = mi_estimator(content_embedding, style_embedding)\n",
        "\n",
        "#                     self.content_opt.zero_grad()\n",
        "#                     self.style_opt.zero_grad()\n",
        "\n",
        "#                     sampler_loss.backward()\n",
        "\n",
        "#                     self.content_opt.step()\n",
        "#                     self.style_opt.step()\n",
        "\n",
        "#                 for j in range(5):\n",
        "#                     mi_estimator.train()\n",
        "#                     for batch1, batch2 in zip(content_trainloader, style_trainloader):\n",
        "#                         content_embedding = self.content_encoder.get_content_embeddings(batch1)\n",
        "#                         style_embedding = self.style_encoder.get_style(batch2)\n",
        "\n",
        "#                         mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "#                         mi_loss = torch.mean(mi_loss)\n",
        "\n",
        "#                         mi_optimizer.zero_grad()\n",
        "#                         mi_loss.backward()\n",
        "#                         mi_optimizer.step()\n",
        "\n",
        "#                 mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "#                 mi_loss = torch.mean(mi_loss)\n",
        "\n",
        "#                 if i % 50 == 0:\n",
        "#                     print(f\"Step {i+1} - Loss: {mi_loss:.4f}\")\n",
        "\n",
        "#                 loss = mi_loss.cpu().detach().numpy().tolist()\n",
        "#                 results[\"step {}\".format(i)] = loss\n",
        "\n",
        "#             mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "#             mi_loss = torch.mean(mi_loss)\n",
        "#             total_loss += mi_loss\n",
        "\n",
        "#         average_loss = total_loss / len(content_trainloader)\n",
        "#         results[\"EPOCH {}:\".format(i)] = average_loss\n",
        "#         print(f\"Epoch {epoch+1}/{self.num_epochs} - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "#         with open('/content/drive/MyDrive/msc_project/model/contrastive/club/mi_loss_step.json', 'w') as json_file:\n",
        "#             json.dump(results, json_file, indent=4)\n",
        "#         return results\n",
        "\n",
        "#     def train_batch(self, train_data, test_data):\n",
        "#         results = {}\n",
        "\n",
        "#         self.content_encoder.encoder.to(self.device)\n",
        "#         self.style_encoder.model.to(self.device)\n",
        "\n",
        "#         tokenized_content_data = self.content_encoder.prepare_data(train_data)\n",
        "#         tokenized_style_data = self.style_encoder.prepare_data(train_data)\n",
        "\n",
        "#         content_trainloader = DataLoader(tokenized_content_data, batch_size=self.batch_size, shuffle=True)\n",
        "#         style_trainloader = DataLoader(tokenized_style_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "#         sample_dim = 768\n",
        "#         # mi_estimator = CLUB(content_embedding, style_embedding, hidden_size=self.hidden_size).to(self.device)\n",
        "#         mi_estimator = CLUB(sample_dim, sample_dim, self.hidden_size).cuda()\n",
        "#         mi_optimizer = torch.optim.Adam(mi_estimator.parameters(), lr=self.lr)\n",
        "\n",
        "#         epoch_losses = []\n",
        "#         # Training Loop\n",
        "#         for epoch in range(self.num_epochs):\n",
        "#             print('epoch', epoch)\n",
        "#             self.content_encoder.encoder.train()\n",
        "#             self.style_encoder.model.train()\n",
        "\n",
        "#             iter_losses = []\n",
        "#             tqdm_iter = tqdm(range(self.num_iters), desc=\"Iterations\", leave=False, total=self.num_iters)\n",
        "\n",
        "#             for i in tqdm_iter:\n",
        "#                 # print('iterations', i)\n",
        "#                 iter_loss = 0\n",
        "#                 count = 0\n",
        "#                 sampler_loss_all = 0\n",
        "#                 for batch1, batch2 in zip(content_trainloader, style_trainloader):\n",
        "#                     if count % 50 == 0:\n",
        "#                         print('count', count)\n",
        "#                         if count != 0:\n",
        "#                           print(f'sampler loss {sampler_loss_all / count}')\n",
        "#                     count += 1\n",
        "#                     # 32 * 512 * 768\n",
        "#                     content_embedding = self.content_encoder.get_content_embeddings(batch1)\n",
        "#                     style_embedding = self.style_encoder.get_style(batch2)\n",
        "\n",
        "#                     mi_estimator.eval()\n",
        "#                     sampler_loss = mi_estimator(content_embedding, style_embedding)\n",
        "#                     # print(sampler_loss)\n",
        "\n",
        "#                     self.content_opt.zero_grad()\n",
        "#                     self.style_opt.zero_grad()\n",
        "\n",
        "#                     sampler_loss.backward()\n",
        "\n",
        "#                     self.content_opt.step()\n",
        "#                     self.style_opt.step()\n",
        "\n",
        "#                     sampler_loss_all += sampler_loss.item()\n",
        "\n",
        "\n",
        "#                 for j in range(5):\n",
        "#                     print(j)\n",
        "#                     mi_loss_temp = 0\n",
        "#                     mi_estimator.train()\n",
        "#                     for batch1, batch2 in zip(content_trainloader, style_trainloader):\n",
        "#                         content_embedding = self.content_encoder.get_content_embeddings(batch1)\n",
        "#                         style_embedding = self.style_encoder.get_style(batch2)\n",
        "\n",
        "#                         # mi_optimizer = torch.optim.Adam(mi_estimator.parameters(), lr=self.lr)\n",
        "\n",
        "#                         mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "#                         mi_loss = torch.mean(mi_loss)\n",
        "\n",
        "#                         mi_optimizer.zero_grad()\n",
        "#                         mi_loss.backward()\n",
        "#                         mi_optimizer.step()\n",
        "\n",
        "#                         iter_loss += mi_loss.item()\n",
        "#                         mi_loss_temp += mi_loss.item()\n",
        "#                     print('mi loss', mi_loss_temp / len(content_trainloader))\n",
        "\n",
        "#                 iter_loss /= 10\n",
        "#                 iter_losses.append(iter_loss)\n",
        "#                 tqdm_iter.set_postfix(loss=iter_loss)\n",
        "#                 if i % 10 == 0:\n",
        "#                     # tqdm.write(f\"Step {i+1} - Loss: {iter_loss:.4f}\")\n",
        "#                     # loss = iter_loss.cpu().detach().numpy().tolist()\n",
        "#                     results[\"step {}\".format(i)] = iter_loss\n",
        "\n",
        "#                 # print(mi_estimator(content_embedding, style_embedding))\n",
        "\n",
        "#             style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "#             torch.save(self.style_encoder.model.state_dict(), style_checkpoint)\n",
        "\n",
        "#             self.test_step(style_checkpoint, train_data, test_data, '')\n",
        "\n",
        "\n",
        "#             epoch_loss = sum(iter_losses) / len(iter_losses)\n",
        "#             epoch_losses.append(epoch_loss)\n",
        "#             results[\"EPOCH {}:\".format(i)] = epoch_loss\n",
        "#             print(f\"Epoch {epoch+1}/{self.num_epochs} - Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "#         with open('/content/drive/MyDrive/msc_project/model/contrastive/club/mi_loss_batch.json', 'w') as json_file:\n",
        "#             json.dump(results, json_file, indent=4)\n",
        "#         return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wljacnxUfnxn"
      },
      "outputs": [],
      "source": [
        "class ContentEncoder():\n",
        "    def __init__(self,\n",
        "                 checkpoint,\n",
        "                 train_data,\n",
        "                 test_data,):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.checkpoint = checkpoint\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.encoder = BertGenerationEncoder.from_pretrained(self.checkpoint)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
        "        self.lr = 2e-5\n",
        "        self.max_length = 256\n",
        "\n",
        "    def prepare_data(self, data):\n",
        "        # data = Dataset.from_dict(data)\n",
        "        processed_data = data.map(self.prepare_inputs,\n",
        "            # batched=True,\n",
        "            # batch_size=16,\n",
        "        )\n",
        "        processed_data = processed_data.remove_columns([\"sentence1\", \"label\"])\n",
        "        processed_data.set_format(\n",
        "            type=\"torch\",\n",
        "            columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        "        )\n",
        "        return processed_data\n",
        "\n",
        "    def prepare_inputs(self, examples):\n",
        "        tokenizer = self.tokenizer\n",
        "        inputs = tokenizer.encode_plus(examples[\"sentence1\"], truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
        "        outputs = tokenizer.encode_plus(examples[\"sentence1\"], truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
        "\n",
        "        examples[\"input_ids\"] = inputs.input_ids\n",
        "        examples[\"attention_mask\"] = inputs.attention_mask\n",
        "        examples[\"decoder_input_ids\"] = outputs.input_ids\n",
        "        examples[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "        examples[\"labels\"] = outputs.input_ids.copy()\n",
        "        return examples\n",
        "\n",
        "\n",
        "    def get_content_embeddings(self, data):\n",
        "        encoder = self.encoder.to(self.device)\n",
        "        # data = self.prepare_data(data)\n",
        "        # data_input_ids = data['input_ids'].to(self.device)\n",
        "        # data_attention_mask = data['attention_mask'].to(self.device)\n",
        "        x = data\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        # outputs = encoder(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "        outputs = encoder(input_ids=x[0], attention_mask=x[2])\n",
        "\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "        return last_hidden_states\n",
        "\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0):\n",
        "        super().__init__()\n",
        "        print(f'Logistic Regression classifier of dim ({in_dim} {hid_dim} {out_dim})')\n",
        "\n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(in_dim, hid_dim, bias=True),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hid_dim, out_dim, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        out = self.nn(x)\n",
        "        if return_feat:\n",
        "            return out, x\n",
        "        return out\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    FEAT_LEN = 768\n",
        "\n",
        "    def __init__(self, raw_bert, classifier):\n",
        "        super().__init__()\n",
        "        self.bert = raw_bert\n",
        "        self.fc = classifier\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        # x is a tokenized input\n",
        "        # feature = self.bert(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
        "        feature = self.bert(input_ids=x[0], attention_mask=x[2])\n",
        "        # print(feature.last_hidden_state.shape)\n",
        "        # out = self.fc(feature.pooler_output.flatten(1))       # not good for our task     # (BS, E)\n",
        "        out = self.fc(feature.last_hidden_state.flatten(1))  # (BS, T, E)\n",
        "        if return_feat:\n",
        "            return out, feature.last_hidden_state, feature\n",
        "        return out\n",
        "\n",
        "\n",
        "def load_model_dic(model, ckpt_path, verbose=True, strict=True):\n",
        "    \"\"\"\n",
        "    Load weights to model and take care of weight parallelism\n",
        "    \"\"\"\n",
        "    assert os.path.exists(ckpt_path), f\"trained model {ckpt_path} does not exist\"\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(ckpt_path), strict=strict)\n",
        "    except:\n",
        "        state_dict = torch.load(ckpt_path)\n",
        "        state_dict = {k.partition('module.')[2]: state_dict[k] for k in state_dict.keys()}\n",
        "        model.load_state_dict(state_dict, strict=strict)\n",
        "    if verbose:\n",
        "        print(f'Model loaded: {ckpt_path}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_model(ckpt_dir, cp_name, model):\n",
        "    \"\"\"\n",
        "    Create directory /Checkpoint under exp_data_path and save encoder as cp_name\n",
        "    \"\"\"\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    saving_model_path = os.path.join(ckpt_dir, cp_name)\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        model = model.module  # convert to non-parallel form\n",
        "    torch.save(model.state_dict(), saving_model_path)\n",
        "    print(f'Model saved: {saving_model_path}')\n",
        "\n",
        "\n",
        "class StyleEncoder():\n",
        "    def __init__(\n",
        "            self,\n",
        "            checkpoint,\n",
        "            train_data,\n",
        "            test_data):\n",
        "\n",
        "        self.checkpoint = checkpoint\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "        # self.model = BertModel.from_pretrained(checkpoint)\n",
        "        num_tokens, hidden_dim, out_dim, dropout = 256, 512, 150, 0.35\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
        "        extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "        model = BertClassifier(extractor, LogisticRegression(768 * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "        self.model = load_model_dic(model, checkpoint, verbose=True, strict=True)\n",
        "        # self.tokenizer = BertTokenizer.from_pretrained(checkpoint, padding=True, truncation=True)\n",
        "        # self.model = BertModel.from_pretrained(checkpoint)\n",
        "        self.parameters = self.model.parameters()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.max_length = 256\n",
        "\n",
        "    def prepare_inputs(self, examples):\n",
        "        tokenizer = self.tokenizer\n",
        "        inputs = tokenizer.encode_plus(examples['sentence1'], padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "        return inputs\n",
        "\n",
        "    def prepare_data(self, data):\n",
        "        processed_data = data.map(self.prepare_inputs)\n",
        "        processed_data = processed_data.remove_columns([\"sentence1\", \"label\"])\n",
        "        processed_data.set_format(type=\"torch\",)\n",
        "        return processed_data\n",
        "\n",
        "    def get_style(self, encoded_dict):\n",
        "        # data_input_ids = encoded_dict['input_ids'].to(self.device)\n",
        "        # data_attention_mask = encoded_dict['attention_mask'].to(self.device)\n",
        "        # data_token_type_ids = encoded_dict['token_type_ids'].to(self.device)\n",
        "        # x = data_input_ids, data_token_type_ids, data_attention_mask\n",
        "        x = encoded_dict\n",
        "            # model_output = self.model(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "        # with torch.no_grad():\n",
        "        # pred, feats, model_output = self.model(x, return_feat=True)\n",
        "        # feats = self.model.bert(input_ids=x[0], attention_mask=x[2])\n",
        "        pred, feats, model_output = self.model(x, return_feat=True)\n",
        "        # feats = feats.last_hidden_state\n",
        "        # sentence_embedding = self.mean_pooling(model_output, encoded_dict['attention_mask'])\n",
        "        # last_hidden_states = model_output.last_hidden_state\n",
        "        # return last_hidden_states\n",
        "        return pred, feats\n",
        "\n",
        "\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 content_encoder,\n",
        "                 style_encoder,\n",
        "                 num_epochs,\n",
        "                 batch_size,\n",
        "                 num_iters,\n",
        "                 log_step,\n",
        "                 lr=2e-5,\n",
        "                 hidden_size=500):\n",
        "\n",
        "        super(DualEncoder, self).__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.content_encoder = content_encoder\n",
        "        self.style_encoder = style_encoder\n",
        "        self.lr = lr\n",
        "        self.num_iters = num_iters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.log_step = log_step\n",
        "        self.content_opt = torch.optim.Adam(self.content_encoder.encoder.parameters(), self.lr)\n",
        "        self.style_opt = torch.optim.Adam(self.style_encoder.model.parameters(), lr = self.lr)\n",
        "\n",
        "    def test_step(self, style_checkpoint, train_loader, test_data, test_loader, output_file):\n",
        "        ranking_eval = RegionComparison(checkpoint = style_checkpoint,\n",
        "                                        train_loader=train_loader,\n",
        "                                        test_data=test_data,\n",
        "                                        test_loader=test_loader,\n",
        "                                        output_file=output_file)\n",
        "\n",
        "        # result_list = ranking_eval.compare_to_regions(train_data, test_data)\n",
        "        # with open(output_file, 'w') as f:\n",
        "        #     for dictionary in result_list:\n",
        "        #         json_string = json.dumps(dictionary)\n",
        "        #         f.write(json_string + '\\n')\n",
        "\n",
        "        metrics_file = \"/content/drive/MyDrive/msc_project/model/contrastive/club/metrics.json\"\n",
        "        accuracy_k = \"/content/drive/MyDrive/msc_project/model/contrastive/club/accuracy_k.json\"\n",
        "\n",
        "        metrics = ranking_eval.compute_metrics()\n",
        "        # with open(metrics_file, 'w') as f:\n",
        "        #     json.dump(metrics, f, indent=4)\n",
        "        # metrics = {}\n",
        "\n",
        "        result_topk = {}\n",
        "\n",
        "        # for i in range(1,2):\n",
        "        #     metrics_topk = ranking_eval.compute_top_k(i)\n",
        "        #     result_topk[f'Accuracy top-{i}'] = metrics_topk\n",
        "\n",
        "        # metrics_top10 = ranking_eval.compute_top_k(10)\n",
        "        # result_topk[f'Accuracy top-10'] = metrics_top10\n",
        "\n",
        "        # metrics_top20 = ranking_eval.compute_top_k(20)\n",
        "        # result_topk[f'Accuracy top-20'] = metrics_top20\n",
        "\n",
        "        # with open(accuracy_k, 'w') as f:\n",
        "        #     json.dump(result_topk, f, indent=4)\n",
        "        return metrics, result_topk\n",
        "\n",
        "\n",
        "    def train(self, train_dict, test_dic, val_dic=None):\n",
        "        self.content_encoder.encoder.to(self.device)\n",
        "        self.style_encoder.model.to(self.device)\n",
        "\n",
        "        train_x, train_y = train_dict['content'].tolist(), train_dict['Target'].tolist()\n",
        "        test_x, test_y = test_dic['content'].tolist(), test_dic['Target'].tolist()\n",
        "\n",
        "        if val_dic is not None:\n",
        "            val_x, val_y = val_dic['content'].tolist(), val_dic['Target'].tolist()\n",
        "\n",
        "        from transformers import BertTokenizer, BertModel\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "        num_tokens, hidden_dim = 256, 512\n",
        "\n",
        "        train_set = BertDataset(train_x, train_y, tokenizer, num_tokens)\n",
        "        test_set = BertDataset(test_x, test_y, tokenizer, num_tokens)\n",
        "\n",
        "        if val_dic is not None:\n",
        "            val_set = BertDataset(val_x, val_y, tokenizer, num_tokens)\n",
        "\n",
        "        temperature, sample_unit_size = 0.1, 2\n",
        "        # print(f'coefficient, temperature, sample_unit_size = {coefficient, temperature, sample_unit_size}')\n",
        "\n",
        "        # load data\n",
        "        train_sampler = TrainSamplerMultiClassUnit(train_set, sample_unit_size=sample_unit_size)\n",
        "        train_loader = DataLoader(train_set, batch_size=self.batch_size, sampler=train_sampler, shuffle=False,\n",
        "                                  num_workers=4, pin_memory=True, drop_last=False)\n",
        "        # train_loader = DataLoader(train_set, batch_size=base_bs * ngpus, shuffle=True,\n",
        "        #                           num_workers=4 * ngpus, pin_memory=True, drop_last=False)\n",
        "        test_loader = DataLoader(test_set, batch_size=self.batch_size, shuffle=False, num_workers=4,\n",
        "                                pin_memory=True, drop_last=False)\n",
        "\n",
        "        if val_dic is not None:\n",
        "            val_loader = DataLoader(val_set, batch_size=self.batch_size, shuffle=False, num_workers=4,\n",
        "                                    pin_memory=True, drop_last=True)\n",
        "\n",
        "        sample_dim = 196608\n",
        "        # sample_dim = 768\n",
        "        mi_estimator = CLUB(sample_dim, sample_dim, self.hidden_size).cuda()\n",
        "        mi_optimizer = torch.optim.Adam(mi_estimator.parameters(), lr=1e-3)\n",
        "        supcon = SupConLoss_contrastiveAA()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # style_checkpoint = f\"/content/drive/MyDrive/msc_project/model/contrastive/club_blogs50/style_encoder_supcon_0.pt\"\n",
        "        # self.test_step(style_checkpoint, train_loader, test_dic, test_loader, '')\n",
        "\n",
        "\n",
        "        for epoch in range(5):  # num_iter_phase1 is the number of iterations for this phase\n",
        "            train_estimator_loss = AverageMeter()\n",
        "            pg = tqdm(train_loader, leave=False, total=len(train_loader), disable=False)\n",
        "            for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "                x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "\n",
        "                # Encode the samples using style and content encoders\n",
        "                # These encoders are not updated in this phase\n",
        "                with torch.no_grad():  # Ensure that encoders are not trained\n",
        "                    content_embedding = self.content_encoder.get_content_embeddings(x)\n",
        "                    pred, style_embedding = self.style_encoder.get_style(x)\n",
        "\n",
        "                # Train the MI estimator\n",
        "                mi_estimator.train()\n",
        "                mi_loss = mi_estimator.learning_loss(content_embedding.flatten(1), style_embedding.flatten(1))\n",
        "                # mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "\n",
        "                mi_optimizer.zero_grad()\n",
        "                mi_loss.backward()\n",
        "                mi_optimizer.step()\n",
        "\n",
        "                train_estimator_loss.update(mi_loss.item())\n",
        "\n",
        "                pg.set_postfix({\n",
        "                    'train eistimator loss': '{:.6f}'.format(train_estimator_loss.avg),\n",
        "                    'epoch': '{:03d}'.format(epoch)\n",
        "                })\n",
        "            print(f'epoch {epoch}, train eistimator loss {train_estimator_loss.avg}')\n",
        "\n",
        "        print()\n",
        "        epoch_losses = []\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "\n",
        "            # numbers = list(range(len(train_loader)))\n",
        "            # random_numbers = random.sample(numbers, 500)\n",
        "            # print(random_numbers)\n",
        "\n",
        "            self.content_encoder.encoder.train()\n",
        "            self.style_encoder.model.train()\n",
        "            mi_estimator.eval()\n",
        "\n",
        "            count = 0\n",
        "            sampler_loss_all = 0\n",
        "\n",
        "            train_acc = AverageMeter()\n",
        "            train_loss = AverageMeter()\n",
        "            train_sampler_loss = AverageMeter()\n",
        "            train_supcon_loss = AverageMeter()\n",
        "            train_cls_loss = AverageMeter()\n",
        "            pg = tqdm(train_loader, leave=False, total=len(train_loader), disable=False)\n",
        "            for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "                # if i not in random_numbers:\n",
        "                #     continue\n",
        "\n",
        "                x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "                content_embedding = self.content_encoder.get_content_embeddings(x)\n",
        "                pred, style_embedding = self.style_encoder.get_style(x)\n",
        "                # print('pred', pred.argmax(1))\n",
        "                # print('y', y)\n",
        "\n",
        "                # sampler_loss = mi_estimator(style_embedding, content_embedding)\n",
        "                sampler_loss = mi_estimator(content_embedding.flatten(1), style_embedding.flatten(1))\n",
        "                supcon_loss = supcon(style_embedding.flatten(1), y.long())\n",
        "                cls_loss = criterion(pred, y.long())\n",
        "\n",
        "                coe = 5\n",
        "                # loss = coe * sampler_loss + supcon_loss + cls_loss\n",
        "                loss = coe * sampler_loss + supcon_loss\n",
        "\n",
        "                acc = (pred.argmax(1) == y).sum().item() / len(y)\n",
        "\n",
        "                train_acc.update(acc)\n",
        "                train_loss.update(loss.item())\n",
        "                train_sampler_loss.update(sampler_loss.item())\n",
        "                train_supcon_loss.update(supcon_loss.item())\n",
        "                train_cls_loss.update(cls_loss.item())\n",
        "\n",
        "                self.content_opt.zero_grad()\n",
        "                self.style_opt.zero_grad()\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                self.content_opt.step()\n",
        "                self.style_opt.step()\n",
        "\n",
        "\n",
        "                pg.set_postfix({\n",
        "                    'train acc': '{:.6f}'.format(train_acc.avg),\n",
        "                    'train sampler loss': '{:.6f}'.format(train_sampler_loss.avg),\n",
        "                    'train supcon loss': '{:.6f}'.format(train_supcon_loss.avg),\n",
        "                    'train cls loss': '{:.6f}'.format(train_cls_loss.avg),\n",
        "                    'train L': '{:.6f}'.format(train_loss.avg),\n",
        "                    'epoch': '{:03d}'.format(epoch)\n",
        "                })\n",
        "\n",
        "            print(f'epoch {epoch}, sampler loss {train_sampler_loss.avg}, supcon loss {train_supcon_loss.avg}, cls loss {train_cls_loss.avg}, loss {train_loss.avg}, style acc {train_acc.avg}')\n",
        "\n",
        "            # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "            # torch.save(self.style_encoder.model.state_dict(), style_checkpoint)\n",
        "            # self.test_step(style_checkpoint, train_dict, test_dic, '')\n",
        "\n",
        "            for j in range(5):\n",
        "                # numbers = list(range(len(train_loader)))\n",
        "                # random_numbers = random.sample(numbers, 500)\n",
        "                # print(random_numbers)\n",
        "\n",
        "                train_estimator_loss = AverageMeter()\n",
        "                mi_estimator.train()\n",
        "                pg = tqdm(train_loader, leave=False, total=len(train_loader), disable=False)\n",
        "                for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "                    # if i not in random_numbers:\n",
        "                    #     continue\n",
        "\n",
        "                    x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "                    content_embedding = self.content_encoder.get_content_embeddings(x)\n",
        "                    pred, style_embedding = self.style_encoder.get_style(x)\n",
        "\n",
        "                    mi_loss = mi_estimator.learning_loss(content_embedding.flatten(1), style_embedding.flatten(1))\n",
        "                    # mi_loss = mi_estimator.learning_loss(content_embedding, style_embedding)\n",
        "                    mi_optimizer.zero_grad()\n",
        "                    mi_loss.backward()\n",
        "                    mi_optimizer.step()\n",
        "\n",
        "                    train_estimator_loss.update(mi_loss.item())\n",
        "\n",
        "                    pg.set_postfix({\n",
        "                        'train eistimator loss': '{:.6f}'.format(train_estimator_loss.avg),\n",
        "                        'iteration': '{:03d}'.format(j)\n",
        "                    })\n",
        "\n",
        "                print(f'iteration {j}, train eistimator loss {train_estimator_loss.avg}')\n",
        "\n",
        "            style_checkpoint = f\"/content/drive/MyDrive/msc_project/model/contrastive/club_100_150/style_encoder_supcon1_{epoch}.pt\"\n",
        "            torch.save(self.style_encoder.model.state_dict(), style_checkpoint)\n",
        "            content_checkpoint = f\"/content/drive/MyDrive/msc_project/model/contrastive/club_100_150/content_encoder_supcon1_{epoch}.pt\"\n",
        "            torch.save(self.content_encoder.encoder.state_dict(), content_checkpoint)\n",
        "            self.test_step(style_checkpoint, train_loader, test_dic, test_loader, '')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7UTNDcxgbR6"
      },
      "source": [
        "# loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP0Jus4jgcjF"
      },
      "outputs": [],
      "source": [
        "class CLUB(nn.Module):\n",
        "    def __init__(self, x_dim, y_dim, hidden_size):\n",
        "        super(CLUB, self).__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # self.x_samples = x_samples\n",
        "        # self.y_samples = y_samples\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # self.p_mu = nn.Sequential(nn.Linear(self.x_samples.shape[2], self.hidden_size // 2),\n",
        "        #                         nn.ReLU(),\n",
        "        #                         nn.Linear(self.hidden_size // 2, self.y_samples.shape[2]))\n",
        "\n",
        "        # self.p_logvar = nn.Sequential(nn.Linear(self.x_samples.shape[2], self.hidden_size // 2),\n",
        "        #                             nn.ReLU(),\n",
        "        #                             nn.Linear(self.hidden_size // 2, self.y_samples.shape[2]),\n",
        "        #                             nn.Tanh())\n",
        "        self.p_mu = nn.Sequential(nn.Linear(x_dim, self.hidden_size // 2),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(self.hidden_size // 2, y_dim))\n",
        "\n",
        "        self.p_logvar = nn.Sequential(nn.Linear(x_dim, self.hidden_size // 2),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(self.hidden_size // 2, y_dim),\n",
        "                                    nn.Tanh())\n",
        "\n",
        "    def get_mu_logvar(self, data):\n",
        "        # print(data.shape)\n",
        "        mu = self.p_mu(data)\n",
        "        logvar = self.p_logvar(data)\n",
        "        return mu, logvar\n",
        "\n",
        "    def forward(self, x_samples, y_samples):\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "        positive = torch.div(-(mu - y_samples)**2, 2. * torch.exp(logvar))\n",
        "\n",
        "        prediction_1 = mu.unsqueeze(1)\n",
        "        y_samples_1 = y_samples.unsqueeze(0)\n",
        "        negative = - torch.div(torch.mean((y_samples_1 - prediction_1)**2, dim=1), 2. * torch.exp(logvar))\n",
        "        res = torch.mean(positive.sum(dim = -1) - negative.sum(dim = -1))\n",
        "        return res\n",
        "\n",
        "    def loglikeli(self, x_samples, y_samples):\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "        # res = torch.mean((-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1), dim=0)\n",
        "        res = torch.mean((-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1), dim=0)\n",
        "        return res\n",
        "\n",
        "    def learning_loss(self, x_samples, y_samples):\n",
        "        res = - self.loglikeli(x_samples, y_samples)\n",
        "        return res\n",
        "\n",
        "class SupConLoss_contrastiveAA(nn.Module):\n",
        "    def __init__(self, temperature=0.1, margin=0.2):\n",
        "        \"\"\"\n",
        "        Implementation of the loss described in the paper Supervised Contrastive Learning :\n",
        "        https://arxiv.org/abs/2004.11362\n",
        "        :param temperature: int\n",
        "        \"\"\"\n",
        "        super(SupConLoss_contrastiveAA, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "\n",
        "    def forward(self, projections, targets):\n",
        "        \"\"\"\n",
        "        :param projections: torch.Tensor, shape [batch_size, projection_dim]\n",
        "        :param targets: torch.Tensor, shape [batch_size]\n",
        "        :return: torch.Tensor, scalar\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\") if projections.is_cuda else torch.device(\"cpu\")\n",
        "\n",
        "        dot_product_tempered = self.cos(projections.unsqueeze(1), projections.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        exp_dot_tempered = (\n",
        "            torch.exp(dot_product_tempered - torch.max(dot_product_tempered, dim=1, keepdim=True)[0]) + 1e-5\n",
        "        )\n",
        "\n",
        "        # mask_similar_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) == targets).to(device)\n",
        "        # mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0])).to(device)\n",
        "        # mask_combined_pos = mask_similar_class * mask_anchor_out\n",
        "\n",
        "        # mask_diff_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) != targets).to(device)\n",
        "        # mask_combined_neg = mask_diff_class * mask_anchor_out\n",
        "\n",
        "        mask_similar_class = (targets.unsqueeze(1) == targets.unsqueeze(0)).to(device)\n",
        "        mask_anchor_out = ~torch.eye(projections.shape[0], dtype=torch.bool).to(device)  # Mask self-similarities\n",
        "\n",
        "        # Positive and negative masks combined\n",
        "        mask_combined_pos = mask_similar_class * mask_anchor_out\n",
        "        mask_combined_neg = (~mask_similar_class) * mask_anchor_out\n",
        "\n",
        "        cardinality_pos = mask_combined_pos.sum(dim=1).clamp(min=1)\n",
        "\n",
        "        # cardinality_pos = torch.sum(mask_combined_pos, dim=1)\n",
        "\n",
        "        # for i in range(cardinality_pos.size(0)):\n",
        "        #     if cardinality_pos[i]==0:\n",
        "        #         cardinality_pos[i] = 1\n",
        "        # print(1)\n",
        "\n",
        "        exp_sum_neg = torch.sum(exp_dot_tempered * mask_combined_neg, dim=1)\n",
        "        prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg.view(-1, 1) + 1e-5)\n",
        "\n",
        "        log_prob = -torch.log(prob) * mask_combined_pos\n",
        "        # for i in range(cardinality_pos.size(0)):\n",
        "        #     if cardinality_pos[i]==0:\n",
        "        #         cardinality_pos[i] = 1\n",
        "\n",
        "        total_loss = torch.mean(torch.sum(log_prob, dim=1) / cardinality_pos)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "# class CLUB(nn.Module):  # CLUB: Mutual Information Contrastive Learning Upper Bound\n",
        "#     '''\n",
        "#         This class provides the CLUB estimation to I(X,Y)\n",
        "#         Method:\n",
        "#             forward() :      provides the estimation with input samples\n",
        "#             loglikeli() :   provides the log-likelihood of the approximation q(Y|X) with input samples\n",
        "#         Arguments:\n",
        "#             x_dim, y_dim :         the dimensions of samples from X, Y respectively\n",
        "#             hidden_size :          the dimension of the hidden layer of the approximation network q(Y|X)\n",
        "#             x_samples, y_samples : samples from X and Y, having shape [sample_size, x_dim/y_dim]\n",
        "#     '''\n",
        "#     def __init__(self, x_dim, y_dim, hidden_size):\n",
        "#         super(CLUB, self).__init__()\n",
        "#         # p_mu outputs mean of q(Y|X)\n",
        "#         #print(\"create CLUB with dim {}, {}, hiddensize {}\".format(x_dim, y_dim, hidden_size))\n",
        "#         self.p_mu = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "#                                        nn.ReLU(),\n",
        "#                                        nn.Linear(hidden_size//2, y_dim))\n",
        "#         # p_logvar outputs log of variance of q(Y|X)\n",
        "#         self.p_logvar = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "#                                        nn.ReLU(),\n",
        "#                                        nn.Linear(hidden_size//2, y_dim),\n",
        "#                                        nn.Tanh())\n",
        "\n",
        "#     def get_mu_logvar(self, x_samples):\n",
        "#         mu = self.p_mu(x_samples)\n",
        "#         logvar = self.p_logvar(x_samples)\n",
        "#         return mu, logvar\n",
        "\n",
        "#     def forward(self, x_samples, y_samples):\n",
        "#         mu, logvar = self.get_mu_logvar(x_samples)\n",
        "#         # print(mu)\n",
        "#         # print(logvar)\n",
        "\n",
        "#         # log of conditional probability of positive sample pairs\n",
        "#         positive = - (mu - y_samples)**2 /2./logvar.exp()\n",
        "#         # print('positive', positive)\n",
        "#         # print(positive.sum(dim = -1))\n",
        "\n",
        "#         prediction_1 = mu.unsqueeze(1)          # shape [nsample,1,dim]\n",
        "#         # print(prediction_1.shape)\n",
        "#         y_samples_1 = y_samples.unsqueeze(0)    # shape [1,nsample,dim]\n",
        "\n",
        "#         # log of conditional probability of negative sample pairs\n",
        "#         negative = - ((y_samples_1 - prediction_1)**2).mean(dim=1)/2./logvar.exp()\n",
        "#         # print('negative', negative)\n",
        "#         # print(negative.sum(dim = -1))\n",
        "\n",
        "#         return (positive.sum(dim = -1) - negative.sum(dim = -1)).mean()\n",
        "\n",
        "#     def loglikeli(self, x_samples, y_samples): # unnormalized loglikelihood\n",
        "#         mu, logvar = self.get_mu_logvar(x_samples)\n",
        "#         return (-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1).mean(dim=0)\n",
        "\n",
        "#     def learning_loss(self, x_samples, y_samples):\n",
        "#         return - self.loglikeli(x_samples, y_samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAwfcwWQgn9R"
      },
      "source": [
        "# evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2GlToZsgp2c"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "class RegionComparison():\n",
        "    def __init__(self,\n",
        "                 checkpoint,\n",
        "                 train_loader,\n",
        "                 test_data,\n",
        "                 test_loader,\n",
        "                 output_file = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"):\n",
        "        self.checkpoint = checkpoint\n",
        "        # self.model =  BertModel.from_pretrained(self.checkpoint)\n",
        "        # self.tokenizer = BertTokenizer.from_pretrained(self.checkpoint, padding=True, truncation=True)\n",
        "        num_tokens, hidden_dim, out_dim, dropout = 256, 512, 150, 0.35\n",
        "        self.num_tokens = num_tokens\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
        "        extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "        model = BertClassifier(extractor, LogisticRegression(768 * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "        self.model = load_model_dic(model, checkpoint, verbose=True, strict=True)\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.test_data = test_data\n",
        "        self.output_file = output_file\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "        self.max_length = 256\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        # attention_mask: batch_size * max_length\n",
        "        token_embeddings = model_output[0] # batch_size * max_length * hidden_dim\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float() # batch_size * max_length * hidden_dim\n",
        "        input_mask_expanded = input_mask_expanded.to(self.device)\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    def test_AA_acc(self):\n",
        "        # test_x, test_y = self.test_data['content'].tolist(), self.test_data['Target'].tolist()\n",
        "        # test_set = BertDataset(test_x, test_y, self.tokenizer, self.num_tokens)\n",
        "        # test_loader = DataLoader(test_set, batch_size=24, shuffle=False, num_workers=4,\n",
        "        #                             pin_memory=True)\n",
        "        test_loader = self.test_loader\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (x1, x2, x3, y) in enumerate(test_loader):  # for x1, x2, x3, y in train_set:\n",
        "                x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "                pred, feats, model_output = self.model(x, return_feat=True)\n",
        "                all_preds.append(pred.argmax(1).cpu().detach().numpy())\n",
        "                all_labels.append(y.cpu().detach().numpy())\n",
        "\n",
        "        all_preds = np.concatenate(all_preds, axis=0).tolist()\n",
        "        all_labels = np.concatenate(all_labels, axis=0).tolist()\n",
        "        # print(all_preds)\n",
        "        # print(all_labels)\n",
        "        # Compare predictions to labels\n",
        "        correct_predictions = sum(p == l for p, l in zip(all_preds, all_labels))\n",
        "        # Calculate accuracy\n",
        "        accuracy = correct_predictions / len(all_preds)\n",
        "        print('accuracy', accuracy)\n",
        "\n",
        "    # Compute and return average embeddings for each region\n",
        "    def get_average_embeddings(self, data):\n",
        "        self.model.eval()\n",
        "\n",
        "        device = self.device\n",
        "        # tokenizer = self.tokenizer\n",
        "        model = self.model\n",
        "        label_embeddings = {}\n",
        "        label_counts = {}\n",
        "        for i, (x1, x2, x3, y) in enumerate(data):\n",
        "            x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "            with torch.no_grad():\n",
        "                pred, feats, model_output = self.model(x, return_feat=True)\n",
        "                batch_embeddings = feats.flatten(1).cpu()\n",
        "\n",
        "            for i, label in enumerate(y):\n",
        "                label = label.item()  # Ensure the label is a simple value (if tensor)\n",
        "                embedding = batch_embeddings[i]\n",
        "\n",
        "                if label not in label_embeddings:\n",
        "                    label_embeddings[label] = embedding\n",
        "                    label_counts[label] = 1\n",
        "                else:\n",
        "                    label_embeddings[label] += embedding\n",
        "                    label_counts[label] += 1\n",
        "\n",
        "            # Clear memory after processing the batch\n",
        "            del x, feats\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Compute mean embeddings for each label\n",
        "        mean_embeddings = {}\n",
        "        for label, total_embedding in label_embeddings.items():\n",
        "            mean_embeddings[label] = total_embedding / label_counts[label]\n",
        "\n",
        "        return mean_embeddings\n",
        "\n",
        "        # # Group the data by label\n",
        "        # label_data = {}\n",
        "        # # for example in data:\n",
        "        # for idx, example in data.iterrows():\n",
        "        #     # label = example['label']\n",
        "        #     # sentence = example['sentence1']\n",
        "        #     label = example['Target']\n",
        "        #     sentence = example['content']\n",
        "        #     if label not in label_data:\n",
        "        #         label_data[label] = []\n",
        "        #     label_data[label].append(sentence)\n",
        "\n",
        "        # # Encode each sentence and extract the embeddings\n",
        "        # label_embeddings = {}\n",
        "        # label_counts = {}\n",
        "        # for label, sentences in label_data.items():\n",
        "        #     sentence_embeddings = []\n",
        "        #     for sentence in sentences:\n",
        "        #         encoded_dict = tokenizer.encode_plus(\n",
        "        #             sentence,\n",
        "        #             # padding=True,\n",
        "        #             truncation=True,\n",
        "        #             return_tensors='pt',\n",
        "        #             max_length=self.max_length,\n",
        "        #             padding=\"max_length\"\n",
        "        #         )\n",
        "        #         # Compute token embeddings\n",
        "        #         with torch.no_grad():\n",
        "        #             data_input_ids = encoded_dict['input_ids'].to(self.device)\n",
        "        #             data_attention_mask = encoded_dict['attention_mask'].to(self.device)\n",
        "        #             data_token_type_ids = encoded_dict['token_type_ids'].to(self.device)\n",
        "        #             x = data_input_ids, data_token_type_ids, data_attention_mask\n",
        "        #             # model_output = self.model(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "        #             pred, feats, model_output = self.model(x, return_feat=True)\n",
        "\n",
        "        #         # Performing mean pooling\n",
        "        #         # sentence_embedding = self.mean_pooling(model_output, encoded_dict['attention_mask'].to(device))\n",
        "        #         sentence_embedding = feats.flatten(1)\n",
        "        #         sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "        #     label_embeddings[label] = torch.stack(sentence_embeddings)\n",
        "\n",
        "        # mean_embeddings = {}\n",
        "        # for label, embeddings in label_embeddings.items():\n",
        "        #     mean_embedding = torch.mean(embeddings, dim=0)\n",
        "        #     mean_embeddings[label] = mean_embedding\n",
        "\n",
        "        # return mean_embeddings\n",
        "\n",
        "\n",
        "    def get_clustered_embeddings(self, data, n_clusters=1):\n",
        "        self.model.eval()\n",
        "\n",
        "        device = self.device\n",
        "        tokenizer = self.tokenizer\n",
        "        model = self.model\n",
        "\n",
        "        # Group the data by label\n",
        "        label_data = {}\n",
        "        for example in data:\n",
        "            label = example['label']\n",
        "            sentence = example['sentence1']\n",
        "            if label not in label_data:\n",
        "                label_data[label] = []\n",
        "            label_data[label].append(sentence)\n",
        "\n",
        "        # Encode each sentence and extract the embeddings\n",
        "        label_embeddings = {}\n",
        "        for label, sentences in label_data.items():\n",
        "            sentence_embeddings = []\n",
        "            for sentence in sentences:\n",
        "                encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence,\n",
        "                    # padding=True,\n",
        "                    truncation=True,\n",
        "                    return_tensors='pt',\n",
        "                    max_length=self.max_length,\n",
        "                    padding=\"max_length\"\n",
        "                )\n",
        "                # Compute token embeddings\n",
        "                with torch.no_grad():\n",
        "                    data_input_ids = encoded_dict['input_ids'].to(self.device)\n",
        "                    data_attention_mask = encoded_dict['attention_mask'].to(self.device)\n",
        "                    data_token_type_ids = encoded_dict['token_type_ids'].to(self.device)\n",
        "                    x = data_input_ids, data_token_type_ids, data_attention_mask\n",
        "                    # model_output = self.model(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "                    pred, feats, model_output = self.model(x, return_feat=True)\n",
        "\n",
        "                # Performing mean pooling\n",
        "                sentence_embedding = self.mean_pooling(model_output, encoded_dict['attention_mask'].to(device))\n",
        "                sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "            label_embeddings[label] = torch.stack(sentence_embeddings)\n",
        "\n",
        "        author_embeddings = {}\n",
        "        for author, embeddings in label_embeddings.items():\n",
        "            embeddings = embeddings.squeeze(1)\n",
        "            embeddings = embeddings.cpu()\n",
        "            # print(embeddings.shape)\n",
        "            kmeans = KMeans(n_clusters=n_clusters)\n",
        "            kmeans.fit(embeddings)\n",
        "            author_embeddings[author] = kmeans.cluster_centers_[0]  # Use the centroid of the most prominent cluster\n",
        "        return author_embeddings\n",
        "\n",
        "\n",
        "    # Compute and return the ranking for the regions based on the input data\n",
        "    def compare_to_regions(self, train_loader, test_data, test_loader):\n",
        "\n",
        "        self.model.eval()\n",
        "        device = self.device\n",
        "        model = self.model\n",
        "\n",
        "        all_embeddings = []\n",
        "        for i, (x1, x2, x3, y) in enumerate(test_loader):\n",
        "            x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "            with torch.no_grad():\n",
        "                pred, feats, model_output = self.model(x, return_feat=True)\n",
        "                batch_embeddings = feats.flatten(1).cpu()\n",
        "                all_embeddings.append(batch_embeddings)\n",
        "        all_embeddings = torch.cat(all_embeddings, dim=0)\n",
        "\n",
        "        # # input_data = test_data['sentence1']\n",
        "        # input_data = test_data['content'].tolist()\n",
        "\n",
        "        # input_embeddings = []\n",
        "        # for idx, text in enumerate(input_data):\n",
        "        #     encoded_dict = self.tokenizer.encode_plus(\n",
        "        #         text,\n",
        "        #         truncation=True,\n",
        "        #         padding=\"max_length\",\n",
        "        #         return_tensors='pt',\n",
        "        #         max_length=self.max_length\n",
        "        #     )\n",
        "\n",
        "        #     # Compute token embeddings\n",
        "        #     with torch.no_grad():\n",
        "        #         # encoded_dict = encoded_dict.to(self.device)\n",
        "        #         # print(encoded_dict)\n",
        "        #         data_input_ids = encoded_dict['input_ids'].to(self.device)\n",
        "        #         data_attention_mask = encoded_dict['attention_mask'].to(self.device)\n",
        "        #         data_token_type_ids = encoded_dict['token_type_ids'].to(self.device)\n",
        "        #         x = data_input_ids, data_token_type_ids, data_attention_mask\n",
        "        #         # model_output = self.model(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "        #         pred, feats, model_output = self.model(x, return_feat=True)\n",
        "        #         # model_output = self.model(**encoded_dict)\n",
        "\n",
        "        #     # Performing mean pooling\n",
        "        #     # sentence_embeddings = self.mean_pooling(model_output, encoded_dict['attention_mask']) # 1 * hidden_dim\n",
        "        #     sentence_embeddings = feats.flatten(1)\n",
        "        #     input_embeddings.append(sentence_embeddings)\n",
        "\n",
        "        # a dictionary, key is the label and values are embeddings for each author (embedding: 1 * hidden_dim)\n",
        "        region_embeddings = self.get_average_embeddings(train_loader)\n",
        "\n",
        "        # region_embeddings = self.get_clustered_embeddings(train_data)\n",
        "        region_embeddings = {label: torch.tensor(embedding).to(self.device) for label, embedding in region_embeddings.items()}\n",
        "        # print(len(all_embeddings))\n",
        "        # Compute the similarity between the embeddings of the input data and each region\n",
        "        similarities = []\n",
        "        for input_embedding in all_embeddings:\n",
        "            input_embedding = input_embedding.to(self.device)\n",
        "            # print(input_embedding.shape)\n",
        "            input_embedding = torch.reshape(input_embedding, (1, -1)) # 1 * hidden_dim\n",
        "            # print(input_embedding.shape)\n",
        "\n",
        "            input_similarity = {}\n",
        "\n",
        "            for label, region_embedding in region_embeddings.items():\n",
        "                # print(region_embedding.shape)\n",
        "                region_embedding = region_embedding.view(1, -1)  # Reshape to (1, num_features)\n",
        "                similarity = torch.nn.CosineSimilarity(dim=-1)\n",
        "                input_similarity[label] = similarity(region_embedding, input_embedding).item()\n",
        "\n",
        "            # Sort the labels by similarity score for each input embedding\n",
        "            sorted_labels = dict(sorted(input_similarity.items(), key=lambda x: x[1], reverse=True))\n",
        "            similarities.append(sorted_labels)\n",
        "\n",
        "        # print(len(similarities))\n",
        "        # print(len(test_data))\n",
        "        # each data is stored in a dictionary containing label, sentence and similarity_scores\n",
        "        test_y = test_data['Target'].tolist()\n",
        "        test_x = test_data['content'].tolist()\n",
        "        results_list = []\n",
        "        for i in range(len(test_data)):\n",
        "            result = {}\n",
        "            # result['label'] = test_data['label'][i]\n",
        "            result['label'] = test_y[i]\n",
        "\n",
        "            # input_text = test_data['sentence1'][i]\n",
        "            input_text = test_x[i]\n",
        "            result['sentence'] = input_text\n",
        "\n",
        "            similarity_scores = similarities[i]\n",
        "            result['similarity_scores'] = similarity_scores\n",
        "            results_list.append(result)\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    def get_region_embs(self, train_data, test_data):\n",
        "        input_data = test_data['sentence1']\n",
        "\n",
        "        input_embeddings = []\n",
        "        for idx, text in enumerate(input_data):\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors='pt',\n",
        "                max_length=self.max_length,\n",
        "            )\n",
        "\n",
        "            # Compute token embeddings\n",
        "            with torch.no_grad():\n",
        "                encoded_dict = encoded_dict.to(self.device)\n",
        "                model_output = self.model(**encoded_dict)\n",
        "\n",
        "            # Performing mean pooling\n",
        "            sentence_embeddings = self.mean_pooling(model_output, encoded_dict['attention_mask'])\n",
        "            input_embeddings.append(sentence_embeddings)\n",
        "\n",
        "        region_embeddings = self.get_average_embeddings(train_data)\n",
        "        region_embeddings = {label: torch.tensor(embedding).to(self.device) for label, embedding in region_embeddings.items()}\n",
        "        return input_embeddings\n",
        "\n",
        "    def extract_labels_predictions(self, results_list, key_index=0):\n",
        "        labels = []\n",
        "        predictions = []\n",
        "        for result in results_list:\n",
        "            labels.append(result['label'])\n",
        "            score_dict = result['similarity_scores']\n",
        "            key = list(score_dict.keys())[key_index]\n",
        "            predictions.append(key)\n",
        "\n",
        "        # predictions = [str(i) for i in predictions]\n",
        "        # labels = [str(i) for i in labels]\n",
        "        # print(labels)\n",
        "        # print(predictions)\n",
        "        # print(self.model.bert.config.label2id)\n",
        "        # predictions = [self.model.bert.config.label2id[label] for label in predictions]\n",
        "        # labels = [self.model.bert.config.label2id[label] for label in labels]\n",
        "\n",
        "        return labels, predictions\n",
        "\n",
        "    def compute_top_k(self, top_k):\n",
        "        result_list = self.compare_to_regions(self.train_data, self.test_data)\n",
        "        labels = []\n",
        "        predictions = []\n",
        "\n",
        "        for result in result_list:\n",
        "            labels.append(result['label'])\n",
        "            score_dict = result['similarity_scores']\n",
        "            keys = list(score_dict.keys())[:top_k]\n",
        "            # print(keys)\n",
        "            keys = [str(i) for i in keys]\n",
        "            # keys = [self.model.config.label2id[key] for key in keys]\n",
        "            predictions.append(keys)\n",
        "        # print(labels)\n",
        "        # predictions = [str(i) for i in predictions]\n",
        "        labels = [str(i) for i in labels]\n",
        "        # print(predictions)\n",
        "        # print(labels)\n",
        "        # labels = [self.model.config.label2id[label] for label in labels]\n",
        "        # labels = [str(i) for i in labels]\n",
        "\n",
        "        total_examples = len(labels)\n",
        "        correct_predictions = 0\n",
        "\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label in prediction[:top_k]:\n",
        "                correct_predictions += 1\n",
        "\n",
        "        top_k_accuracy = round((correct_predictions / total_examples),3)\n",
        "        print(f\"{top_k} accuracy: {top_k_accuracy}\")\n",
        "        return top_k_accuracy\n",
        "\n",
        "\n",
        "    def compute_metrics(self):\n",
        "        self.test_AA_acc()\n",
        "        result_list = self.compare_to_regions(self.train_loader, self.test_data, self.test_loader)\n",
        "        references, predictions = self.extract_labels_predictions(result_list)\n",
        "        predictions = [str(i) for i in predictions]\n",
        "        references = [str(i) for i in references]\n",
        "        # print(predictions)\n",
        "        # print(references)\n",
        "\n",
        "        metric_names = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
        "        metrics = {metric_name: load_metric(metric_name, trust_remote_code=True) for metric_name in metric_names}\n",
        "        results = {}\n",
        "        for metric_name, metric in metrics.items():\n",
        "            if metric_name == \"accuracy\":\n",
        "                score = metric.compute(predictions=predictions, references=references)\n",
        "            else:\n",
        "                try:\n",
        "                    score = metric.compute(predictions=predictions, references=references, average=\"weighted\")\n",
        "                except ValueError:\n",
        "                    score = metric.compute(predictions=predictions, references=references, average=None)\n",
        "\n",
        "            print(f\"{metric_name} score: {score}\")\n",
        "            results[metric_name] = score\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTq1ZaI_fRn7"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FQUGPUNUuYg"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe2_para_bert-base-cased_coe2.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe2_para_val0.73512_e24.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Train Step\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train_batch(train_data, test_data)\n",
        "\n",
        "    print(\"-------------------- Saving Model --------------------\")\n",
        "    # Save model\n",
        "    # torch.save(style_encoder.model.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/style_encoder.pt\")\n",
        "    # torch.save(content_encoder.encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # torch.save(dual_encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/dual_encoder.pt\")\n",
        "\n",
        "    torch.save(style_encoder.model.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\")\n",
        "    torch.save(content_encoder.encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "\n",
        "    # save_model(exp_dir, f'{id}_val{final_test_acc:.5f}_finale{epoch}.pt', model)\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    torch.save(dual_encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/dual_encoder.pt\")\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d38wMSMel-h5"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe2_para_bert-base-cased_coe2.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe2_para_val0.73512_e24.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Train Step\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train_batch(train_data, test_data)\n",
        "\n",
        "    print(\"-------------------- Saving Model --------------------\")\n",
        "    # Save model\n",
        "    # torch.save(style_encoder.model.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/style_encoder.pt\")\n",
        "    # torch.save(content_encoder.encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # torch.save(dual_encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/dual_encoder.pt\")\n",
        "\n",
        "    torch.save(style_encoder.model.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\")\n",
        "    torch.save(content_encoder.encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "\n",
        "    # save_model(exp_dir, f'{id}_val{final_test_acc:.5f}_finale{epoch}.pt', model)\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    torch.save(dual_encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/dual_encoder.pt\")\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW-mcpfNfOeF"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/processed/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/processed/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_supcon_bert-base-cased_coe1_temp0.1_unit2_epoch30/diffusiondb100_supcon_val0.78125_e26.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Train Step\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train_batch(train_data, test_data)\n",
        "\n",
        "    print(\"-------------------- Saving Model --------------------\")\n",
        "    # Save model\n",
        "    # torch.save(style_encoder.model.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/style_encoder.pt\")\n",
        "    # torch.save(content_encoder.encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/home/thao/home/contrastive_aa/disentangle_res/style_encoder\")\n",
        "    # torch.save(dual_encoder.state_dict(), \"/home/thao/home/contrastive_aa/disentangle_res/dual_encoder.pt\")\n",
        "\n",
        "    torch.save(style_encoder.model.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\")\n",
        "    torch.save(content_encoder.encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder.pt\")\n",
        "\n",
        "    # style_encoder.model.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    # style_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "\n",
        "    # save_model(exp_dir, f'{id}_val{final_test_acc:.5f}_finale{epoch}.pt', model)\n",
        "\n",
        "    # content_encoder.encoder.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/content_encoder\")\n",
        "    # content_encoder.tokenizer.save_pretrained(\"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder\")\n",
        "    torch.save(dual_encoder.state_dict(), \"/content/drive/MyDrive/msc_project/model/contrastive/club/dual_encoder.pt\")\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZEkhBsCtC8W"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv59ANA2lAiP"
      },
      "source": [
        "# current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z49G8Vs1WSIm"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0ptmUXa-__bS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/vary/train_random100_150_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/vary/val_random100_150_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/vary/test_random100_150_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_150_lcl_coe1_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_150_lcl_coe1_val0.73867_e29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8sfi8xXdLeu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_train.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_val.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_test.csv')\n",
        "    nlp_train = nlp_train[['text', 'author_id']]\n",
        "    # nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['text', 'author_id']]\n",
        "    # nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['text', 'author_id']]\n",
        "    # nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/blogs50_lcl_coe1_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/blogs50_lcl_coe1_val0.83212_finale29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rjrdkltOFZnS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_train.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_val.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_test.csv')\n",
        "    nlp_train = nlp_train[['text', 'author_id']]\n",
        "    # nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['text', 'author_id']]\n",
        "    # nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['text', 'author_id']]\n",
        "    # nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/blogs50_lcl_coe1_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/blogs50_lcl_coe1_val0.83212_finale29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvC5itvz3LtD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_train.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_val.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/blogs/processed/blogs50_AA_test.csv')\n",
        "    nlp_train = nlp_train[['text', 'author_id']]\n",
        "    # nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['text', 'author_id']]\n",
        "    # nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['text', 'author_id']]\n",
        "    # nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/blogs50_lcl_coe1_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/blogs50_lcl_coe1_val0.83212_finale29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN5i7dvVCVoD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_val0.73264_e16.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKRYaF6PC-j5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_topicseparate100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_topicseparate100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_topicseparate100_label_1.csv')\n",
        "    # nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train = nlp_train[['prompt', 'user_label']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    # nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val = nlp_val[['prompt', 'user_label']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    # nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test = nlp_test[['prompt', 'user_label']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "    # print(nlp_train['Target'])\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_topic_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_topic_val0.48859_e29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovNoItxvPQKK"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4PEYsiLOsyW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_val0.73264_e16.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    # print(\"-------------------- Evaluation --------------------\")\n",
        "    # save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    # dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RTTN85YyUMV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_val0.73264_e16.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yLJGV7Iyfnf"
      },
      "source": [
        "# others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3WULId5iLfS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_supcon_para_bert-base-cased_coe1_temp0.1_unit2_epoch30/diffusiondb100_supcon_para_val0.72321_e29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P706Wnvtmohd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe2_para_bert-base-cased_coe2.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe2_para_val0.73512_e24.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    print(\"-------------------- Training --------------------\")\n",
        "    dual_encoder.train(nlp_train, nlp_test)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUNdkqx5lBz1"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/processed/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/processed/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_supcon_bert-base-cased_coe1_temp0.1_unit2_epoch30/diffusiondb100_supcon_val0.78125_e26.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXZ_2hnT8ZIJ"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_supcon_para_bert-base-cased_coe1_temp0.1_unit2_epoch30/diffusiondb100_supcon_para_val0.72321_e29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n",
        "\n",
        "# average\n",
        "# accuracy score: {'accuracy': 0.7085}\n",
        "# precision score: {'precision': 0.7262531009903335}\n",
        "# recall score: {'recall': 0.7085}\n",
        "# f1 score: {'f1': 0.711030859836859}\n",
        "\n",
        "# accuracy score: {'accuracy': 0.7155}\n",
        "# precision score: {'precision': 0.7354965007653969}\n",
        "# recall score: {'recall': 0.7155}\n",
        "# f1 score: {'f1': 0.719259827630641}\n",
        "\n",
        "# kmeans\n",
        "# accuracy score: {'accuracy': 0.7085}\n",
        "# precision score: {'precision': 0.7262531009903335}\n",
        "# recall score: {'recall': 0.7085}\n",
        "# f1 score: {'f1': 0.711030859836859}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEN_OmS7fQoj"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_para_val0.72073_e29.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n",
        "\n",
        "# average\n",
        "# accuracy score: {'accuracy': 0.6865}\n",
        "# precision score: {'precision': 0.6929100874109159}\n",
        "# recall score: {'recall': 0.6865}\n",
        "# f1 score: {'f1': 0.6807407783602909}\n",
        "\n",
        "# accuracy score: {'accuracy': 0.71}\n",
        "# precision score: {'precision': 0.7129844761372993}\n",
        "# recall score: {'recall': 0.71}\n",
        "# f1 score: {'f1': 0.7040015279480824}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDS5Pbvmwvad"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_cls_para_bert-base-cased_coe0.0_temp0.1_unit2_epoch30/diffusiondb100_cls_para_val0.72073_e24.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8O2QxcWJg2H"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    train_data = get_csv_dataset(train_file)\n",
        "    test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    train_data = train_data['train'].shuffle()\n",
        "    test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe2_para_bert-base-cased_coe2.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe2_para_val0.73512_e24.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=train_data,\n",
        "                                 test_data=test_data)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=train_data,\n",
        "                                     test_data=test_data)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, train_data, test_data, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3UalscTvytB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    # train_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv\"\n",
        "    # test_file = \"/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv\"\n",
        "    # train_data = get_csv_dataset(train_file)\n",
        "    # test_data = get_csv_dataset(test_file)\n",
        "\n",
        "    # train_data = train_data.rename_column(\"user_name\", \"label\")\n",
        "    # train_data = train_data.rename_column(\"prompt\", \"sentence1\")\n",
        "    # test_data = test_data.rename_column(\"user_name\", \"label\")\n",
        "    # test_data = test_data.rename_column(\"prompt\", \"sentence1\")\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data = train_data['train'].shuffle().select(range(100))\n",
        "    # test_data = test_data['train'].shuffle().select(range(100))\n",
        "    # train_data = train_data['train'].shuffle()\n",
        "    # test_data = test_data['train'].shuffle()\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_val0.73264_e16.pt'\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder_1.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gqSbyJt2NoY"
      },
      "source": [
        "# current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln-E2yDYgHF7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club_0.73/style_encoder_supcon_18.pt\"    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_test_res\"\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club_0.73/style_encoder_supcon_18.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-y8CQSP6gvt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Example lists\n",
        "y_true = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99]\n",
        "\n",
        "\n",
        "y_pred = [0, 23, 81, 0, 78, 18, 0, 0, 69, 18, 0, 0, 36, 36, 0, 41, 52, 82, 0, 38, 1, 1, 1, 1, 84, 39, 1, 1, 29, 18, 1, 81, 1, 1, 1, 6, 1, 33, 1, 42, 2, 2, 2, 48, 2, 70, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 93, 2, 4, 2, 3, 3, 3, 3, 3, 3, 3, 39, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 68, 4, 94, 4, 4, 4, 4, 11, 4, 4, 4, 4, 41, 28, 53, 4, 4, 4, 4, 0, 52, 5, 5, 50, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 21, 72, 6, 6, 39, 6, 7, 6, 72, 75, 6, 6, 6, 6, 6, 72, 6, 6, 6, 6, 7, 7, 49, 74, 29, 23, 68, 7, 7, 74, 7, 7, 32, 7, 7, 94, 7, 7, 51, 7, 39, 8, 81, 29, 8, 8, 8, 8, 8, 47, 29, 68, 8, 7, 8, 81, 8, 73, 8, 57, 9, 9, 9, 9, 9, 9, 9, 82, 9, 9, 9, 9, 9, 9, 9, 58, 9, 9, 9, 29, 52, 85, 85, 39, 10, 10, 10, 10, 10, 43, 35, 29, 53, 26, 10, 90, 10, 10, 48, 46, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 53, 12, 12, 12, 49, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 80, 13, 13, 13, 13, 49, 13, 13, 13, 13, 84, 13, 26, 13, 29, 13, 13, 53, 13, 14, 14, 16, 65, 30, 47, 26, 14, 14, 31, 82, 37, 8, 15, 35, 43, 84, 14, 14, 14, 15, 78, 15, 35, 15, 15, 15, 15, 15, 15, 41, 15, 68, 15, 15, 15, 15, 15, 15, 68, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 48, 48, 17, 17, 17, 51, 31, 17, 17, 48, 17, 17, 17, 46, 68, 58, 41, 17, 17, 4, 18, 36, 86, 25, 18, 18, 18, 81, 18, 18, 74, 18, 18, 18, 18, 25, 18, 64, 47, 19, 86, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 34, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 73, 20, 21, 34, 98, 85, 29, 21, 21, 21, 21, 21, 21, 73, 21, 21, 21, 21, 34, 21, 21, 94, 47, 22, 22, 22, 22, 22, 22, 22, 22, 22, 33, 22, 22, 22, 22, 22, 22, 60, 22, 22, 14, 23, 23, 77, 23, 52, 67, 68, 23, 23, 13, 70, 23, 68, 23, 61, 23, 23, 52, 23, 24, 13, 24, 24, 24, 10, 24, 82, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 6, 25, 25, 7, 99, 61, 90, 25, 47, 25, 32, 25, 25, 25, 62, 25, 26, 26, 26, 26, 3, 26, 26, 26, 26, 81, 26, 26, 53, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 32, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 86, 28, 28, 28, 28, 10, 45, 6, 86, 29, 29, 10, 29, 29, 72, 33, 29, 47, 29, 29, 29, 53, 65, 29, 45, 30, 0, 30, 68, 45, 18, 30, 30, 30, 30, 41, 62, 30, 78, 30, 30, 30, 39, 0, 33, 31, 31, 31, 31, 31, 31, 84, 31, 31, 31, 10, 31, 31, 31, 31, 31, 31, 31, 18, 31, 52, 41, 32, 32, 7, 21, 32, 32, 32, 44, 32, 32, 32, 32, 94, 32, 32, 32, 32, 1, 33, 33, 33, 33, 33, 78, 33, 67, 33, 33, 67, 33, 41, 33, 47, 78, 33, 67, 29, 33, 34, 34, 77, 86, 18, 34, 34, 34, 34, 34, 38, 34, 18, 34, 46, 14, 34, 68, 34, 51, 18, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 33, 14, 35, 35, 35, 35, 35, 73, 36, 36, 36, 36, 36, 36, 36, 36, 8, 6, 36, 36, 70, 36, 36, 36, 36, 80, 36, 37, 37, 37, 37, 37, 81, 70, 37, 37, 34, 37, 52, 37, 73, 37, 37, 37, 37, 37, 52, 91, 38, 38, 38, 38, 38, 47, 38, 78, 38, 18, 38, 1, 38, 38, 38, 38, 38, 29, 0, 3, 39, 15, 7, 3, 39, 39, 29, 39, 39, 39, 4, 94, 10, 39, 21, 39, 39, 45, 45, 40, 40, 40, 89, 40, 32, 84, 38, 40, 40, 40, 40, 40, 93, 29, 40, 40, 40, 40, 40, 6, 41, 75, 1, 41, 6, 41, 26, 54, 41, 75, 41, 86, 41, 58, 41, 41, 0, 41, 38, 42, 42, 42, 42, 42, 42, 42, 42, 26, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 96, 43, 51, 73, 43, 43, 46, 43, 43, 58, 43, 46, 43, 43, 43, 43, 85, 43, 43, 14, 73, 44, 44, 44, 44, 44, 73, 44, 44, 73, 44, 74, 73, 82, 44, 26, 32, 21, 44, 47, 62, 94, 21, 73, 40, 45, 21, 3, 39, 45, 85, 45, 21, 73, 45, 45, 45, 23, 45, 73, 46, 4, 61, 46, 46, 84, 46, 46, 8, 46, 19, 31, 23, 46, 53, 10, 82, 46, 46, 46, 17, 30, 26, 47, 44, 47, 47, 56, 67, 47, 47, 47, 47, 47, 69, 84, 39, 47, 66, 48, 94, 48, 48, 48, 10, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 10, 49, 49, 49, 49, 49, 49, 49, 49, 15, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 61, 51, 51, 51, 51, 67, 51, 51, 51, 32, 51, 51, 85, 51, 51, 51, 51, 23, 52, 52, 5, 13, 52, 52, 52, 48, 52, 52, 84, 52, 52, 52, 49, 52, 52, 53, 93, 53, 53, 5, 53, 50, 53, 53, 61, 53, 90, 53, 33, 53, 53, 53, 53, 90, 35, 53, 94, 54, 67, 54, 35, 1, 65, 54, 54, 54, 7, 54, 54, 68, 32, 54, 97, 54, 54, 54, 32, 55, 55, 49, 55, 55, 55, 55, 55, 55, 55, 55, 55, 94, 55, 29, 55, 55, 55, 94, 55, 56, 42, 46, 56, 56, 56, 56, 56, 56, 56, 73, 56, 47, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 79, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 31, 57, 62, 39, 58, 39, 65, 58, 58, 58, 58, 65, 58, 86, 58, 58, 58, 58, 98, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 69, 59, 59, 59, 59, 60, 60, 60, 94, 60, 60, 60, 34, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 44, 61, 61, 61, 85, 61, 61, 16, 64, 61, 61, 7, 73, 61, 74, 64, 70, 62, 62, 39, 81, 62, 62, 62, 62, 85, 20, 31, 62, 62, 62, 62, 62, 1, 85, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 85, 64, 64, 7, 64, 64, 66, 3, 64, 64, 64, 41, 64, 64, 64, 64, 64, 65, 65, 86, 65, 41, 65, 65, 65, 65, 65, 65, 65, 65, 65, 95, 81, 65, 65, 65, 73, 66, 66, 66, 66, 66, 13, 66, 66, 33, 66, 66, 66, 66, 66, 66, 79, 66, 66, 66, 66, 74, 74, 67, 67, 67, 7, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 74, 67, 98, 23, 94, 75, 86, 68, 68, 49, 46, 91, 48, 68, 48, 81, 48, 58, 68, 68, 73, 65, 69, 69, 69, 78, 69, 21, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 3, 69, 69, 3, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 31, 55, 70, 70, 57, 9, 70, 70, 13, 14, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 93, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 78, 72, 73, 38, 73, 73, 73, 13, 73, 83, 94, 73, 73, 73, 73, 47, 73, 73, 73, 21, 21, 73, 74, 74, 74, 74, 74, 74, 74, 61, 33, 74, 74, 74, 74, 74, 74, 74, 74, 25, 74, 74, 62, 75, 75, 75, 75, 75, 75, 67, 75, 13, 75, 70, 75, 61, 51, 93, 71, 75, 61, 10, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 17, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 48, 78, 78, 78, 78, 78, 82, 78, 82, 78, 78, 78, 78, 61, 72, 78, 78, 78, 31, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 50, 80, 80, 80, 80, 80, 80, 80, 81, 81, 57, 81, 57, 51, 37, 81, 81, 81, 78, 81, 81, 31, 81, 81, 81, 81, 81, 98, 29, 55, 82, 82, 82, 78, 37, 54, 7, 82, 82, 46, 57, 82, 10, 82, 61, 40, 82, 82, 73, 83, 29, 83, 83, 24, 83, 83, 83, 73, 83, 83, 83, 29, 83, 85, 83, 83, 83, 94, 68, 61, 84, 84, 33, 84, 84, 84, 84, 84, 84, 16, 84, 84, 84, 51, 32, 84, 61, 5, 85, 7, 73, 45, 7, 85, 85, 86, 85, 85, 85, 85, 85, 3, 85, 69, 85, 29, 81, 85, 86, 86, 21, 86, 42, 86, 86, 86, 51, 8, 86, 86, 86, 86, 59, 86, 58, 86, 8, 42, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 47, 88, 83, 88, 88, 88, 88, 88, 88, 88, 88, 88, 74, 88, 88, 88, 89, 26, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 97, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 10, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 26, 91, 91, 91, 91, 18, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 41, 92, 92, 92, 79, 92, 93, 93, 52, 93, 93, 93, 93, 93, 93, 51, 93, 93, 93, 93, 93, 93, 93, 94, 88, 93, 18, 21, 34, 85, 94, 94, 41, 90, 94, 94, 94, 79, 94, 94, 98, 94, 94, 10, 94, 94, 95, 67, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 93, 81, 95, 96, 1, 94, 96, 58, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 61, 96, 94, 96, 94, 97, 97, 97, 97, 49, 97, 97, 97, 97, 97, 97, 97, 97, 97, 90, 97, 97, 97, 97, 97, 73, 98, 98, 98, 98, 98, 56, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 58, 99, 99, 99, 99, 44, 99, 99, 99, 99, 99, 99, 44, 99, 99, 99, 99, 99, 99, 99, 99]\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Precision, Recall, and F1 Score\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klsA1Vj_7Ibh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "def main(\n",
        "    batch_size: int,\n",
        "    num_epochs: int,\n",
        "    log_step: int,\n",
        "    num_iters: int,\n",
        "    # save_dir: str,\n",
        "    ):\n",
        "    # torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # Preare data\n",
        "    # data_files = {\n",
        "    #     \"train\": \"../../data/twitter_micro_train.json\",\n",
        "    #     \"test\": \"../../data/twitter_micro_test.json\"}\n",
        "    # train_data, test_data = get_dataset(data_files=data_files)\n",
        "\n",
        "    nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/train_random100_label_1.csv')\n",
        "    nlp_val = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/val_random100_label_1.csv')\n",
        "    nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/paraphrased/test_random100_label_1.csv')\n",
        "    nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "    nlp_train.columns = ['content', 'Target']\n",
        "    nlp_val = nlp_val[['prompt', 'user_name']]\n",
        "    nlp_val.columns = ['content', 'Target']\n",
        "    nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "    nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "    # train_data, test_data = get_samples(data_files=data_files,len_train_sample=10000, len_test_sample=10000)\n",
        "\n",
        "    # Load pretrained model\n",
        "    # style_checkpoint = \"/home/thao/home/contrastive_aa/AA_region_cls\"\n",
        "    style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/lcl/diffusiondb100_lcl_coe1_para_bert-base-cased_coe1.0_temp0.1_unit2_epoch30/diffusiondb100_lcl_coe1_para_val0.73264_e16.pt'\n",
        "    content_checkpoint = \"bert-base-cased\"\n",
        "\n",
        "    # Build model\n",
        "    style_encoder = StyleEncoder(checkpoint=style_checkpoint,\n",
        "                                 train_data=nlp_train,\n",
        "                                 test_data=nlp_test)\n",
        "\n",
        "    content_encoder = ContentEncoder(checkpoint=content_checkpoint,\n",
        "                                     train_data=nlp_train,\n",
        "                                     test_data=nlp_test)\n",
        "\n",
        "    dual_encoder = DualEncoder(content_encoder=content_encoder,\n",
        "                               style_encoder=style_encoder,\n",
        "                               num_epochs=num_epochs,\n",
        "                               batch_size=batch_size,\n",
        "                               num_iters=num_iters,\n",
        "                               log_step=log_step)\n",
        "\n",
        "    # Test Step\n",
        "    print(\"-------------------- Evaluation --------------------\")\n",
        "    save_dir = \"/content/drive/MyDrive/msc_project/model/contrastive/club/result.json\"\n",
        "    # style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club_0.73/style_encoder_supcon_18.pt\"\n",
        "    dual_encoder.test_step(style_checkpoint, nlp_train, nlp_test, save_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=20)\n",
        "    parser.add_argument(\"--num_iters\", type=int, default=100)\n",
        "    # parser.add_argument(\"--save_dir\", type=str)\n",
        "    parser.add_argument(\"--log_step\", type=int, default=10)\n",
        "    # parser.add_argument(\"--do_train\", action=\"store_true\")\n",
        "    # parser.add_argument(\"--do_evaluation\", action=\"store_true\")\n",
        "\n",
        "    training_args = {\n",
        "      'batch_size': 32,\n",
        "      'num_epochs': 20,\n",
        "      'num_iters': 1,\n",
        "      'log_step': 10,\n",
        "    }\n",
        "\n",
        "    # parse args\n",
        "    # args = parser.parse_args(**vars(training_args))\n",
        "\n",
        "    main(**training_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlAOu8Re6gzO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Joi2BOKfw8"
      },
      "source": [
        "# test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am0VZzbjKhIt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "\n",
        "class CLUBForCategorical(nn.Module): # Update 04/27/2022\n",
        "    '''\n",
        "    This class provide a CLUB estimator to calculate MI upper bound between vector-like embeddings and categorical labels.\n",
        "    Estimate I(X,Y), where X is continuous vector and Y is discrete label.\n",
        "    '''\n",
        "    def __init__(self, input_dim, label_num, hidden_size=None):\n",
        "        '''\n",
        "        input_dim : the dimension of input embeddings\n",
        "        label_num : the number of categorical labels\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        if hidden_size is None:\n",
        "            self.variational_net = nn.Linear(input_dim, label_num)\n",
        "        else:\n",
        "            self.variational_net = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_size, label_num)\n",
        "            )\n",
        "\n",
        "    def forward(self, inputs, labels):\n",
        "        '''\n",
        "        inputs : shape [batch_size, input_dim], a batch of embeddings\n",
        "        labels : shape [batch_size], a batch of label index\n",
        "        '''\n",
        "        logits = self.variational_net(inputs)  #[sample_size, label_num]\n",
        "\n",
        "        # log of conditional probability of positive sample pairs\n",
        "        #positive = - nn.functional.cross_entropy(logits, labels, reduction='none')\n",
        "        sample_size, label_num = logits.shape\n",
        "\n",
        "        logits_extend = logits.unsqueeze(1).repeat(1, sample_size, 1)  # shape [sample_size, sample_size, label_num]\n",
        "        labels_extend = labels.unsqueeze(0).repeat(sample_size, 1)     # shape [sample_size, sample_size]\n",
        "\n",
        "        # log of conditional probability of negative sample pairs\n",
        "        log_mat = - nn.functional.cross_entropy(\n",
        "            logits_extend.reshape(-1, label_num),\n",
        "            labels_extend.reshape(-1, ),\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        log_mat = log_mat.reshape(sample_size, sample_size)\n",
        "        positive = torch.diag(log_mat).mean()\n",
        "        negative = log_mat.mean()\n",
        "        return positive - negative\n",
        "\n",
        "    def loglikeli(self, inputs, labels):\n",
        "        logits = self.variational_net(inputs)\n",
        "        return - nn.functional.cross_entropy(logits, labels)\n",
        "\n",
        "    def learning_loss(self, inputs, labels):\n",
        "        return - self.loglikeli(inputs, labels)\n",
        "\n",
        "\n",
        "class CLUB(nn.Module):  # CLUB: Mutual Information Contrastive Learning Upper Bound\n",
        "    '''\n",
        "        This class provides the CLUB estimation to I(X,Y)\n",
        "        Method:\n",
        "            forward() :      provides the estimation with input samples\n",
        "            loglikeli() :   provides the log-likelihood of the approximation q(Y|X) with input samples\n",
        "        Arguments:\n",
        "            x_dim, y_dim :         the dimensions of samples from X, Y respectively\n",
        "            hidden_size :          the dimension of the hidden layer of the approximation network q(Y|X)\n",
        "            x_samples, y_samples : samples from X and Y, having shape [sample_size, x_dim/y_dim]\n",
        "    '''\n",
        "    def __init__(self, x_dim, y_dim, hidden_size):\n",
        "        super(CLUB, self).__init__()\n",
        "        # p_mu outputs mean of q(Y|X)\n",
        "        #print(\"create CLUB with dim {}, {}, hiddensize {}\".format(x_dim, y_dim, hidden_size))\n",
        "        self.p_mu = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(hidden_size//2, y_dim))\n",
        "        # p_logvar outputs log of variance of q(Y|X)\n",
        "        self.p_logvar = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(hidden_size//2, y_dim),\n",
        "                                       nn.Tanh())\n",
        "\n",
        "    def get_mu_logvar(self, x_samples):\n",
        "        mu = self.p_mu(x_samples)\n",
        "        logvar = self.p_logvar(x_samples)\n",
        "        return mu, logvar\n",
        "\n",
        "    def forward(self, x_samples, y_samples):\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "\n",
        "        # log of conditional probability of positive sample pairs\n",
        "        positive = - (mu - y_samples)**2 /2./logvar.exp()\n",
        "\n",
        "        prediction_1 = mu.unsqueeze(1)          # shape [nsample,1,dim]\n",
        "        y_samples_1 = y_samples.unsqueeze(0)    # shape [1,nsample,dim]\n",
        "\n",
        "        # log of conditional probability of negative sample pairs\n",
        "        negative = - ((y_samples_1 - prediction_1)**2).mean(dim=1)/2./logvar.exp()\n",
        "\n",
        "        return (positive.sum(dim = -1) - negative.sum(dim = -1)).mean()\n",
        "\n",
        "    def loglikeli(self, x_samples, y_samples): # unnormalized loglikelihood\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "        return (-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1).mean(dim=0)\n",
        "\n",
        "    def learning_loss(self, x_samples, y_samples):\n",
        "        return - self.loglikeli(x_samples, y_samples)\n",
        "\n",
        "\n",
        "class CLUBMean(nn.Module):  # Set variance of q(y|x) to 1, logvar = 0. Update 11/26/2022\n",
        "    def __init__(self, x_dim, y_dim, hidden_size=None):\n",
        "        # p_mu outputs mean of q(Y|X)\n",
        "        # print(\"create CLUB with dim {}, {}, hiddensize {}\".format(x_dim, y_dim, hidden_size))\n",
        "\n",
        "        super(CLUBMean, self).__init__()\n",
        "\n",
        "        if hidden_size is None:\n",
        "            self.p_mu = nn.Linear(x_dim, y_dim)\n",
        "        else:\n",
        "            self.p_mu = nn.Sequential(nn.Linear(x_dim, int(hidden_size)),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(int(hidden_size), y_dim))\n",
        "\n",
        "\n",
        "    def get_mu_logvar(self, x_samples):\n",
        "        # variance is set to 1, which means logvar=0\n",
        "        mu = self.p_mu(x_samples)\n",
        "        return mu, 0\n",
        "\n",
        "    def forward(self, x_samples, y_samples):\n",
        "\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "\n",
        "        # log of conditional probability of positive sample pairs\n",
        "        positive = - (mu - y_samples)**2 /2.\n",
        "\n",
        "        prediction_1 = mu.unsqueeze(1)          # shape [nsample,1,dim]\n",
        "        y_samples_1 = y_samples.unsqueeze(0)    # shape [1,nsample,dim]\n",
        "\n",
        "        # log of conditional probability of negative sample pairs\n",
        "        negative = - ((y_samples_1 - prediction_1)**2).mean(dim=1)/2.\n",
        "\n",
        "        return (positive.sum(dim = -1) - negative.sum(dim = -1)).mean()\n",
        "\n",
        "    def loglikeli(self, x_samples, y_samples): # unnormalized loglikelihood\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "        return (-(mu - y_samples)**2).sum(dim=1).mean(dim=0)\n",
        "\n",
        "    def learning_loss(self, x_samples, y_samples):\n",
        "        return - self.loglikeli(x_samples, y_samples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CLUBSample(nn.Module):  # Sampled version of the CLUB estimator\n",
        "    def __init__(self, x_dim, y_dim, hidden_size):\n",
        "        super(CLUBSample, self).__init__()\n",
        "        self.p_mu = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(hidden_size//2, y_dim))\n",
        "\n",
        "        self.p_logvar = nn.Sequential(nn.Linear(x_dim, hidden_size//2),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(hidden_size//2, y_dim),\n",
        "                                       nn.Tanh())\n",
        "\n",
        "    def get_mu_logvar(self, x_samples):\n",
        "        mu = self.p_mu(x_samples)\n",
        "        logvar = self.p_logvar(x_samples)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "    def loglikeli(self, x_samples, y_samples):\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "        return (-(mu - y_samples)**2 /logvar.exp()-logvar).sum(dim=1).mean(dim=0)\n",
        "\n",
        "\n",
        "    def forward(self, x_samples, y_samples):\n",
        "        mu, logvar = self.get_mu_logvar(x_samples)\n",
        "\n",
        "        sample_size = x_samples.shape[0]\n",
        "        #random_index = torch.randint(sample_size, (sample_size,)).long()\n",
        "        random_index = torch.randperm(sample_size).long()\n",
        "\n",
        "        positive = - (mu - y_samples)**2 / logvar.exp()\n",
        "        negative = - (mu - y_samples[random_index])**2 / logvar.exp()\n",
        "        upper_bound = (positive.sum(dim = -1) - negative.sum(dim = -1)).mean()\n",
        "        return upper_bound/2.\n",
        "\n",
        "    def learning_loss(self, x_samples, y_samples):\n",
        "        return - self.loglikeli(x_samples, y_samples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSsKMfTRLEap"
      },
      "outputs": [],
      "source": [
        "class GaussianSampler(nn.Module):\n",
        "    def __init__(self, dim, para_list = None):\n",
        "        super(GaussianSampler, self).__init__()\n",
        "        self.dim = dim\n",
        "        if para_list is None:\n",
        "            para_list = [0.55] * dim\n",
        "        self.p_theta_ = torch.nn.Parameter(torch.tensor(para_list, requires_grad = True))\n",
        "\n",
        "    def get_trans_mat(self):\n",
        "        p_theta = self.p_theta_.cuda().unsqueeze(-1)\n",
        "        #p_theta = torch.softmax(p_theta, dim = 0)\n",
        "\n",
        "        trans_row1 = torch.cat((torch.sin(p_theta),torch.cos(p_theta)), dim=-1).unsqueeze(-1)\n",
        "        trans_row2 = torch.cat((torch.cos(p_theta),torch.sin(p_theta)), dim=-1).unsqueeze(-1)  #[dim, 2,1]\n",
        "        return torch.cat((trans_row1, trans_row2), dim=-1)  #[dim,2,2]\n",
        "\n",
        "    def gen_samples(self, num_sample, cuda = True):\n",
        "        noise= torch.randn(self.dim,num_sample,2).cuda()\n",
        "        trans_mat = self.get_trans_mat()\n",
        "        samples = torch.bmm(noise, trans_mat).transpose(0,1) #[dim, nsample, 2]\n",
        "        if not cuda:\n",
        "            samples = samples.cpu().detach().numpy()\n",
        "        return samples[:,:,0], samples[:,:,1]\n",
        "\n",
        "    def get_covariance(self):\n",
        "        p_theta = self.p_theta_.cuda()\n",
        "        return (2.*torch.sin(p_theta)*torch.cos(p_theta))\n",
        "\n",
        "    def get_MI(self):\n",
        "        rho = self.get_covariance()\n",
        "        return -1./2.*torch.log(1-rho**2).sum().item()\n",
        "        #return -self.dim /2.*torch.log(1-rho**2 / 2).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsKl2_aMLHQd"
      },
      "outputs": [],
      "source": [
        "lr = 1e-4\n",
        "batch_size = 100\n",
        "num_iter = 5000\n",
        "sample_dim = 2\n",
        "hidden_size = 5\n",
        "estimator_name = \"CLUB\"\n",
        "\n",
        "\n",
        "sampler = GaussianSampler(sample_dim).cuda()\n",
        "#print(\"The corvariance of Gaussian is {}\".format(sampler.get_covariance().cpu().detach().numpy()))\n",
        "x_sample, y_sample = sampler.gen_samples(1000, cuda = False)\n",
        "plt.scatter(x_sample, y_sample)\n",
        "plt.show()\n",
        "\n",
        "mi_estimator = eval(estimator_name)(sample_dim, sample_dim, hidden_size).cuda()\n",
        "\n",
        "sampler_optimizer = torch.optim.Adam(sampler.parameters(), lr = lr)\n",
        "mi_optimizer = torch.optim.Adam(mi_estimator.parameters(), lr = lr)\n",
        "\n",
        "mi_true_values = []\n",
        "mi_est_values = []\n",
        "mi_loss_all = []\n",
        "sampler_loss_all = []\n",
        "min_mi = 100.\n",
        "\n",
        "for i in range(num_iter):\n",
        "    sampler.train()\n",
        "    mi_estimator.eval()\n",
        "    x_samples, y_samples = sampler.gen_samples(batch_size)\n",
        "    sampler_loss = mi_estimator(x_samples, y_samples)\n",
        "    sampler_optimizer.zero_grad()\n",
        "    sampler_loss.backward() # retain_graph=True)\n",
        "    sampler_optimizer.step()\n",
        "\n",
        "    mi_losses = 0\n",
        "    for j in range(5):\n",
        "        mi_estimator.train()\n",
        "        x_samples, y_samples = sampler.gen_samples(batch_size)\n",
        "        mi_loss = mi_estimator.learning_loss(x_samples, y_samples)\n",
        "        # mi_losses += mi_loss.item()\n",
        "        mi_optimizer.zero_grad()\n",
        "        mi_loss.backward()\n",
        "        mi_optimizer.step()\n",
        "        mi_losses += mi_loss.item()\n",
        "        # print(mi_loss.item())\n",
        "\n",
        "    mi_true_values.append(sampler.get_MI())\n",
        "    mi_est_values.append(mi_estimator(x_samples, y_samples).item())\n",
        "    mi_loss_all.append(mi_losses / 5)\n",
        "    sampler_loss_all.append(sampler_loss.item())\n",
        "    if i % 100 ==0:\n",
        "        print(\"step {}, true MI value {}, estimated MI value {}, MI loss {}, sampler loss {}\".format(i, sampler.get_MI(), mi_estimator(x_samples, y_samples).item(), mi_losses / 5, sampler_loss.item()))\n",
        "\n",
        "\n",
        "plt.plot(np.arange(len(mi_est_values)), mi_est_values, label=estimator_name + \" est\")\n",
        "plt.plot(np.arange(len(mi_true_values)), mi_true_values, label=\"True MI value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(mi_est_values)), sampler_loss_all)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(mi_est_values)), mi_loss_all)\n",
        "plt.show()\n",
        "\n",
        "x_sample, y_sample = sampler.gen_samples(1000, cuda=False)\n",
        "plt.scatter(x_sample, y_sample)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OVs1PxmkqK"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq5HLfLvMyrR"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0):\n",
        "        super().__init__()\n",
        "        print(f'Logistic Regression classifier of dim ({in_dim} {hid_dim} {out_dim})')\n",
        "\n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(in_dim, hid_dim, bias=True),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(hid_dim, out_dim, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        out = self.nn(x)\n",
        "        if return_feat:\n",
        "            return out, x\n",
        "        return out\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    FEAT_LEN = 768\n",
        "\n",
        "    def __init__(self, raw_bert, classifier):\n",
        "        super().__init__()\n",
        "        self.bert = raw_bert\n",
        "        self.fc = classifier\n",
        "\n",
        "    def forward(self, x, return_feat=False):\n",
        "        # x is a tokenized input\n",
        "        # feature = self.bert(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
        "        feature = self.bert(input_ids=x[0], attention_mask=x[2])\n",
        "        # print(feature.last_hidden_state.shape)\n",
        "        # out = self.fc(feature.pooler_output.flatten(1))       # not good for our task     # (BS, E)\n",
        "        out = self.fc(feature.last_hidden_state.flatten(1))  # (BS, T, E)\n",
        "        if return_feat:\n",
        "            return out, feature.last_hidden_state, feature\n",
        "        return out\n",
        "\n",
        "\n",
        "def load_model_dic(model, ckpt_path, verbose=True, strict=True):\n",
        "    \"\"\"\n",
        "    Load weights to model and take care of weight parallelism\n",
        "    \"\"\"\n",
        "    assert os.path.exists(ckpt_path), f\"trained model {ckpt_path} does not exist\"\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(ckpt_path), strict=strict)\n",
        "    except:\n",
        "        state_dict = torch.load(ckpt_path)\n",
        "        state_dict = {k.partition('module.')[2]: state_dict[k] for k in state_dict.keys()}\n",
        "        model.load_state_dict(state_dict, strict=strict)\n",
        "    if verbose:\n",
        "        print(f'Model loaded: {ckpt_path}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_model(ckpt_dir, cp_name, model):\n",
        "    \"\"\"\n",
        "    Create directory /Checkpoint under exp_data_path and save encoder as cp_name\n",
        "    \"\"\"\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    saving_model_path = os.path.join(ckpt_dir, cp_name)\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        model = model.module  # convert to non-parallel form\n",
        "    torch.save(model.state_dict(), saving_model_path)\n",
        "    print(f'Model saved: {saving_model_path}')\n",
        "\n",
        "\n",
        "class StyleEncoder():\n",
        "    def __init__(\n",
        "            self,\n",
        "            checkpoint,\n",
        "            train_data,\n",
        "            test_data):\n",
        "\n",
        "        self.checkpoint = checkpoint\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "\n",
        "        # self.model = BertModel.from_pretrained(checkpoint)\n",
        "        num_tokens, hidden_dim, out_dim, dropout = 256, 512, 100, 0.35\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
        "        extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "        model = BertClassifier(extractor, LogisticRegression(768 * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "        self.model = load_model_dic(model, checkpoint, verbose=True, strict=True)\n",
        "        # self.tokenizer = BertTokenizer.from_pretrained(checkpoint, padding=True, truncation=True)\n",
        "        # self.model = BertModel.from_pretrained(checkpoint)\n",
        "        self.parameters = self.model.parameters()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.max_length = 256\n",
        "\n",
        "    def prepare_inputs(self, examples):\n",
        "        tokenizer = self.tokenizer\n",
        "        inputs = tokenizer.encode_plus(examples['sentence1'], padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "        return inputs\n",
        "\n",
        "    def prepare_data(self, data):\n",
        "        processed_data = data.map(self.prepare_inputs)\n",
        "        processed_data = processed_data.remove_columns([\"sentence1\", \"label\"])\n",
        "        processed_data.set_format(type=\"torch\",)\n",
        "        return processed_data\n",
        "\n",
        "    def get_style(self, encoded_dict):\n",
        "        data_input_ids = encoded_dict['input_ids'].to(self.device)\n",
        "        data_attention_mask = encoded_dict['attention_mask'].to(self.device)\n",
        "        data_token_type_ids = encoded_dict['token_type_ids'].to(self.device)\n",
        "        x = data_input_ids, data_token_type_ids, data_attention_mask\n",
        "        with torch.no_grad():\n",
        "            # model_output = self.model(input_ids=data_input_ids, attention_mask=data_attention_mask)\n",
        "            pred, feats, model_output = self.model(x, return_feat=True)\n",
        "        # sentence_embedding = self.mean_pooling(model_output, encoded_dict['attention_mask'])\n",
        "        # last_hidden_states = model_output.last_hidden_state\n",
        "        # return last_hidden_states\n",
        "        return feats\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "from math import log\n",
        "\n",
        "class SupConLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.1, margin=0.2):\n",
        "        \"\"\"\n",
        "        Implementation of the loss described in the paper Supervised Contrastive Learning :\n",
        "        https://arxiv.org/abs/2004.11362\n",
        "        :param temperature: int\n",
        "        \"\"\"\n",
        "        super(SupConLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, projections, targets):\n",
        "        \"\"\"\n",
        "        :param projections: torch.Tensor, shape [batch_size, projection_dim]\n",
        "        :param targets: torch.Tensor, shape [batch_size]\n",
        "        :return: torch.Tensor, scalar\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\") if projections.is_cuda else torch.device(\"cpu\")\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        # dot_product_tempered = torch.mm(projections, projections.T) / self.temperature\n",
        "        # The cosine similarity between all pairs of projection vectors is computed\n",
        "        dot_product_tempered = self.cos(projections.unsqueeze(1), projections.unsqueeze(0)) / self.temperature\n",
        "\n",
        "        # Compute softmax probabilities over all pairs (positive and negative)\n",
        "        # Minus max for numerical stability with exponential. Same done in cross entropy. Epsilon added to avoid log(0)\n",
        "        exp_dot_tempered = (\n",
        "            torch.exp(dot_product_tempered - torch.max(dot_product_tempered, dim=1, keepdim=True)[0]) + 1e-5\n",
        "        )\n",
        "        # Identify positive pairs for each anchor sample\n",
        "        # This mask identifies pairs of samples that belong to the same class\n",
        "        mask_similar_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) == targets).to(device)\n",
        "        # This mask removes the self-similarity (diagonal elements)\n",
        "        mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0])).to(device)\n",
        "        # This is the combined mask that identifies positive pairs (i.e., samples that belong to the same class but are not the same sample)\n",
        "        mask_combined_pos = mask_similar_class * mask_anchor_out\n",
        "\n",
        "        mask_diff_class = (targets.unsqueeze(1).repeat(1, targets.shape[0]) != targets).to(device)\n",
        "        mask_combined_neg = mask_diff_class * mask_anchor_out\n",
        "\n",
        "        # exp_sum = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
        "        # probabilities = exp_dot_tempered / (exp_sum + 1e-5)\n",
        "\n",
        "        # Compute number of relevant positive samples for each anchor sample\n",
        "        cardinality_pos = torch.sum(mask_combined_pos, dim=1)\n",
        "\n",
        "        # to avoid nan value of the loss if there is only one sample of a category  on the batch\n",
        "        # Ensures that if there's only one sample of a class (i.e., no positive pairs), the division by zero is avoided by setting the count to 1\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        # # Compute log probability of positive pairs\n",
        "        # log_prob = -torch.log(exp_dot_tempered / (torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)))\n",
        "        # supervised_contrastive_loss_per_sample = torch.sum(log_prob * mask_combined_pos, dim=1) / cardinality_pos\n",
        "        # supervised_contrastive_loss = torch.mean(supervised_contrastive_loss_per_sample)\n",
        "\n",
        "        # Sum of the exponentiated similarities for the negative pairs\n",
        "        exp_sum_neg = torch.sum(exp_dot_tempered * mask_combined_neg, dim=1)\n",
        "        prob = exp_dot_tempered / (exp_dot_tempered + exp_sum_neg + 1e-5)\n",
        "\n",
        "        log_prob = -torch.log(prob) * mask_combined_pos\n",
        "        for i in range(cardinality_pos.size(0)):\n",
        "            if cardinality_pos[i]==0:\n",
        "                cardinality_pos[i] = 1\n",
        "\n",
        "        total_loss = torch.mean(torch.sum(log_prob, dim=1) / cardinality_pos)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "class BertDataset(Dataset):\n",
        "    def __init__(self, x, y, tokenizer, length=128, return_idx=False):\n",
        "        super(BertDataset, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.length = length\n",
        "        self.x = x\n",
        "        self.return_idx = return_idx\n",
        "        self.y = torch.tensor(y)\n",
        "        self.tokens_cache = {}\n",
        "\n",
        "    def tokenize(self, x):\n",
        "        dic = self.tokenizer.batch_encode_plus(\n",
        "            [x],  # input must be a list\n",
        "            max_length=self.length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return [x[0] for x in dic.values()]  # get rid of the first dim\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        int_idx = int(idx)\n",
        "        assert idx == int_idx\n",
        "        idx = int_idx\n",
        "        if idx not in self.tokens_cache:\n",
        "            self.tokens_cache[idx] = self.tokenize(self.x[idx])\n",
        "        input_ids, token_type_ids, attention_mask = self.tokens_cache[idx]\n",
        "        if self.return_idx:\n",
        "            return input_ids, token_type_ids, attention_mask, self.y[idx], idx, self.x[idx]\n",
        "        return input_ids, token_type_ids, attention_mask, self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "\n",
        "def get_csv_dataset(data_file):\n",
        "    dataset = load_dataset(\"csv\", data_files=data_file)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Itx3NdW9ud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/processed/train_random100_label_1.csv')\n",
        "nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/processed/test_random100_label_1.csv')\n",
        "nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "nlp_train.columns = ['content', 'Target']\n",
        "nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "nlp_test.columns = ['content', 'Target']\n",
        "\n",
        "\n",
        "limit = 100\n",
        "print(\"Number of authors: \", limit)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "style_checkpoint = \"/content/drive/MyDrive/msc_project/model/contrastive/club/style_encoder.pt\"\n",
        "\n",
        "num_tokens, hidden_dim, out_dim, dropout = 256, 512, 100, 0.35\n",
        "ngpus, base_bs = 1, 32\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
        "extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "model = BertClassifier(extractor, LogisticRegression(768 * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "model = load_model_dic(model, style_checkpoint, verbose=True, strict=True)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# get dataset\n",
        "test_x, test_y = nlp_test['content'].tolist(), nlp_test['Target'].tolist()\n",
        "test_set = BertDataset(test_x, test_y, tokenizer, num_tokens)\n",
        "test_loader = DataLoader(test_set, batch_size=base_bs * ngpus, shuffle=False, num_workers=4 * ngpus,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "supcon = SupConLoss()\n",
        "coefficient = 1\n",
        "\n",
        "model.eval()\n",
        "pg = tqdm(test_loader, leave=False, total=len(test_loader), disable=False)\n",
        "\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_acc = AverageMeter()\n",
        "    test_loss_1 = AverageMeter()\n",
        "    test_loss_2 = AverageMeter()\n",
        "    test_loss = AverageMeter()\n",
        "\n",
        "    for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "        x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "        pred, feats, model_output = model(x, return_feat=True)\n",
        "\n",
        "        # classification\n",
        "        loss_1 = criterion(pred, y.long())\n",
        "\n",
        "        # contrastive learning\n",
        "        # sim_matrix = compute_sim_matrix(feats)\n",
        "        # target_matrix = compute_target_matrix(y)\n",
        "        # loss_2 = contrastive_loss(sim_matrix, target_matrix, temperature, y)\n",
        "        loss_2 = supcon(pred, y.long())\n",
        "\n",
        "        # total loss\n",
        "        loss = loss_1 + coefficient * loss_2\n",
        "        # loss = loss_2\n",
        "        # loss = loss_1\n",
        "        # loss_2 = loss_1\n",
        "\n",
        "        # logger\n",
        "        test_acc.update((pred.argmax(1) == y).sum().item() / len(y))\n",
        "        test_loss.update(loss.item())\n",
        "        test_loss_1.update(loss_1.item())\n",
        "        test_loss_2.update(loss_2.item())\n",
        "\n",
        "        # Append the predictions and labels to the lists\n",
        "        all_preds.extend(pred.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "        pg.set_postfix({\n",
        "            'test acc': '{:.6f}'.format(test_acc.avg),\n",
        "            # 'epoch': '{:03d}'.format(epoch)\n",
        "        })\n",
        "        print(pred.argmax(1), y, test_acc.avg)\n",
        "\n",
        "# After the loop, you can now use all_preds and all_labels as needed\n",
        "print(\"All Predictions:\", all_preds)\n",
        "print(\"All Labels:\", all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = np.mean(all_preds == all_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(test_acc.avg)\n",
        "print(test_loss.avg)\n",
        "print(test_loss_1.avg)\n",
        "print(test_loss_2.avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPuBdTe2clQV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "nlp_train = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/processed/train_random100_label_1.csv')\n",
        "nlp_test = pd.read_csv('/content/drive/MyDrive/msc_project/data/diffusiondb/processed/test_random100_label_1.csv')\n",
        "nlp_train = nlp_train[['prompt', 'user_name']]\n",
        "nlp_train.columns = ['content', 'Target']\n",
        "nlp_test = nlp_test[['prompt', 'user_name']]\n",
        "nlp_test.columns = ['content', 'Target']\n",
        "print(len(nlp_test))\n",
        "prompt_counts = nlp_test.groupby('Target').size()\n",
        "\n",
        "print(prompt_counts)\n",
        "\n",
        "limit = 100\n",
        "print(\"Number of authors: \", limit)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "style_checkpoint = '/content/drive/MyDrive/msc_project/model/contrastive/contrax/exp_data/diffusiondb100_supcon_cls_bert-base-cased_coe1_temp0.1_unit6_epoch30/diffusiondb100_supcon_cls_val0.79216_e24.pt'\n",
        "\n",
        "\n",
        "num_tokens, hidden_dim, out_dim, dropout = 256, 512, 100, 0.35\n",
        "ngpus, base_bs = 1, 32\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
        "extractor = BertModel.from_pretrained('bert-base-cased')\n",
        "model = BertClassifier(extractor, LogisticRegression(768 * num_tokens, hidden_dim, out_dim, dropout=dropout))\n",
        "model = load_model_dic(model, style_checkpoint, verbose=True, strict=True)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# get dataset\n",
        "test_x, test_y = nlp_test['content'].tolist(), nlp_test['Target'].tolist()\n",
        "test_set = BertDataset(test_x, test_y, tokenizer, num_tokens)\n",
        "test_loader = DataLoader(test_set, batch_size=base_bs * ngpus, shuffle=False, num_workers=4 * ngpus,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "supcon = SupConLoss()\n",
        "coefficient = 1\n",
        "\n",
        "model.eval()\n",
        "pg = tqdm(test_loader, leave=False, total=len(test_loader), disable=False)\n",
        "\n",
        "# Initialize lists to store predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_acc = AverageMeter()\n",
        "    test_loss_1 = AverageMeter()\n",
        "    test_loss_2 = AverageMeter()\n",
        "    test_loss = AverageMeter()\n",
        "\n",
        "    for i, (x1, x2, x3, y) in enumerate(pg):\n",
        "        x, y = (x1.cuda(), x2.cuda(), x3.cuda()), y.cuda()\n",
        "        pred, feats, model_output = model(x, return_feat=True)\n",
        "\n",
        "        # classification\n",
        "        loss_1 = criterion(pred, y.long())\n",
        "\n",
        "        # contrastive learning\n",
        "        # sim_matrix = compute_sim_matrix(feats)\n",
        "        # target_matrix = compute_target_matrix(y)\n",
        "        # loss_2 = contrastive_loss(sim_matrix, target_matrix, temperature, y)\n",
        "        loss_2 = supcon(pred, y.long())\n",
        "\n",
        "        # total loss\n",
        "        loss = loss_1 + coefficient * loss_2\n",
        "        # loss = loss_2\n",
        "        # loss = loss_1\n",
        "        # loss_2 = loss_1\n",
        "\n",
        "        # logger\n",
        "        test_acc.update((pred.argmax(1) == y).sum().item() / len(y))\n",
        "        test_loss.update(loss.item())\n",
        "        test_loss_1.update(loss_1.item())\n",
        "        test_loss_2.update(loss_2.item())\n",
        "\n",
        "        # Append the predictions and labels to the lists\n",
        "        all_preds.extend(pred.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "        pg.set_postfix({\n",
        "            'test acc': '{:.6f}'.format(test_acc.avg),\n",
        "            # 'epoch': '{:03d}'.format(epoch)\n",
        "        })\n",
        "        print(pred.argmax(1), y, test_acc.avg)\n",
        "\n",
        "# After the loop, you can now use all_preds and all_labels as needed\n",
        "print(\"All Predictions:\", all_preds)\n",
        "print(\"All Labels:\", all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = np.mean(all_preds == all_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(test_acc.avg)\n",
        "print(test_loss.avg)\n",
        "print(test_loss_1.avg)\n",
        "print(test_loss_2.avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNJB-qZ-cvE2"
      },
      "outputs": [],
      "source": [
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = np.mean(all_preds == all_labels)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovu8NAMvjPps"
      },
      "outputs": [],
      "source": [
        "all_preds1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 1, 1, 1, 1, 1, 1, 51, 1, 1, 95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 97, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 76, 5, 5, 5, 76, 5, 5, 5, 5, 5, 5, 5, 6, 6, 43, 6, 84, 6, 6, 14, 6, 55, 28, 6, 6, 74, 6, 6, 6, 74, 6, 6, 7, 37, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 44, 54, 8, 8, 8, 35, 8, 8, 8, 8, 8, 15, 8, 36, 8, 8, 8, 8, 16, 8, 64, 9, 9, 9, 59, 9, 56, 9, 9, 9, 9, 9, 79, 9, 9, 9, 9, 9, 9, 9, 10, 10, 80, 10, 40, 10, 10, 10, 97, 10, 10, 10, 10, 10, 54, 10, 10, 10, 10, 10, 11, 11, 29, 11, 11, 11, 11, 11, 11, 11, 11, 11, 51, 36, 11, 11, 1, 11, 52, 67, 12, 46, 12, 12, 12, 12, 12, 12, 12, 12, 97, 12, 12, 12, 1, 12, 12, 78, 12, 12, 13, 75, 15, 31, 13, 1, 84, 14, 13, 61, 13, 13, 13, 13, 13, 13, 13, 73, 13, 13, 95, 3, 14, 14, 14, 56, 14, 14, 88, 11, 14, 14, 54, 14, 14, 14, 14, 14, 14, 14, 35, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 62, 16, 16, 16, 16, 73, 43, 16, 16, 16, 17, 22, 16, 16, 16, 84, 16, 61, 16, 17, 17, 17, 17, 17, 17, 17, 17, 95, 17, 17, 17, 46, 43, 29, 17, 17, 17, 17, 94, 18, 28, 18, 18, 18, 18, 74, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 28, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 74, 19, 19, 19, 19, 19, 19, 19, 70, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1, 21, 8, 87, 79, 21, 21, 21, 21, 21, 80, 21, 21, 21, 21, 21, 74, 21, 21, 43, 88, 14, 67, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 49, 22, 22, 29, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 46, 15, 24, 24, 24, 24, 62, 24, 24, 33, 19, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 13, 20, 26, 26, 26, 26, 26, 26, 26, 96, 26, 26, 26, 26, 26, 26, 0, 57, 26, 94, 27, 27, 27, 27, 27, 83, 18, 7, 27, 27, 64, 27, 27, 27, 99, 27, 27, 27, 27, 27, 28, 49, 46, 28, 28, 28, 28, 28, 85, 28, 28, 28, 28, 28, 28, 28, 39, 28, 28, 28, 60, 22, 21, 8, 29, 37, 29, 70, 80, 83, 29, 29, 29, 85, 29, 29, 29, 87, 29, 56, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 13, 31, 31, 31, 13, 32, 51, 9, 32, 32, 32, 32, 32, 97, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 61, 33, 54, 43, 33, 80, 33, 33, 33, 33, 33, 56, 33, 33, 54, 33, 33, 14, 33, 34, 40, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 61, 34, 1, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 17, 35, 35, 35, 84, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 66, 37, 31, 33, 37, 36, 37, 37, 37, 37, 84, 37, 37, 37, 37, 14, 37, 44, 37, 87, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 80, 81, 6, 80, 9, 34, 40, 26, 40, 40, 40, 19, 77, 40, 40, 1, 21, 40, 46, 41, 41, 41, 92, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 61, 41, 41, 42, 42, 42, 42, 84, 48, 84, 6, 42, 11, 24, 94, 42, 42, 42, 62, 42, 81, 42, 42, 43, 43, 43, 21, 43, 54, 43, 46, 43, 44, 95, 43, 43, 43, 43, 1, 43, 43, 43, 93, 44, 44, 44, 60, 44, 44, 44, 44, 74, 14, 44, 43, 43, 43, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 16, 34, 46, 84, 46, 46, 88, 46, 46, 52, 31, 80, 46, 46, 46, 43, 72, 90, 46, 66, 46, 47, 47, 33, 47, 97, 47, 47, 47, 47, 79, 47, 47, 47, 47, 47, 47, 47, 79, 47, 47, 48, 48, 48, 48, 6, 48, 55, 48, 48, 48, 48, 48, 48, 48, 48, 48, 32, 48, 48, 27, 49, 49, 48, 49, 49, 46, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 77, 50, 50, 50, 50, 53, 50, 50, 50, 50, 47, 50, 50, 50, 6, 50, 50, 50, 50, 51, 84, 51, 51, 51, 51, 51, 51, 51, 51, 74, 14, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 97, 52, 52, 52, 52, 52, 43, 16, 52, 52, 52, 80, 52, 52, 52, 52, 52, 52, 32, 63, 53, 53, 53, 73, 53, 44, 97, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 40, 54, 54, 35, 54, 54, 54, 89, 54, 54, 54, 13, 54, 11, 33, 54, 95, 66, 55, 55, 55, 55, 85, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 16, 9, 56, 14, 64, 56, 95, 56, 0, 56, 28, 95, 84, 56, 56, 8, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 5, 57, 57, 57, 53, 57, 57, 57, 44, 88, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 32, 20, 59, 20, 59, 72, 59, 24, 90, 59, 59, 18, 59, 59, 59, 26, 59, 73, 59, 60, 60, 60, 31, 73, 80, 43, 60, 60, 82, 60, 34, 60, 60, 60, 60, 60, 65, 60, 74, 44, 44, 43, 61, 61, 61, 61, 61, 61, 32, 61, 61, 61, 56, 61, 61, 88, 61, 73, 74, 62, 62, 62, 62, 62, 62, 62, 64, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 21, 62, 63, 63, 63, 63, 63, 63, 63, 74, 63, 63, 63, 63, 63, 56, 37, 51, 63, 63, 63, 64, 64, 47, 64, 64, 64, 90, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 1, 64, 64, 64, 65, 65, 65, 65, 65, 65, 95, 65, 65, 6, 61, 35, 61, 65, 80, 51, 65, 65, 65, 65, 66, 28, 66, 66, 26, 8, 66, 66, 29, 66, 66, 28, 28, 66, 66, 34, 66, 66, 66, 66, 67, 82, 67, 97, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 88, 67, 67, 67, 67, 68, 68, 13, 68, 68, 68, 68, 68, 68, 68, 68, 94, 68, 68, 68, 68, 68, 68, 68, 68, 69, 3, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 88, 70, 44, 70, 70, 31, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 45, 66, 8, 29, 71, 71, 71, 71, 88, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 7, 72, 72, 72, 72, 72, 59, 72, 72, 73, 73, 61, 73, 16, 73, 73, 50, 73, 73, 73, 73, 33, 73, 73, 73, 19, 73, 66, 73, 74, 74, 74, 16, 74, 74, 74, 74, 74, 74, 74, 74, 74, 60, 6, 15, 74, 13, 74, 36, 75, 75, 75, 24, 75, 75, 6, 75, 54, 75, 75, 84, 75, 75, 60, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 52, 76, 76, 76, 24, 76, 76, 14, 76, 76, 76, 77, 77, 77, 77, 77, 77, 12, 77, 45, 77, 77, 56, 77, 95, 8, 11, 56, 77, 77, 77, 78, 78, 78, 44, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 17, 79, 79, 79, 79, 29, 80, 80, 34, 34, 61, 80, 80, 95, 80, 67, 98, 80, 80, 1, 80, 80, 80, 80, 80, 81, 40, 81, 8, 81, 81, 81, 81, 81, 81, 29, 81, 19, 18, 29, 81, 81, 81, 81, 81, 84, 82, 82, 82, 82, 82, 82, 42, 27, 82, 82, 82, 82, 94, 82, 82, 82, 82, 82, 82, 97, 14, 83, 83, 32, 83, 16, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 77, 84, 84, 44, 22, 84, 84, 84, 84, 43, 21, 14, 67, 61, 84, 84, 43, 84, 84, 84, 85, 85, 85, 75, 85, 85, 85, 85, 85, 85, 57, 85, 85, 73, 37, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 43, 87, 80, 46, 87, 87, 16, 88, 87, 87, 87, 95, 87, 87, 87, 40, 87, 88, 18, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 22, 89, 89, 48, 61, 89, 89, 89, 89, 89, 89, 97, 89, 89, 89, 89, 53, 89, 89, 89, 89, 90, 36, 37, 90, 90, 65, 90, 90, 73, 61, 90, 90, 90, 61, 85, 90, 90, 95, 90, 73, 91, 91, 91, 91, 91, 91, 91, 22, 91, 73, 29, 37, 91, 91, 91, 91, 91, 91, 40, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 51, 92, 33, 92, 92, 26, 92, 92, 85, 93, 93, 20, 93, 93, 93, 6, 72, 93, 93, 34, 93, 75, 93, 53, 93, 11, 93, 93, 93, 94, 94, 55, 94, 27, 94, 94, 94, 94, 94, 64, 94, 94, 94, 28, 94, 19, 59, 94, 64, 95, 95, 95, 95, 95, 95, 95, 95, 6, 95, 95, 55, 95, 95, 43, 95, 95, 95, 95, 95, 96, 96, 96, 24, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 52, 96, 96, 96, 96, 96, 97, 97, 97, 97, 40, 97, 97, 97, 97, 97, 97, 97, 1, 74, 97, 97, 97, 84, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99]\n",
        "all_preds2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 0, 0, 0, 1, 1, 1, 1, 1, 1, 51, 1, 1, 95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 97, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 76, 5, 5, 5, 76, 5, 5, 5, 5, 5, 5, 5, 6, 6, 43, 6, 84, 6, 6, 14, 6, 55, 28, 6, 6, 74, 6, 6, 6, 74, 6, 6, 7, 37, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 44, 54, 8, 8, 8, 35, 8, 8, 8, 8, 8, 15, 8, 36, 8, 8, 8, 8, 16, 8, 64, 9, 9, 9, 59, 9, 56, 9, 9, 9, 9, 9, 79, 9, 9, 9, 9, 9, 9, 9, 10, 10, 80, 10, 40, 10, 10, 10, 97, 10, 10, 10, 10, 10, 54, 10, 10, 10, 10, 10, 11, 11, 29, 11, 11, 11, 11, 11, 11, 11, 11, 11, 51, 36, 11, 11, 1, 11, 52, 67, 12, 46, 12, 12, 12, 12, 12, 12, 12, 12, 97, 12, 12, 12, 1, 12, 12, 78, 12, 12, 13, 75, 15, 31, 13, 1, 84, 14, 13, 61, 13, 13, 13, 13, 13, 13, 13, 73, 13, 13, 95, 3, 14, 14, 14, 56, 14, 14, 88, 11, 14, 14, 54, 14, 14, 14, 14, 14, 14, 14, 35, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 62, 16, 16, 16, 16, 73, 43, 16, 16, 16, 17, 22, 16, 16, 16, 84, 16, 61, 16, 17, 17, 17, 17, 17, 17, 17, 17, 95, 17, 17, 17, 46, 43, 29, 17, 17, 17, 17, 94, 18, 28, 18, 18, 18, 18, 74, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 28, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 74, 19, 19, 19, 19, 19, 19, 19, 70, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1, 21, 8, 87, 79, 21, 21, 21, 21, 21, 80, 21, 21, 21, 21, 21, 74, 21, 21, 43, 88, 14, 67, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 49, 22, 22, 29, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 46, 15, 24, 24, 24, 24, 62, 24, 24, 33, 19, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 13, 20, 26, 26, 26, 26, 26, 26, 26, 96, 26, 26, 26, 26, 26, 26, 0, 57, 26, 94, 27, 27, 27, 27, 27, 83, 18, 7, 27, 27, 64, 27, 27, 27, 99, 27, 27, 27, 27, 27, 28, 49, 46, 28, 28, 28, 28, 28, 85, 28, 28, 28, 28, 28, 28, 28, 39, 28, 28, 28, 60, 22, 21, 8, 29, 37, 29, 70, 80, 83, 29, 29, 29, 85, 29, 29, 29, 87, 29, 56, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 13, 31, 31, 31, 13, 32, 51, 9, 32, 32, 32, 32, 32, 97, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 61, 33, 54, 43, 33, 80, 33, 33, 33, 33, 33, 56, 33, 33, 54, 33, 33, 14, 33, 34, 40, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 61, 34, 1, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 17, 35, 35, 35, 84, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 66, 37, 31, 33, 37, 36, 37, 37, 37, 37, 84, 37, 37, 37, 37, 14, 37, 44, 37, 87, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 80, 81, 6, 80, 9, 34, 40, 26, 40, 40, 40, 19, 77, 40, 40, 1, 21, 40, 46, 41, 41, 41, 92, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 61, 41, 41, 42, 42, 42, 42, 84, 48, 84, 6, 42, 11, 24, 94, 42, 42, 42, 62, 42, 81, 42, 42, 43, 43, 43, 21, 43, 54, 43, 46, 43, 44, 95, 43, 43, 43, 43, 1, 43, 43, 43, 93, 44, 44, 44, 60, 44, 44, 44, 44, 74, 14, 44, 43, 43, 43, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 16, 34, 46, 84, 46, 46, 88, 46, 46, 52, 31, 80, 46, 46, 46, 43, 72, 90, 46, 66, 46, 47, 47, 33, 47, 97, 47, 47, 47, 47, 79, 47, 47, 47, 47, 47, 47, 47, 79, 47, 47, 48, 48, 48, 48, 6, 48, 55, 48, 48, 48, 48, 48, 48, 48, 48, 48, 32, 48, 48, 27, 49, 49, 48, 49, 49, 46, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 77, 50, 50, 50, 50, 53, 50, 50, 50, 50, 47, 50, 50, 50, 6, 50, 50, 50, 50, 51, 84, 51, 51, 51, 51, 51, 51, 51, 51, 74, 14, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 97, 52, 52, 52, 52, 52, 43, 16, 52, 52, 52, 80, 52, 52, 52, 52, 52, 52, 32, 63, 53, 53, 53, 73, 53, 44, 97, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 40, 54, 54, 35, 54, 54, 54, 89, 54, 54, 54, 13, 54, 11, 33, 54, 95, 66, 55, 55, 55, 55, 85, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 16, 9, 56, 14, 64, 56, 95, 56, 0, 56, 28, 95, 84, 56, 56, 8, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 5, 57, 57, 57, 53, 57, 57, 57, 44, 88, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 32, 20, 59, 20, 59, 72, 59, 24, 90, 59, 59, 18, 59, 59, 59, 26, 59, 73, 59, 60, 60, 60, 31, 73, 80, 43, 60, 60, 82, 60, 34, 60, 60, 60, 60, 60, 65, 60, 74, 44, 44, 43, 61, 61, 61, 61, 61, 61, 32, 61, 61, 61, 56, 61, 61, 88, 61, 73, 74, 62, 62, 62, 62, 62, 62, 62, 64, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 21, 62, 63, 63, 63, 63, 63, 63, 63, 74, 63, 63, 63, 63, 63, 56, 37, 51, 63, 63, 63, 64, 64, 47, 64, 64, 64, 90, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 1, 64, 64, 64, 65, 65, 65, 65, 65, 65, 95, 65, 65, 6, 61, 35, 61, 65, 80, 51, 65, 65, 65, 65, 66, 28, 66, 66, 26, 8, 66, 66, 29, 66, 66, 28, 28, 66, 66, 34, 66, 66, 66, 66, 67, 82, 67, 97, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 88, 67, 67, 67, 67, 68, 68, 13, 68, 68, 68, 68, 68, 68, 68, 68, 94, 68, 68, 68, 68, 68, 68, 68, 68, 69, 3, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 88, 70, 44, 70, 70, 31, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 45, 66, 8, 29, 71, 71, 71, 71, 88, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 7, 72, 72, 72, 72, 72, 59, 72, 72, 73, 73, 61, 73, 16, 73, 73, 50, 73, 73, 73, 73, 33, 73, 73, 73, 19, 73, 66, 73, 74, 74, 74, 16, 74, 74, 74, 74, 74, 74, 74, 74, 74, 60, 6, 15, 74, 13, 74, 36, 75, 75, 75, 24, 75, 75, 6, 75, 54, 75, 75, 84, 75, 75, 60, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 52, 76, 76, 76, 24, 76, 76, 14, 76, 76, 76, 77, 77, 77, 77, 77, 77, 12, 77, 45, 77, 77, 56, 77, 95, 8, 11, 56, 77, 77, 77, 78, 78, 78, 44, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 17, 79, 79, 79, 79, 29, 80, 80, 34, 34, 61, 80, 80, 95, 80, 67, 98, 80, 80, 1, 80, 80, 80, 80, 80, 81, 40, 81, 8, 81, 81, 81, 81, 81, 81, 29, 81, 19, 18, 29, 81, 81, 81, 81, 81, 84, 82, 82, 82, 82, 82, 82, 42, 27, 82, 82, 82, 82, 94, 82, 82, 82, 82, 82, 82, 97, 14, 83, 83, 32, 83, 16, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 77, 84, 84, 44, 22, 84, 84, 84, 84, 43, 21, 14, 67, 61, 84, 84, 43, 84, 84, 84, 85, 85, 85, 75, 85, 85, 85, 85, 85, 85, 57, 85, 85, 73, 37, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 43, 87, 80, 46, 87, 87, 16, 88, 87, 87, 87, 95, 87, 87, 87, 40, 87, 88, 18, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 22, 89, 89, 48, 61, 89, 89, 89, 89, 89, 89, 97, 89, 89, 89, 89, 53, 89, 89, 89, 89, 90, 36, 37, 90, 90, 65, 90, 90, 73, 61, 90, 90, 90, 61, 85, 90, 90, 95, 90, 73, 91, 91, 91, 91, 91, 91, 91, 22, 91, 73, 29, 37, 91, 91, 91, 91, 91, 91, 40, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 51, 92, 33, 92, 92, 26, 92, 92, 85, 93, 93, 20, 93, 93, 93, 6, 72, 93, 93, 34, 93, 75, 93, 53, 93, 11, 93, 93, 93, 94, 94, 55, 94, 27, 94, 94, 94, 94, 94, 64, 94, 94, 94, 28, 94, 19, 59, 94, 64, 95, 95, 95, 95, 95, 95, 95, 95, 6, 95, 95, 55, 95, 95, 43, 95, 95, 95, 95, 95, 96, 96, 96, 24, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 52, 96, 96, 96, 96, 96, 97, 97, 97, 97, 40, 97, 97, 97, 97, 97, 97, 97, 1, 74, 97, 97, 97, 84, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99]\n",
        "all_preds1 = np.array(all_preds1)\n",
        "all_preds2 = np.array(all_preds2)\n",
        "accuracy = np.mean(all_preds1 == all_preds2)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU8tr2JTkWyi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LTq1ZaI_fRn7",
        "J7Joi2BOKfw8",
        "i6OVs1PxmkqK"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
